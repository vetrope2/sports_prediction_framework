{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sports Prediction Framework","text":"<p>Welcome to the Sports Prediction Framework, a modular and extensible Python framework designed to facilitate data handling, model training, evaluation, and betting simulations for sports analytics.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<ul> <li>Installation</li> <li>Quick Start Guide</li> <li>Examples</li> <li>Commented Workflow</li> </ul>"},{"location":"#overview","title":"Overview","text":"<p>This framework provides a comprehensive pipeline for sports prediction, including:</p> <ul> <li>Data Loading &amp; Parsing: Flexible connectors and parsers to ingest and preprocess sports data from multiple sources.</li> <li>Data Wrappers: Clean abstractions over raw data for various sports and competitions, supporting feature extraction and label management.</li> <li>Modeling: Support for diverse predictive models, including flat and graph neural network architectures.</li> <li>Training &amp; Evaluation: Learner, trainer, and tester components streamline the training process and enable robust model evaluation.</li> <li>Simulation &amp; Betting Strategies: Implementations of multiple betting simulations to assess strategy performance using historical match data.</li> <li>Optimization: Integration with hyperparameter optimization tools to fine-tune model performance.</li> <li>Data Transformation &amp; Scoping: Powerful mechanisms to segment and iterate over datasets for temporal or categorical analysis.</li> </ul>"},{"location":"#modules","title":"Modules","text":"<ul> <li><code>dataloader</code>: Handles data ingestion and parsing.</li> <li><code>datawrapper</code>: Wraps raw data into usable formats per sport.</li> <li><code>model</code>: Contains model definitions and training logic.</li> <li><code>learner</code>: Coordinates training and evaluation.</li> <li><code>simulation</code>: Betting strategies and evaluation methods.</li> <li><code>transformer</code>: Tools for data segmentation and transformation.</li> <li><code>optimizer</code>: Hyperparameter tuning support.</li> <li><code>utils</code>: Utility functions and helpers.</li> </ul>"},{"location":"base_model/","title":"Base Model","text":""},{"location":"base_model/#model-class","title":"<code>Model</code> Class","text":"<p>The <code>Model</code> class defines a standardized interface for all model implementations within the system. It serves as an abstract base, ensuring consistent usage and interchangeability across different modeling approaches.</p>"},{"location":"base_model/#methods","title":"Methods","text":"<ul> <li> <p><code>fit(X, y)</code>   Trains the model using input features <code>X</code> and target labels <code>y</code>.   This method must be implemented by all concrete subclasses.</p> </li> <li> <p><code>predict(X)</code>   Generates predictions from the input features <code>X</code>.   Returns output in a consistent format, regardless of the model's internal structure.</p> </li> <li> <p><code>set_params(params)</code>   Configures model hyperparameters dynamically using a dictionary <code>params</code>.   Enables flexible experimentation without requiring code changes.</p> </li> <li> <p><code>reset_state()</code>   Resets or reinitializes the internal state of the model.   Useful for ensuring clean training or evaluation runs.</p> </li> </ul>"},{"location":"base_model/#summary","title":"Summary","text":"<p>These methods form the core interface contract for all models in the framework. By adhering to this interface, different model implementations can be easily integrated, compared, and swapped out within the system.</p>"},{"location":"database_connect/","title":"Database Connection","text":""},{"location":"database_connect/#using-database-data-in-the-framework","title":"Using Database Data in the Framework","text":"<p>To use data from a database within the framework, you must have a <code>.env</code> file located in your current working directory. This file should contain the necessary configuration variables for database connection.</p>"},{"location":"database_connect/#required-env-variables","title":"Required <code>.env</code> Variables","text":"<p>Below is an example of the essential variables your <code>.env</code> file should include:</p> <pre><code>DB_HOST=your_db_host\nDB_PORT=your_db_port\nDB_NAME=your_db_name\nDB_USER=your_db_username\nDB_PASSWORD=your_db_password\n</code></pre> <p>\u26a0\ufe0f Warning: The following SSH-related variables are only required if you are connecting to the database via an SSH tunnel.</p> <pre><code>SSH_HOST=ssh_server\nSSH_USER=ssh_user\nSSH_KEY_PATH=path_to_your_key\n</code></pre>"},{"location":"examples/","title":"Self-Contained Demonstration","text":"<p>We provide a self-contained demonstration that does not require any database access. This makes it easy to explore and test the framework without setting up a database connection.</p> <p>The demonstration runs in Google Colab and uses the <code>data.parquet</code> file located in the <code>examples</code> directory of the repository.</p> <p>You can open and run the notebooks directly via the following links:</p> <ul> <li> <p>Flat Model</p> </li> <li> <p>Other Flat</p> </li> <li> <p>Model Evaluation</p> </li> <li> <p>Optimization</p> </li> <li> <p>Simulation example</p> </li> </ul> <p>Feel free to explore these notebooks to get a hands-on understanding of the framework using real data samples.</p>"},{"location":"examples/#example-of-dataparquet-content","title":"Example of <code>data.parquet</code> Content","text":"Date Home Away HS AS WDL odds_1 odds_X odds_2 2004-01-21 Bayern Munich Hamburger SV 3 0 1 1.39 4.00 6.50 2004-01-22 Wolfsburg Dortmund 1 2 2 1.83 3.25 3.75 2004-01-22 Nurnberg Kaiserslautern 1 3 2 2.10 3.25 3.00 2004-01-22 Nurnberg Kaiserslautern 1 3 2 2.00 \u2014 3.25 2004-01-22 Mainz Stuttgart 2 3 2 2.79 3.25 2.20 <p>Note: This is a small excerpt of the <code>data.parquet</code> file. The actual dataset contains many more rows and columns with additional information.</p>"},{"location":"installation/","title":"Installation","text":"<p>Install the framework locally from the folder:</p> <pre><code>pip install .\n</code></pre> <p>Install from pypi:</p> <pre><code>pip install sports-prediction-framework\n</code></pre>"},{"location":"loader/","title":"Data Loading","text":"<p>This section explains how the framework handles loading data from databases and prepares it for use in model training, evaluation, and experimentation.</p> <p>The data loading pipeline is designed to be modular, extensible, and easy to use. It is composed of three main components:</p> <ul> <li>Connector \u2014 manages database connections</li> <li>DataSource \u2014 handles querying and parsing data</li> <li>DataLoader \u2014 provides convenient, high-level data access methods</li> </ul>"},{"location":"loader/#connector","title":"Connector","text":"<p>The <code>Connector</code> is responsible for establishing and managing the connection to your PostgreSQL database. It supports two main modes:</p> <ul> <li>Local connection: connects directly using credentials stored in an environment configuration file (<code>.env</code>).</li> <li>Remote SSH tunneling: securely connects to a remote database via SSH.</li> </ul> <p>This design makes it easy to switch between local development and remote production environments without changing your code.</p>"},{"location":"loader/#datasource","title":"DataSource","text":"<p><code>DataSource</code> acts as the middleman between your database and the application logic. It uses SQLAlchemy to:</p> <ul> <li>Execute raw or parameterized SQL queries.</li> <li>Parse results into Pandas <code>DataFrame</code> objects.</li> <li>Automatically apply sport-specific parsing logic based on the <code>SportType</code> enumeration.</li> </ul> <p>This means that regardless of the sport or data source, <code>DataSource</code> ensures your data is returned in a consistent, ready-to-use format.</p>"},{"location":"loader/#dataloader","title":"DataLoader","text":"<p>The <code>DataLoader</code> sits at the top layer and offers simple class methods that make data retrieval straightforward:</p> <ul> <li>Methods like <code>load()</code>, <code>load_distinct()</code>, and <code>preview()</code> let you query and retrieve data with minimal code.</li> <li>The <code>load_and_wrap()</code> method wraps the loaded data into specialized domain-specific objects (<code>DataWrapper</code> subclasses), making it ready for model consumption.</li> </ul> <p>Using <code>DataLoader</code>, you don't need to worry about database connections, SQL syntax, or parsing details \u2014 it\u2019s all handled behind the scenes.</p>"},{"location":"loader/#typical-data-loading-flow","title":"Typical Data Loading Flow","text":"<p>Here's what happens when you load data through the framework:</p> <ol> <li>Your code calls a method on <code>DataLoader</code> to request data.</li> <li><code>DataLoader</code> creates a <code>DataSource</code> instance.</li> <li><code>DataSource</code> initializes a <code>Connector</code> and opens a database connection.</li> <li>A SQL query is executed to fetch the data.</li> <li>The raw data is parsed and converted to a Pandas DataFrame with sport-specific processing.</li> <li>Optionally, the data is wrapped in a <code>DataWrapper</code> for downstream use.</li> </ol>"},{"location":"optimizer/","title":"Optimizer","text":"<p>The <code>Optimizer</code> class provides a modular and extensible interface for hyperparameter tuning using the Optuna framework. It is designed to be agnostic to the internal model implementation, relying instead on a provided <code>Learner</code> instance and <code>DataWrapper</code> to orchestrate training and evaluation.</p>"},{"location":"optimizer/#core-features","title":"Core Features","text":"<ul> <li>Learner-Agnostic: Works with any <code>Learner</code> class, enabling use with a wide range of models.</li> <li>Metric-Driven Optimization: Selects the best hyperparameters using an evaluation metric of your choice.</li> <li>Search Space Definition: Accepts a flexible <code>search_space</code> dictionary with support for Optuna's parameter suggestion methods.</li> <li>Robust Error Handling: Supports pruning and failure skipping using Optuna's built-in mechanisms.</li> <li>Repeatable &amp; Configurable: Fully configurable number of trials and seed for reproducibility.</li> </ul>"},{"location":"optimizer/#optimization-workflow","title":"Optimization Workflow","text":"<p>The user provides:</p> <ul> <li>A <code>Learner</code> class that wraps model training and testing.</li> <li>A <code>DataWrapper</code> to supply training and testing data.</li> <li>An <code>evaluate_metrics</code> function to compute a scalar score.</li> <li>A <code>search_space</code> dictionary defining the parameters to optimize.</li> </ul> <p>The optimizer iterates over trials:</p> <ul> <li>It samples new hyperparameters using the search space.</li> <li>Passes the parameters to the model through the learner.</li> <li>Trains and tests the model.</li> <li>Evaluates performance using the selected metric.</li> <li>Logs and optionally prunes failed or suboptimal trials.</li> </ul> <p>The best-performing set of parameters is returned at the end.</p>"},{"location":"optimizer/#supported-metrics","title":"Supported Metrics","text":"<p>The optimization process relies on a scoring function, typically selected from the following supported metrics:</p> Metric Description Accuracy Measures the proportion of correct predictions among all predictions. Precision Evaluates the number of true positives out of all predicted positives. Recall Measures the number of true positives out of all actual positives. F1 Score Harmonic mean of Precision and Recall, balancing false positives and false negatives. Brier Score Quantifies the accuracy of probabilistic predictions (lower is better). RPS Ranked Probability Score \u2014 evaluates the quality of multi-class probabilistic forecasts."},{"location":"optimizer/#search-space-usage-example","title":"Search Space Usage Example","text":"<pre><code>search_space = {\n    'n_dense': ('int', 2, 5),\n}\n\nopt = Optimizer(datawrapper, learner, Metric.ACCURACY, search_space, n_trials=4)\nopt.run()\n</code></pre>"},{"location":"scope/","title":"Iterative Training - Scope","text":""},{"location":"scope/#iterative-training-with-scope","title":"Iterative Training with Scope","text":"<p>To support flexible and systematic model training, the framework introduces the concept of a Scope \u2014 a generalized abstraction for iterating over segments of a dataset. This makes it easy to implement strategies like rolling windows, expanding horizons, or category-based splits for training and evaluation.</p>"},{"location":"scope/#scope-the-core-iterator","title":"Scope: The Core Iterator","text":"<p>At its core, the <code>Scope</code> class defines a consistent interface for stepping through data partitions. It exposes key methods such as:</p> <ul> <li><code>shift()</code>: Advance the scope to the next data segment.</li> <li><code>inside()</code>: Check whether iteration can continue.</li> <li><code>reset_state()</code>: Return the scope to its initial state.</li> <li><code>current_state()</code>: Return the current position or window definition.</li> </ul> <p>Several concrete implementations of <code>Scope</code> are available:</p>"},{"location":"scope/#windowscope","title":"WindowScope","text":"<p>A base class for time-based iteration. It operates on a numeric or temporal column and is controlled by three parameters: - <code>start</code>: Where to begin. - <code>size</code>: Length of the window. - <code>stride</code>: Step size between iterations.</p> <p>Derived classes include:</p> <ul> <li><code>ScopeRoller</code>: Uses a fixed-size window and moves it forward by <code>stride</code> on each iteration. This is similar to a rolling window approach.</li> <li><code>ScopeExpander</code>: Starts with a fixed point and increases the window size with each iteration. Useful for walk-forward validation.</li> </ul>"},{"location":"scope/#enumscope","title":"EnumScope","text":"<p>Used for iterating over categorical values (e.g., leagues or countries). It loops through unique entries in a specified column, enabling segmented evaluation for each category.</p>"},{"location":"scope/#scopeselector-bridging-scope-and-data","title":"ScopeSelector: Bridging Scope and Data","text":"<p>While <code>Scope</code> defines how iteration happens, it doesn\u2019t know anything about the dataset itself. That\u2019s where <code>ScopeSelector</code> comes in.</p> <p>A <code>ScopeSelector</code> pairs a <code>Scope</code> with a <code>DataWrapper</code> and provides the <code>transform()</code> method, which applies the current scope state to the dataset. This enables dynamic slicing of data during iterative training or evaluation.</p> <p>Different selectors specialize in different types of filtering: - <code>WindowSelector</code>: Filters rows within a numeric or temporal range. - <code>EnumSelector</code>: Filters by specific category values.</p> <p>This design separates when the data changes (<code>Scope</code>) from how it\u2019s extracted (<code>ScopeSelector</code>), improving modularity and making it easier to extend or compose new strategies.</p>"},{"location":"scope/#dataselector-orchestrating-iteration","title":"DataSelector: Orchestrating Iteration","text":"<p>The <code>DataSelector</code> class coordinates multiple <code>ScopeSelector</code> instances\u2014both for training and testing\u2014and ensures smooth iteration over all valid combinations of data splits.</p> <p>It supports: - Recursive iteration with backtracking to explore complex scope setups. - Mixed scope types (e.g., rolling training window with category-based testing). - Validation of each scope configuration via <code>holds()</code> before proceeding.</p> <p>During each step, <code>DataSelector</code>:</p> <ol> <li>Calls <code>transform()</code> on all selectors to extract the current data subset.</li> <li>Validates the configuration.</li> <li>Advances or backtracks based on the iteration logic.</li> </ol> <p>This design supports reproducible and structured experiments across multiple training and testing regimes, including nested, time-based, and categorical splits.</p>"},{"location":"simulation/","title":"Simulation Framework","text":"<p>To evaluate the effectiveness of betting strategies based on model predictions and associated odds, the framework introduces a modular and extensible simulation infrastructure centered around the <code>Simulation</code> base class.</p>"},{"location":"simulation/#abstract-simulation-interface","title":"Abstract Simulation Interface","text":"<p>The <code>Simulation</code> class serves as an abstract base class that defines the contract for all betting simulations. It operates over a <code>DataWrapper</code>, which provides access to model predictions, betting odds, and match outcomes in a unified structure.</p>"},{"location":"simulation/#key-methods","title":"Key Methods","text":"<ul> <li> <p>Initialization   Accepts a <code>DataWrapper</code> instance and stores the underlying DataFrame for simulation use.</p> </li> <li> <p><code>simulate()</code> (abstract)   Must be implemented by subclasses. Defines the specific betting logic and how returns are calculated.</p> </li> <li> <p><code>evaluate()</code>   A shared utility method that summarizes simulation performance using the following metrics:</p> </li> <li>Total Return \u2013 Cumulative return from all simulated bets.</li> <li>Mean Return \u2013 Average return per bet.</li> <li>Standard Deviation \u2013 Measures the volatility of returns.</li> <li>Sharpe Ratio \u2013 Risk-adjusted return, computed as: <code>Sharpe Ratio = Mean Return / Standard Deviation</code></li> </ul> <p>This abstraction ensures consistent evaluation while allowing custom betting logic to be defined independently for each strategy.</p> <p>This design enables empirical evaluation and benchmarking of various betting strategies, all backed by model-driven predictions and structured performance metrics.</p>"},{"location":"training/","title":"Training Architecture: Trainer, Tester, and Learner","text":"<p>The training workflow in the framework is structured around three main components: Trainer, Tester, and Learner. This modular design promotes clear separation of responsibilities, flexibility, and ease of extension for different model types and evaluation strategies.</p>"},{"location":"training/#trainer","title":"Trainer","text":"<p>The Trainer is responsible for fitting a model to labeled training data. It acts as an interface between the data pipeline and the model\u2019s training methods, ensuring that the appropriate input features and labels are passed. The Trainer handles all necessary preprocessing steps such as column selection and parameter preparation derived from the data. It supports a variety of model types, abstracting away internal model details.</p>"},{"location":"training/#tester","title":"Tester","text":"<p>The Tester handles model evaluation by generating predictions on test or unseen datasets. It performs similar preprocessing to the Trainer, but instead of training, it routes data through the model\u2019s prediction interface. The Tester also manages formatting and handling of prediction outputs to maintain a consistent evaluation interface across different model implementations.</p>"},{"location":"training/#learner","title":"Learner","text":"<p>The Learner orchestrates the overall training and evaluation process by coordinating the Trainer, Tester, and a DataSelector component that defines data splits into training and testing scopes. It manages the training-evaluation loop, applying the Trainer to the training subset and the Tester to the corresponding testing subset.</p>"},{"location":"training/#variants-of-learner","title":"Variants of Learner","text":"<ul> <li> <p>LearnerWithoutScope   Designed for simple cases where no train/test split is necessary. Trainer and Tester operate on the same dataset directly.</p> </li> <li> <p>UpdatingLearner   Supports iterative training and evaluation workflows, such as rolling or sequential splits common in time-series or temporal datasets. It can manage multiple nested learners and merge their results using defined strategies.</p> </li> </ul>"},{"location":"usage/","title":"Getting Started","text":"<p>Welcome to the framework! There are two main ways to get started depending on your setup and needs:</p>"},{"location":"usage/#1-connect-to-a-database","title":"1. Connect to a Database","text":"<p>If you want to work with your own or a remote database, make sure to configure your environment by creating a <code>.env</code> file in your current working directory. This file should include your database credentials and, if necessary, SSH tunnel settings.</p> <p>See Database Configuration for detailed instructions.</p>"},{"location":"usage/#2-use-the-self-contained-examples","title":"2. Use the Self-Contained Examples","text":"<p>If you prefer a quick start without needing database access, you can explore our self-contained demonstrations. These run in Google Colab and use the sample data provided in the <code>examples</code> directory (<code>data.parquet</code>).</p> <p>Check out the Examples and Demos page to open the notebooks directly.</p> <p>Feel free to choose the option that best fits your workflow. If you\u2019re new, we recommend starting with the examples for a smooth introduction!</p>"},{"location":"workflow_comment/","title":"Commented Workflow","text":""},{"location":"workflow_comment/#1-load-bundesliga-data-including-bookmaker-odds-bet365","title":"1. Load Bundesliga Data Including Bookmaker Odds (bet365)","text":"<p>In this step, we load Bundesliga match data filtered by league name and including bookmaker odds from \"bet365\". The data is wrapped for convenient use within the framework.</p> <p>This method shields the user from having to manually connect to a database or parse raw data based on the database format. It returns a ready-to-use wrapped dataset for downstream tasks.</p> <pre><code># Load Bundesliga football match data with bet365 bookmaker odds\ndw = DataLoader.load_and_wrap_odds(\n    \"football\",\n    \"Matches\",\n    lambda c: c.League == \"Bundesliga\",\n    SportType.FOOTBALL,\n    bookmaker=\"bet365\"\n)\n</code></pre> <p>See Also: DataLoader API Reference</p>"},{"location":"workflow_comment/#excerpt-of-loaded-data","title":"Excerpt of loaded data","text":"Date Home Away HS AS WDL odds_1 odds_X odds_2 2004-01-21 Bayern Munich Hamburger SV 3 0 1 1.39 4.00 6.50 2004-01-22 Wolfsburg Dortmund 1 2 2 1.83 3.25 3.75 2004-01-22 Nurnberg Kaiserslautern 1 3 2 2.10 3.25 3.00 2004-01-22 Nurnberg Kaiserslautern 1 3 2 2.00 \u2014 3.25 2004-01-22 Mainz Stuttgart 2 3 2 2.79 3.25 2.20"},{"location":"workflow_comment/#2-apply-basic-transformations","title":"2. Apply Basic Transformations","text":"<p>In this step, we apply standard preprocessing transformations to the wrapped data using the framework\u2019s <code>Transformer</code> class.</p> <p>This step ensures that the raw data is cleaned and standardized for modeling. Transformations may include parsing dates, encoding categorical variables, or formatting numerical features.</p> <pre><code>from sports_prediction_framework.transformer.Transformer import *\n#Applies basic transformations to the dataframe.\nt = Transformer()\ndw = t.transform(dw)\nprint(dw)\n</code></pre> <p>By default, this transformation adds unique numeric identifiers for each team (Team ID columns), which are often used in embedding-based models.</p>"},{"location":"workflow_comment/#sample-of-transformed-match-data","title":"Sample of Transformed Match Data","text":"Date Home Away HID AID HS AS WDL odds_1 odds_X odds_2 2004-01-21 Bayern Munich Hamburger SV 5 17 3 0 1 1.39 4.00 6.50 2004-01-22 Wolfsburg Dortmund 35 9 1 2 2 1.83 3.25 3.75 2004-01-22 Nurnberg Kaiserslautern 27 24 1 3 2 2.10 3.25 3.00 2004-01-22 Nurnberg Kaiserslautern 27 24 1 3 2 2.00 \u2014 3.25 2004-01-22 Mainz Stuttgart 26 32 2 3 2 2.79 3.25 2.20 <p>Note: This is only a small sample of the available data. The full dataset contains additional rows and possibly other columns. Missing values are represented as em dashes (\u2014).</p>"},{"location":"workflow_comment/#3-define-training-and-prediction-scopes","title":"3. Define Training and Prediction Scopes","text":"<p>Before training, we define the scopes that determine which parts of the data will be used for training (relevant scope) and prediction (prediction scope). </p> <p>In this example, both scopes are created using <code>WindowSelector</code> combined with <code>ScopeExpander</code>, which slices the data by the 'Season' column, selecting windows starting from 2004 up to 2008 with a size of 1 season and a stride of 2 seasons.</p> <p>The <code>DataSelector</code> then combines these scopes, managing the data segmentation for iterative training and testing.</p> <pre><code>from sports_prediction_framework.transformer.Scope import *\nfrom sports_prediction_framework.transformer.DataSelector import *\n\nrelevant_scope = [WindowSelector(ScopeExpander(dw, {\n    'col': 'Season', 'start': 2004, 'max': 2008, 'size': 1, 'stride': 2\n}))]\nprediction_scope = [WindowSelector(ScopeExpander(dw, {\n    'col': 'Season', 'start': 2004, 'max': 2008, 'size': 1, 'stride': 2\n}))]\nscope = DataSelector(relevant_scope, prediction_scope)\n</code></pre> <p>See Also: Scope API Reference </p>"},{"location":"workflow_comment/#4-create-model-and-setup-learner","title":"4. Create Model and Setup Learner","text":"<p>Next, we instantiate a <code>FlatModel</code> with chosen parameters and configure a <code>Learner</code> and an <code>UpdatingLearner</code> to manage the training and evaluation process over the defined data scopes.</p> <p>The <code>UpdatingLearner</code> supports iterative updates by coordinating one or more nested learners, enabling flexible training workflows.</p> <pre><code>from sports_prediction_framework.model.FlatModel import FlatModel\nfrom sports_prediction_framework.learner.Learner import Learner, UpdatingLearner, Tester, Trainer\n\nparams = {\n    'embed_dim': 32,\n    'out_dim': 3,\n    'n_dense': 4,\n    'dense_dim': 64,\n    'architecture_type': 'rectangle',\n    'batch_size': 64,\n}\nflat = FlatModel(params)\n\n#Setup learner and updating learner\nl1 = Learner(Trainer(flat), Tester(flat), scope)\nl = UpdatingLearner(Trainer(flat), Tester(flat), scope, [l1])\n</code></pre>"},{"location":"workflow_comment/#5-generate-predictions","title":"5. Generate Predictions","text":"<p>After training, we use the learner to compute predictions on the dataset. The predicted probabilities for each outcome are stored in columns labeled <code>0</code>, <code>1</code>, and <code>2</code>.</p> <p>This allows you to easily access the model\u2019s confidence for each class or outcome.</p> <pre><code>prob = l.compute(dw)\n#Predictions stored in 0,1,2 columns.\nprint(prob)\n</code></pre>"},{"location":"workflow_comment/#example-output","title":"Example Output","text":"Date Home Away HID AID HS AS WDL odds_1 odds_X odds_2 1 0 2 2004-01-21 Bayern Munich Hamburger SV 5 17 3 0 1 1.39 4.00 6.50 0.596798 0.201601 0.201601 2004-01-22 Wolfsburg Dortmund 35 9 1 2 2 1.83 3.25 3.75 0.174244 0.340452 0.485304 2004-01-22 Nurnberg Kaiserslautern 27 24 1 3 2 2.10 3.25 3.00 0.082314 0.082314 0.835371 2004-01-22 Nurnberg Kaiserslautern 27 24 1 3 2 2.00 3.25 0.082314 0.082314 0.835371 2004-01-22 Mainz Stuttgart 26 32 2 3 2 2.79 3.25 2.20 0.031287 0.031287 0.937426"},{"location":"wrapper/","title":"DataWrapper Module","text":"<p>The DataWrapper module provides a unified and extensible interface for handling sports data within the framework. It abstracts the complexity of working with heterogeneous datasets by standardizing access to core elements such as features, labels, and predictions\u2014essential components in machine learning workflows.</p>"},{"location":"wrapper/#core-components","title":"Core Components","text":"<p>The module revolves around two primary classes:</p>"},{"location":"wrapper/#datahandler","title":"DataHandler","text":"<ul> <li>Acts as the foundational data container.</li> <li>Stores raw sports data in a <code>pandas.DataFrame</code>.</li> <li>Manages explicit collections of feature columns, label columns, and prediction columns.</li> <li>Supports operations like merging new features or labels, extracting specific data subsets, and creating copies for safe data manipulation.</li> </ul>"},{"location":"wrapper/#datawrapper","title":"DataWrapper","text":"<ul> <li>A higher-level interface built on top of <code>DataHandler</code>.</li> <li>Provides convenient methods to access the dataframe, features, labels, and predictions.</li> <li>Supports adding or updating columns seamlessly.</li> <li>Designed to be extended for sport-specific adaptations by subclassing.</li> </ul>"},{"location":"wrapper/#specialized-wrappers","title":"Specialized Wrappers","text":"<p>To handle the diverse structures of sports data, the framework includes specialized <code>DataWrapper</code> subclasses tailored to different domains:</p> <ul> <li> <p>MatchWrapper   Focuses on match-based sports data. It manages columns related to competing teams (<code>Home</code>, <code>Away</code>, <code>HID</code>, <code>AID</code>), scores (<code>HS</code>, <code>AS</code>), and outcomes (<code>WDL</code>). This wrapper offers helper methods to retrieve and update teams involved in the dataset, encapsulating match-specific logic for easier downstream processing.</p> </li> <li> <p>RaceWrapper   Designed for individual competitor sports such as racing. It standardizes access to ranking and performance-related data, facilitating feature extraction and modeling for race results.</p> </li> <li> <p>LeagueWrapper   Handles aggregated competition data such as league standings or seasonal summaries. This wrapper is useful for datasets that represent competition contexts broader than individual events.</p> </li> </ul>"},{"location":"wrapper/#combining-wrappers","title":"Combining Wrappers","text":"<p>Some sports combine multiple data perspectives and therefore require multiple inheritance from these wrappers. For example, the <code>FootballWrapper</code> inherits from both <code>MatchWrapper</code> and <code>LeagueWrapper</code> to provide comprehensive support for both match-level and league-level data semantics.</p> <p>This modular design ensures that data handling remains consistent across different sports, while still being flexible enough to accommodate the unique aspects of each sport\u2019s data structure.</p>"},{"location":"wrapper/#parser-component","title":"Parser Component","text":"<p>The Parser module is responsible for converting raw data from external or internal databases into a standardized internal format that the framework can use for modeling and analysis. This step is crucial when working with heterogeneous data sources, each with its own naming conventions, formats, and quirks.</p> <p>Parsing is automatically triggered during data loading when data is wrapped into a <code>DataWrapper</code>, ensuring all data entering the pipeline follows a consistent schema.</p>"},{"location":"wrapper/#parser-architecture","title":"Parser Architecture","text":"<p>All parser implementations inherit from a common base class, <code>AbstractParser</code>, which defines the standard interface and expected behavior.</p>"},{"location":"wrapper/#current-implementations","title":"Current Implementations","text":"<ul> <li>Filtering out rows with invalid or placeholder results.</li> <li>Extracting home and away team goals from raw result strings.</li> <li>Normalizing season representations (e.g., <code>\"2020/2021\"</code>) into a consistent numeric format.</li> <li>Mapping categorical match outcomes (<code>\"W\"</code>, <code>\"D\"</code>, <code>\"L\"</code>) to numeric labels (<code>1</code>, <code>0</code>, <code>2</code>) suitable for classification.</li> <li>Renaming inconsistent column names to standardized schema (e.g., <code>\"HT\"</code> \u2192 <code>\"Home\"</code>).</li> <li>Ensuring proper data types for key columns to maintain downstream compatibility.</li> </ul>"},{"location":"wrapper/#data-source-specific-parsing","title":"Data Source Specific Parsing","text":"<p>The parser implementations include custom methods for different data sources, since each source may have unique formats or conventions. This modular design allows easy extension to new data sources without affecting existing parsers.</p>"},{"location":"wrapper/#summary","title":"Summary","text":"<p>The Parser component abstracts the complexity of raw data heterogeneity, providing a clean and reliable interface to the rest of the framework. By standardizing input data, it enables consistent and accurate downstream processing and model training.</p>"},{"location":"reference/base_model/","title":"Base model","text":""},{"location":"reference/base_model/#model.Model.Model","title":"<code>Model</code>","text":"<p>Base class for a machine learning model.</p>"},{"location":"reference/base_model/#model.Model.Model--attributes","title":"Attributes","text":"<p>in_cols : list     List of input column names used by the model. model : object     The underlying model object (e.g., sklearn, PyTorch, etc.).</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>class Model:\n    \"\"\"\n    Base class for a machine learning model.\n\n    Attributes\n    ----------\n    in_cols : list\n        List of input column names used by the model.\n    model : object\n        The underlying model object (e.g., sklearn, PyTorch, etc.).\n    \"\"\"\n\n    in_cols = []\n    model = None\n\n    def __init__(self, **kwargs):\n        \"\"\"\n        Initialize the model and capture initialization parameters.\n\n        Parameters\n        ----------\n        **kwargs : dict\n            Arbitrary keyword arguments passed during model initialization.\n        \"\"\"\n        self._init_params = self._get_init_params()\n\n    def fit(self, features: pd.DataFrame, labels: pd.DataFrame):\n        \"\"\"\n        Train the model using provided features and labels.\n\n        Parameters\n        ----------\n        features : pd.DataFrame\n            Input features for training.\n        labels : pd.DataFrame\n            Target labels for training.\n\n        Raises\n        ------\n        NotImplementedError\n            This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    def predict(self, data: pd.DataFrame) -&gt; np.ndarray:\n        \"\"\"\n        Generate predictions from the model for given input data.\n\n        Parameters\n        ----------\n        data : pd.DataFrame\n            Input features for prediction.\n\n        Returns\n        -------\n        np.ndarray\n            Model predictions.\n\n        Raises\n        ------\n        NotImplementedError\n            This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    def set_parameters_from_wrapper(self, wrapper: DataWrapper):\n        \"\"\"\n        Set model parameters based on the provided DataWrapper.\n\n        Parameters\n        ----------\n        wrapper : DataWrapper\n            A wrapper containing relevant configuration or metadata.\n        \"\"\"\n        pass\n\n    def reset_state(self):\n        \"\"\"\n        Reset the internal state of the model, if applicable.\n\n        Raises\n        ------\n        NotImplementedError\n            This method must be implemented by subclasses.\n        \"\"\"\n        raise NotImplementedError\n\n    def set_params(self, params: dict):\n        \"\"\"\n        Set parameters on the underlying model object.\n\n        Parameters\n        ----------\n        params : dict\n            Dictionary of parameter names and values to set.\n        \"\"\"\n        for key, value in params.items():\n            setattr(self.model, key, value)\n\n    def _get_init_params(self) -&gt; dict:\n        \"\"\"\n        Retrieve the constructor parameters of the model instance.\n\n        Uses introspection to get arguments passed to __init__, except 'self'.\n\n        Returns\n        -------\n        dict\n            Dictionary of parameter names and values.\n        \"\"\"\n        frame = inspect.currentframe()\n        init_args = inspect.getargvalues(frame.f_back)\n        params = {k: v for k, v in init_args.locals.items() if k != 'self'}\n        return params\n\n    def log_params(self) -&gt; None:\n        \"\"\"\n        Log the model's constructor parameters to MLflow using MLFlowTracker.\n\n        Raises\n        ------\n        RuntimeError\n            If MLFlowTracker has no active run.\n        \"\"\"\n        MLFlowTracker.log_params(self._init_params)\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initialize the model and capture initialization parameters.</p>"},{"location":"reference/base_model/#model.Model.Model.__init__--parameters","title":"Parameters","text":"<p>**kwargs : dict     Arbitrary keyword arguments passed during model initialization.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def __init__(self, **kwargs):\n    \"\"\"\n    Initialize the model and capture initialization parameters.\n\n    Parameters\n    ----------\n    **kwargs : dict\n        Arbitrary keyword arguments passed during model initialization.\n    \"\"\"\n    self._init_params = self._get_init_params()\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.fit","title":"<code>fit(features, labels)</code>","text":"<p>Train the model using provided features and labels.</p>"},{"location":"reference/base_model/#model.Model.Model.fit--parameters","title":"Parameters","text":"<p>features : pd.DataFrame     Input features for training. labels : pd.DataFrame     Target labels for training.</p>"},{"location":"reference/base_model/#model.Model.Model.fit--raises","title":"Raises","text":"<p>NotImplementedError     This method must be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def fit(self, features: pd.DataFrame, labels: pd.DataFrame):\n    \"\"\"\n    Train the model using provided features and labels.\n\n    Parameters\n    ----------\n    features : pd.DataFrame\n        Input features for training.\n    labels : pd.DataFrame\n        Target labels for training.\n\n    Raises\n    ------\n    NotImplementedError\n        This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.log_params","title":"<code>log_params()</code>","text":"<p>Log the model's constructor parameters to MLflow using MLFlowTracker.</p>"},{"location":"reference/base_model/#model.Model.Model.log_params--raises","title":"Raises","text":"<p>RuntimeError     If MLFlowTracker has no active run.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def log_params(self) -&gt; None:\n    \"\"\"\n    Log the model's constructor parameters to MLflow using MLFlowTracker.\n\n    Raises\n    ------\n    RuntimeError\n        If MLFlowTracker has no active run.\n    \"\"\"\n    MLFlowTracker.log_params(self._init_params)\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.predict","title":"<code>predict(data)</code>","text":"<p>Generate predictions from the model for given input data.</p>"},{"location":"reference/base_model/#model.Model.Model.predict--parameters","title":"Parameters","text":"<p>data : pd.DataFrame     Input features for prediction.</p>"},{"location":"reference/base_model/#model.Model.Model.predict--returns","title":"Returns","text":"<p>np.ndarray     Model predictions.</p>"},{"location":"reference/base_model/#model.Model.Model.predict--raises","title":"Raises","text":"<p>NotImplementedError     This method must be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def predict(self, data: pd.DataFrame) -&gt; np.ndarray:\n    \"\"\"\n    Generate predictions from the model for given input data.\n\n    Parameters\n    ----------\n    data : pd.DataFrame\n        Input features for prediction.\n\n    Returns\n    -------\n    np.ndarray\n        Model predictions.\n\n    Raises\n    ------\n    NotImplementedError\n        This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset the internal state of the model, if applicable.</p>"},{"location":"reference/base_model/#model.Model.Model.reset_state--raises","title":"Raises","text":"<p>NotImplementedError     This method must be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Reset the internal state of the model, if applicable.\n\n    Raises\n    ------\n    NotImplementedError\n        This method must be implemented by subclasses.\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.set_parameters_from_wrapper","title":"<code>set_parameters_from_wrapper(wrapper)</code>","text":"<p>Set model parameters based on the provided DataWrapper.</p>"},{"location":"reference/base_model/#model.Model.Model.set_parameters_from_wrapper--parameters","title":"Parameters","text":"<p>wrapper : DataWrapper     A wrapper containing relevant configuration or metadata.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def set_parameters_from_wrapper(self, wrapper: DataWrapper):\n    \"\"\"\n    Set model parameters based on the provided DataWrapper.\n\n    Parameters\n    ----------\n    wrapper : DataWrapper\n        A wrapper containing relevant configuration or metadata.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/base_model/#model.Model.Model.set_params","title":"<code>set_params(params)</code>","text":"<p>Set parameters on the underlying model object.</p>"},{"location":"reference/base_model/#model.Model.Model.set_params--parameters","title":"Parameters","text":"<p>params : dict     Dictionary of parameter names and values to set.</p> Source code in <code>sports_prediction_framework\\model\\Model.py</code> <pre><code>def set_params(self, params: dict):\n    \"\"\"\n    Set parameters on the underlying model object.\n\n    Parameters\n    ----------\n    params : dict\n        Dictionary of parameter names and values to set.\n    \"\"\"\n    for key, value in params.items():\n        setattr(self.model, key, value)\n</code></pre>"},{"location":"reference/data_selector/","title":"data_selector","text":""},{"location":"reference/data_selector/#transformer.DataSelector.DataSelector","title":"<code>DataSelector</code>","text":"<p>Manages synchronized updates across training and testing data scopes.</p> <p>DataSelector coordinates iteration over combinations of training and testing scopes, applying logic such as updating, validation (<code>holds()</code>), and resetting of state. It serves as a unified interface to handle these paired scopes and traverse all valid combinations recursively, even when the number of scopes differs.</p> <p>Attributes:</p> Name Type Description <code>train_selectors</code> <code>list[ScopeSelector]</code> <p>List of training data scope selectors.</p> <code>test_selectors</code> <code>list[ScopeSelector]</code> <p>List of testing data scope selectors.</p> <code>max_index</code> <code>int</code> <p>The maximum number of selectors among train/test.</p> <code>selector_index</code> <code>int</code> <p>The current index of the selector being updated.</p> Source code in <code>sports_prediction_framework\\transformer\\DataSelector.py</code> <pre><code>class DataSelector:\n    \"\"\"\n    Manages synchronized updates across training and testing data scopes.\n\n    DataSelector coordinates iteration over combinations of training and testing\n    scopes, applying logic such as updating, validation (`holds()`), and resetting\n    of state. It serves as a unified interface to handle these paired scopes and\n    traverse all valid combinations recursively, even when the number of scopes differs.\n\n    Attributes:\n        train_selectors (list[ScopeSelector]): List of training data scope selectors.\n        test_selectors (list[ScopeSelector]): List of testing data scope selectors.\n        max_index (int): The maximum number of selectors among train/test.\n        selector_index (int): The current index of the selector being updated.\n    \"\"\"\n\n    train_selectors = [Scope]\n    test_selectors = [Scope]\n\n    def __init__(self, train_selectors: [ScopeSelector] = [], test_selectors: [ScopeSelector] = [],\n                 wrapper: DataWrapper = None):\n        self.train_selectors = train_selectors\n        self.test_selectors = test_selectors\n        self.max_index = max(len(train_selectors), len(test_selectors))\n        self.selector_index = self.max_index - 1\n\n\n    def holds(self):\n        if self.selector_index &lt; 0 or (self.train_selectors and not self.train_selectors[0].holds()) or \\\n                (self.test_selectors and not self.test_selectors[0].holds()):\n            return False\n        return True\n\n    def update(self):\n        \"\"\"\n        Recursively updates training and testing scopes in a synchronized way.\n\n        This method performs a backtracking traversal through all valid combinations\n        of training and testing scopes, calling `update()` on each scope pair and\n        ensuring both satisfy their `holds()` condition. If a combination fails, it\n        resets the scopes and backtracks to try other possibilities.\n\n        Handles cases where the number of training and testing scopes differs, enabling\n        distinct granularity in data iteration.\n\n        Iteration begins at the last scope and progresses through all valid configurations.\n        \"\"\"\n        if not self.holds():\n            return\n        if self.selector_index == self.max_index:\n            self.selector_index -= 1\n        train_scope = None\n        test_scope = None\n        if self.selector_index &lt; len(self.train_selectors):\n            train_scope = self.train_selectors[self.selector_index]\n            train_scope.update()\n        if self.selector_index &lt; len(self.test_selectors):\n            test_scope = self.test_selectors[self.selector_index]\n            test_scope.update()\n        if (train_scope is None or train_scope.holds()) and (test_scope is None or test_scope.holds()):\n            self.selector_index += 1\n        else:\n            if train_scope is not None:\n                train_scope.reset_state()\n            if test_scope is not None:\n                test_scope.reset_state()\n            self.selector_index -= 1\n            self.update()\n\n\n    def transform_wrapper(self, wrapper: DataWrapper, selectors: [ScopeSelector]):\n        wrapper_trans = wrapper\n        for selector in selectors:\n            wrapper_trans = selector.transform(wrapper_trans)\n# Used only for informative purposes. TO BE IMPLEMENTED or REMOVED\n            #cur = selector.current_state()\n            #wrapper_trans.current_selection[cur[0]] = cur[1]\n        return wrapper_trans\n\n    def transform_test(self, wrapper: DataWrapper):\n        return self.transform_wrapper(wrapper, self.test_selectors)\n\n    def transform_train(self, wrapper: DataWrapper):\n        return self.transform_wrapper(wrapper, self.train_selectors)\n\n    def reset_state(self):\n        self.selector_index = self.max_index - 1\n        for selector in self.train_selectors:\n            selector.reset_state()\n</code></pre>"},{"location":"reference/data_selector/#transformer.DataSelector.DataSelector.update","title":"<code>update()</code>","text":"<p>Recursively updates training and testing scopes in a synchronized way.</p> <p>This method performs a backtracking traversal through all valid combinations of training and testing scopes, calling <code>update()</code> on each scope pair and ensuring both satisfy their <code>holds()</code> condition. If a combination fails, it resets the scopes and backtracks to try other possibilities.</p> <p>Handles cases where the number of training and testing scopes differs, enabling distinct granularity in data iteration.</p> <p>Iteration begins at the last scope and progresses through all valid configurations.</p> Source code in <code>sports_prediction_framework\\transformer\\DataSelector.py</code> <pre><code>def update(self):\n    \"\"\"\n    Recursively updates training and testing scopes in a synchronized way.\n\n    This method performs a backtracking traversal through all valid combinations\n    of training and testing scopes, calling `update()` on each scope pair and\n    ensuring both satisfy their `holds()` condition. If a combination fails, it\n    resets the scopes and backtracks to try other possibilities.\n\n    Handles cases where the number of training and testing scopes differs, enabling\n    distinct granularity in data iteration.\n\n    Iteration begins at the last scope and progresses through all valid configurations.\n    \"\"\"\n    if not self.holds():\n        return\n    if self.selector_index == self.max_index:\n        self.selector_index -= 1\n    train_scope = None\n    test_scope = None\n    if self.selector_index &lt; len(self.train_selectors):\n        train_scope = self.train_selectors[self.selector_index]\n        train_scope.update()\n    if self.selector_index &lt; len(self.test_selectors):\n        test_scope = self.test_selectors[self.selector_index]\n        test_scope.update()\n    if (train_scope is None or train_scope.holds()) and (test_scope is None or test_scope.holds()):\n        self.selector_index += 1\n    else:\n        if train_scope is not None:\n            train_scope.reset_state()\n        if test_scope is not None:\n            test_scope.reset_state()\n        self.selector_index -= 1\n        self.update()\n</code></pre>"},{"location":"reference/dataloader/","title":"dataloader","text":""},{"location":"reference/dataloader/#dataloader.Connector.Connector","title":"<code>Connector</code>","text":"<p>Manages connection to a PostgreSQL database, optionally through an SSH tunnel.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>class Connector:\n    \"\"\"\n    Manages connection to a PostgreSQL database, optionally through an SSH tunnel.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the Connector by loading configuration values from a .env file.\n        \"\"\"\n        self.config = dotenv_values(dotenv_path)\n\n    def connect_to_db(self):\n        \"\"\"\n        Establishes a direct connection to the PostgreSQL database using SQLAlchemy.\n        Creates an engine and a session for interacting with the database.\n        \"\"\"\n        try:\n            self.eng = create_engine(f'postgresql+psycopg2://{self.config[\"DB_USER\"]}:{self.config[\"DB_PASSWORD\"]}@127.0.0.1:5433/{self.config[\"DB_NAME\"]}')\n            session_func = sessionmaker(bind=self.eng)\n            self.session = session_func()\n            print(\"Connected to database\")\n        except Exception as e:\n            print(\"Connection to database failed.\")\n\n    def connect_to_db_via_ssh(self):\n        \"\"\"\n        Establishes an SSH tunnel to the remote host and connects to the database through the tunnel.\n        Starts the tunnel and calls `connect_to_db()` for the actual database connection.\n        \"\"\"\n        try:\n            # Establish SSH tunnel\n            self.tunnel = SSHTunnelForwarder(\n                (self.config['SSH_HOST'], 22),  # SSH server and port\n                ssh_username=self.config['SSH_USER'],\n                ssh_pkey=self.config['SSH_KEY_PATH'],\n                remote_bind_address=(self.config['DB_HOST'], int(self.config['DB_PORT'])),  # Remote database address\n                local_bind_address=('127.0.0.1', 5433)  # Local forwarding\n            )\n\n            self.tunnel.start()\n\n            self.connect_to_db()\n        except Exception as e:\n            pass\n\n    def close(self):\n        \"\"\"\n        Closes the SSH tunnel (if open), the database session, and disposes of the SQLAlchemy engine.\n        \"\"\"\n        self.tunnel.stop()\n        self.session.close()\n        self.eng.dispose()\n\n    def get_engine(self):\n        \"\"\"\n        Returns the SQLAlchemy engine object.\n\n        Returns:\n            sqlalchemy.engine.Engine: The SQLAlchemy engine connected to the database.\n        \"\"\"\n        return self.eng\n</code></pre>"},{"location":"reference/dataloader/#dataloader.Connector.Connector.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the Connector by loading configuration values from a .env file.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the Connector by loading configuration values from a .env file.\n    \"\"\"\n    self.config = dotenv_values(dotenv_path)\n</code></pre>"},{"location":"reference/dataloader/#dataloader.Connector.Connector.close","title":"<code>close()</code>","text":"<p>Closes the SSH tunnel (if open), the database session, and disposes of the SQLAlchemy engine.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>def close(self):\n    \"\"\"\n    Closes the SSH tunnel (if open), the database session, and disposes of the SQLAlchemy engine.\n    \"\"\"\n    self.tunnel.stop()\n    self.session.close()\n    self.eng.dispose()\n</code></pre>"},{"location":"reference/dataloader/#dataloader.Connector.Connector.connect_to_db","title":"<code>connect_to_db()</code>","text":"<p>Establishes a direct connection to the PostgreSQL database using SQLAlchemy. Creates an engine and a session for interacting with the database.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>def connect_to_db(self):\n    \"\"\"\n    Establishes a direct connection to the PostgreSQL database using SQLAlchemy.\n    Creates an engine and a session for interacting with the database.\n    \"\"\"\n    try:\n        self.eng = create_engine(f'postgresql+psycopg2://{self.config[\"DB_USER\"]}:{self.config[\"DB_PASSWORD\"]}@127.0.0.1:5433/{self.config[\"DB_NAME\"]}')\n        session_func = sessionmaker(bind=self.eng)\n        self.session = session_func()\n        print(\"Connected to database\")\n    except Exception as e:\n        print(\"Connection to database failed.\")\n</code></pre>"},{"location":"reference/dataloader/#dataloader.Connector.Connector.connect_to_db_via_ssh","title":"<code>connect_to_db_via_ssh()</code>","text":"<p>Establishes an SSH tunnel to the remote host and connects to the database through the tunnel. Starts the tunnel and calls <code>connect_to_db()</code> for the actual database connection.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>def connect_to_db_via_ssh(self):\n    \"\"\"\n    Establishes an SSH tunnel to the remote host and connects to the database through the tunnel.\n    Starts the tunnel and calls `connect_to_db()` for the actual database connection.\n    \"\"\"\n    try:\n        # Establish SSH tunnel\n        self.tunnel = SSHTunnelForwarder(\n            (self.config['SSH_HOST'], 22),  # SSH server and port\n            ssh_username=self.config['SSH_USER'],\n            ssh_pkey=self.config['SSH_KEY_PATH'],\n            remote_bind_address=(self.config['DB_HOST'], int(self.config['DB_PORT'])),  # Remote database address\n            local_bind_address=('127.0.0.1', 5433)  # Local forwarding\n        )\n\n        self.tunnel.start()\n\n        self.connect_to_db()\n    except Exception as e:\n        pass\n</code></pre>"},{"location":"reference/dataloader/#dataloader.Connector.Connector.get_engine","title":"<code>get_engine()</code>","text":"<p>Returns the SQLAlchemy engine object.</p> <p>Returns:</p> Type Description <p>sqlalchemy.engine.Engine: The SQLAlchemy engine connected to the database.</p> Source code in <code>sports_prediction_framework\\dataloader\\Connector.py</code> <pre><code>def get_engine(self):\n    \"\"\"\n    Returns the SQLAlchemy engine object.\n\n    Returns:\n        sqlalchemy.engine.Engine: The SQLAlchemy engine connected to the database.\n    \"\"\"\n    return self.eng\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource","title":"<code>DataSource</code>","text":"<p>Provides an interface for querying a PostgreSQL database with optional parsing based on sport type. Can connect either directly or via SSH tunneling and supports multiple query types.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>class DataSource:\n    \"\"\"\n    Provides an interface for querying a PostgreSQL database with optional parsing based on sport type.\n    Can connect either directly or via SSH tunneling and supports multiple query types.\n    \"\"\"\n\n    def __init__(self, sport_type: SportType = None, via_ssh=True):\n        \"\"\"\n        Initializes the DataSource and establishes a database connection.\n\n        Args:\n            sport_type (SportType, optional): If provided, sets up a parser specific to the sport.\n            via_ssh (bool): If True, establishes the connection through SSH tunneling.\n        \"\"\"\n        self.con = Connector()\n        self.db_type = self.con.config['DB_NAME']\n\n        if sport_type is not None:\n            self.parser = sport_type.get_parser()()\n\n        if via_ssh:\n            self.con.connect_to_db_via_ssh()\n        else:\n            self.con.connect_to_db()\n\n    def plain_query(self, query: str) -&gt; pd.DataFrame:\n        \"\"\"\n        Executes a raw SQL query directly.\n        WARNING: This method does not sanitize inputs and is vulnerable to SQL injection. Use with caution.\n\n        Args:\n            query (str): Raw SQL query string.\n\n        Returns:\n            pd.DataFrame: Query results.\n        \"\"\"\n        return pd.read_sql_query(query, con=self.con.get_engine())\n\n    def parse_data(self, df: pd.DataFrame):\n        \"\"\"\n        Parses the DataFrame according to the parser configured for the current database type.\n\n        Args:\n            df (pd.DataFrame): Raw query results.\n\n        Returns:\n            pd.DataFrame: Parsed DataFrame.\n        \"\"\"\n        match self.db_type:\n            case \"bet\":\n                return self.parser.parse_isdb(df)\n            case \"flashscore\":\n                return self.parser.parse_flashscore(df)\n            case \"betexplorer\":\n                return self.parser.parse_betexplorer(df)\n            case _:\n                return df\n\n    def query(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n        \"\"\"\n        Executes a filtered SQL query and parses the result based on the database type.\n\n        Args:\n            schema_name (str): Schema name.\n            table_name (str): Table name.\n            filter_func (Callable): Filter function to apply on table columns.\n\n        Returns:\n            pd.DataFrame: Parsed query result.\n        \"\"\"\n        metadata = MetaData(schema=schema_name)\n        table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n        query = select(table).filter(filter_func(table.c))\n        df = pd.read_sql(query, self.con.session.bind)\n        return self.parse_data(df)\n\n    def query_no_parse(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n        \"\"\"\n        Executes a filtered SQL query without parsing the result.\n\n        Args:\n            schema_name (str): Schema name.\n            table_name (str): Table name.\n            filter_func (Callable): Filter function to apply on table columns.\n\n        Returns:\n            pd.DataFrame: Raw query result.\n        \"\"\"\n        metadata = MetaData(schema=schema_name)\n        table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n        query = select(table).filter(filter_func(table.c))\n        df = pd.read_sql(query, self.con.session.bind)\n        return df\n\n    def preview_query(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n        \"\"\"\n        Retrieves a limited preview (5 rows) of the query results.\n\n        Args:\n            schema_name (str): Schema name.\n            table_name (str): Table name.\n            filter_func (Callable): Filter function to apply on table columns.\n\n        Returns:\n            pd.DataFrame: Preview of the query result.\n        \"\"\"\n        metadata = MetaData(schema=schema_name)\n        table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n        query = select(table).filter(filter_func(table.c)).limit(5)\n        df = pd.read_sql(query, self.con.session.bind)\n        return df\n\n    def query_distinct(self, schema_name, table_name, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n        \"\"\"\n        Executes a query that returns distinct rows based on specified columns.\n\n        WARNING: This uses PostgreSQL-specific `DISTINCT ON` functionality.\n\n        Args:\n            schema_name (str): Schema name.\n            table_name (str): Table name.\n            filter_func (Callable): Filter function to apply on table columns.\n            distinct_cols (list, optional): Columns to apply DISTINCT ON.\n\n        Returns:\n            pd.DataFrame: Resulting DataFrame with distinct rows.\n        \"\"\"\n        metadata = MetaData(schema=schema_name)\n        table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n\n        if distinct_cols:\n            query = select(table).distinct(*[table.c[col] for col in distinct_cols]).filter(filter_func(table.c))\n        else:\n            query = select(table).filter(filter_func(table.c))\n\n        df = pd.read_sql(query, self.con.session.bind)\n        return df\n\n    def close(self):\n        \"\"\"\n        Closes the database session and SSH tunnel (if used).\n        \"\"\"\n        self.con.close()\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.__init__","title":"<code>__init__(sport_type=None, via_ssh=True)</code>","text":"<p>Initializes the DataSource and establishes a database connection.</p> <p>Parameters:</p> Name Type Description Default <code>sport_type</code> <code>SportType</code> <p>If provided, sets up a parser specific to the sport.</p> <code>None</code> <code>via_ssh</code> <code>bool</code> <p>If True, establishes the connection through SSH tunneling.</p> <code>True</code> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def __init__(self, sport_type: SportType = None, via_ssh=True):\n    \"\"\"\n    Initializes the DataSource and establishes a database connection.\n\n    Args:\n        sport_type (SportType, optional): If provided, sets up a parser specific to the sport.\n        via_ssh (bool): If True, establishes the connection through SSH tunneling.\n    \"\"\"\n    self.con = Connector()\n    self.db_type = self.con.config['DB_NAME']\n\n    if sport_type is not None:\n        self.parser = sport_type.get_parser()()\n\n    if via_ssh:\n        self.con.connect_to_db_via_ssh()\n    else:\n        self.con.connect_to_db()\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.close","title":"<code>close()</code>","text":"<p>Closes the database session and SSH tunnel (if used).</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def close(self):\n    \"\"\"\n    Closes the database session and SSH tunnel (if used).\n    \"\"\"\n    self.con.close()\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.parse_data","title":"<code>parse_data(df)</code>","text":"<p>Parses the DataFrame according to the parser configured for the current database type.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Raw query results.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: Parsed DataFrame.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def parse_data(self, df: pd.DataFrame):\n    \"\"\"\n    Parses the DataFrame according to the parser configured for the current database type.\n\n    Args:\n        df (pd.DataFrame): Raw query results.\n\n    Returns:\n        pd.DataFrame: Parsed DataFrame.\n    \"\"\"\n    match self.db_type:\n        case \"bet\":\n            return self.parser.parse_isdb(df)\n        case \"flashscore\":\n            return self.parser.parse_flashscore(df)\n        case \"betexplorer\":\n            return self.parser.parse_betexplorer(df)\n        case _:\n            return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.plain_query","title":"<code>plain_query(query)</code>","text":"<p>Executes a raw SQL query directly. WARNING: This method does not sanitize inputs and is vulnerable to SQL injection. Use with caution.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>Raw SQL query string.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Query results.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def plain_query(self, query: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Executes a raw SQL query directly.\n    WARNING: This method does not sanitize inputs and is vulnerable to SQL injection. Use with caution.\n\n    Args:\n        query (str): Raw SQL query string.\n\n    Returns:\n        pd.DataFrame: Query results.\n    \"\"\"\n    return pd.read_sql_query(query, con=self.con.get_engine())\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.preview_query","title":"<code>preview_query(schema_name, table_name, filter_func)</code>","text":"<p>Retrieves a limited preview (5 rows) of the query results.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name.</p> required <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>filter_func</code> <code>Callable</code> <p>Filter function to apply on table columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Preview of the query result.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def preview_query(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n    \"\"\"\n    Retrieves a limited preview (5 rows) of the query results.\n\n    Args:\n        schema_name (str): Schema name.\n        table_name (str): Table name.\n        filter_func (Callable): Filter function to apply on table columns.\n\n    Returns:\n        pd.DataFrame: Preview of the query result.\n    \"\"\"\n    metadata = MetaData(schema=schema_name)\n    table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n    query = select(table).filter(filter_func(table.c)).limit(5)\n    df = pd.read_sql(query, self.con.session.bind)\n    return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.query","title":"<code>query(schema_name, table_name, filter_func)</code>","text":"<p>Executes a filtered SQL query and parses the result based on the database type.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name.</p> required <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>filter_func</code> <code>Callable</code> <p>Filter function to apply on table columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Parsed query result.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def query(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n    \"\"\"\n    Executes a filtered SQL query and parses the result based on the database type.\n\n    Args:\n        schema_name (str): Schema name.\n        table_name (str): Table name.\n        filter_func (Callable): Filter function to apply on table columns.\n\n    Returns:\n        pd.DataFrame: Parsed query result.\n    \"\"\"\n    metadata = MetaData(schema=schema_name)\n    table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n    query = select(table).filter(filter_func(table.c))\n    df = pd.read_sql(query, self.con.session.bind)\n    return self.parse_data(df)\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.query_distinct","title":"<code>query_distinct(schema_name, table_name, filter_func, distinct_cols=None)</code>","text":"<p>Executes a query that returns distinct rows based on specified columns.</p> <p>WARNING: This uses PostgreSQL-specific <code>DISTINCT ON</code> functionality.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name.</p> required <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>filter_func</code> <code>Callable</code> <p>Filter function to apply on table columns.</p> required <code>distinct_cols</code> <code>list</code> <p>Columns to apply DISTINCT ON.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Resulting DataFrame with distinct rows.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def query_distinct(self, schema_name, table_name, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n    \"\"\"\n    Executes a query that returns distinct rows based on specified columns.\n\n    WARNING: This uses PostgreSQL-specific `DISTINCT ON` functionality.\n\n    Args:\n        schema_name (str): Schema name.\n        table_name (str): Table name.\n        filter_func (Callable): Filter function to apply on table columns.\n        distinct_cols (list, optional): Columns to apply DISTINCT ON.\n\n    Returns:\n        pd.DataFrame: Resulting DataFrame with distinct rows.\n    \"\"\"\n    metadata = MetaData(schema=schema_name)\n    table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n\n    if distinct_cols:\n        query = select(table).distinct(*[table.c[col] for col in distinct_cols]).filter(filter_func(table.c))\n    else:\n        query = select(table).filter(filter_func(table.c))\n\n    df = pd.read_sql(query, self.con.session.bind)\n    return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataSource.DataSource.query_no_parse","title":"<code>query_no_parse(schema_name, table_name, filter_func)</code>","text":"<p>Executes a filtered SQL query without parsing the result.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Schema name.</p> required <code>table_name</code> <code>str</code> <p>Table name.</p> required <code>filter_func</code> <code>Callable</code> <p>Filter function to apply on table columns.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Raw query result.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataSource.py</code> <pre><code>def query_no_parse(self, schema_name, table_name, filter_func) -&gt; pd.DataFrame:\n    \"\"\"\n    Executes a filtered SQL query without parsing the result.\n\n    Args:\n        schema_name (str): Schema name.\n        table_name (str): Table name.\n        filter_func (Callable): Filter function to apply on table columns.\n\n    Returns:\n        pd.DataFrame: Raw query result.\n    \"\"\"\n    metadata = MetaData(schema=schema_name)\n    table = Table(table_name, metadata, autoload_with=self.con.eng, schema=schema_name)\n    query = select(table).filter(filter_func(table.c))\n    df = pd.read_sql(query, self.con.session.bind)\n    return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader","title":"<code>DataLoader</code>","text":"<p>A utility class for loading and wrapping data from a database using the DataSource and DataHandler interfaces. Provides class methods for querying, previewing, and post-processing data.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>class DataLoader:\n    \"\"\"\n    A utility class for loading and wrapping data from a database using the DataSource and DataHandler interfaces.\n    Provides class methods for querying, previewing, and post-processing data.\n    \"\"\"\n\n    @classmethod\n    def load(cls, schema_name: str, table_name: str, filter_func) -&gt; pd.DataFrame:\n        \"\"\"\n        Loads a DataFrame from the specified schema and table using a filter function.\n\n        Args:\n            schema_name (str): Name of the schema in the database.\n            table_name (str): Name of the table to query.\n            filter_func (Callable): A function used to filter the query.\n\n        Returns:\n            pd.DataFrame: The resulting DataFrame from the query.\n        \"\"\"\n        ds = DataSource()\n        df = ds.query(schema_name, table_name, filter_func)\n        ds.close()\n        return df\n\n    @classmethod\n    def load_distinct(cls, schema_name: str, table_name: str, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n        \"\"\"\n        Loads a DataFrame from the specified schema and table, optionally using distinct columns.\n\n        Args:\n            schema_name (str): Name of the schema in the database.\n            table_name (str): Name of the table to query.\n            filter_func (Callable): A function used to filter the query.\n            distinct_cols (list, optional): Columns to apply distinct selection on.\n\n        Returns:\n            pd.DataFrame: The resulting DataFrame from the query.\n        \"\"\"\n        ds = DataSource()\n        df = ds.query(schema_name, table_name, filter_func)\n        ds.close()\n        return df\n\n    @classmethod\n    def preview(cls, schema_name: str, table_name: str, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n        \"\"\"\n        Loads a preview of the data using the preview_query method.\n\n        Args:\n            schema_name (str): Name of the schema in the database.\n            table_name (str): Name of the table to preview.\n            filter_func (Callable): A function used to filter the query.\n            distinct_cols (list, optional): Columns to apply distinct selection on.\n\n        Returns:\n            pd.DataFrame: A preview of the data.\n        \"\"\"\n        ds = DataSource()\n        df = ds.preview_query(schema_name, table_name, filter_func)\n        ds.close()\n        return df\n\n    @classmethod\n    def load_and_wrap(cls, schema_name, table_name, filter_func, sport: SportType = None):\n        \"\"\"\n        Loads data from the database and wraps it using the appropriate wrapper for the specified sport.\n\n        Args:\n            schema_name (str): Name of the schema.\n            table_name (str): Name of the table.\n            filter_func (Callable): A function used to filter the query.\n            sport (SportType, optional): The sport type which determines the data wrapper to use.\n\n        Returns:\n            DataWrapper: A wrapped handler containing the queried data.\n        \"\"\"\n        ds = DataSource(sport)\n        df = ds.query(schema_name, table_name, filter_func)\n        handler = DataHandler(df)\n        wrapper = sport.get_wrapper()(handler)\n        ds.close()\n\n        return wrapper\n\n    @classmethod\n    def load_and_wrap_odds(cls, schema_name, table_name, filter_func, sport: SportType = None, bookmaker=None):\n        \"\"\"\n        Loads match data along with corresponding betting odds and wraps it for the given sport.\n\n        Args:\n            schema_name (str): Name of the schema.\n            table_name (str): Name of the match data table.\n            filter_func (Callable): A function used to filter the match data.\n            sport (SportType, optional): The sport type which determines the data wrapper to use.\n            bookmaker (str, optional): The bookmaker name used to filter the odds table.\n\n        Returns:\n            DataWrapper: A wrapped handler containing the match and betting odds data.\n        \"\"\"\n        ds = DataSource(sport)\n        df = ds.query(schema_name, table_name, filter_func)\n\n        bookie_func = lambda c: c.Bookmaker == bookmaker\n        bets = ds.query_no_parse(schema_name, \"Odds_1x2\", bookie_func)\n        bets = bets.rename(columns={\"1\": \"odds_1\", \"X\": \"odds_X\", \"2\": \"odds_2\"})\n\n        cols_to_join = [\"MatchID\", \"odds_1\", \"odds_X\", \"odds_2\"]\n        odds_subset = bets[cols_to_join]\n        df = df.merge(odds_subset, on=\"MatchID\", how=\"inner\")\n        df[[\"odds_1\", \"odds_X\", \"odds_2\"]] = df[[\"odds_1\", \"odds_X\", \"odds_2\"]].apply(pd.to_numeric, errors='coerce')\n\n        handler = DataHandler(df)\n        wrapper = sport.get_wrapper()(handler)\n        ds.close()\n\n        return wrapper\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader.load","title":"<code>load(schema_name, table_name, filter_func)</code>  <code>classmethod</code>","text":"<p>Loads a DataFrame from the specified schema and table using a filter function.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema in the database.</p> required <code>table_name</code> <code>str</code> <p>Name of the table to query.</p> required <code>filter_func</code> <code>Callable</code> <p>A function used to filter the query.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The resulting DataFrame from the query.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>@classmethod\ndef load(cls, schema_name: str, table_name: str, filter_func) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads a DataFrame from the specified schema and table using a filter function.\n\n    Args:\n        schema_name (str): Name of the schema in the database.\n        table_name (str): Name of the table to query.\n        filter_func (Callable): A function used to filter the query.\n\n    Returns:\n        pd.DataFrame: The resulting DataFrame from the query.\n    \"\"\"\n    ds = DataSource()\n    df = ds.query(schema_name, table_name, filter_func)\n    ds.close()\n    return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader.load_and_wrap","title":"<code>load_and_wrap(schema_name, table_name, filter_func, sport=None)</code>  <code>classmethod</code>","text":"<p>Loads data from the database and wraps it using the appropriate wrapper for the specified sport.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema.</p> required <code>table_name</code> <code>str</code> <p>Name of the table.</p> required <code>filter_func</code> <code>Callable</code> <p>A function used to filter the query.</p> required <code>sport</code> <code>SportType</code> <p>The sport type which determines the data wrapper to use.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataWrapper</code> <p>A wrapped handler containing the queried data.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>@classmethod\ndef load_and_wrap(cls, schema_name, table_name, filter_func, sport: SportType = None):\n    \"\"\"\n    Loads data from the database and wraps it using the appropriate wrapper for the specified sport.\n\n    Args:\n        schema_name (str): Name of the schema.\n        table_name (str): Name of the table.\n        filter_func (Callable): A function used to filter the query.\n        sport (SportType, optional): The sport type which determines the data wrapper to use.\n\n    Returns:\n        DataWrapper: A wrapped handler containing the queried data.\n    \"\"\"\n    ds = DataSource(sport)\n    df = ds.query(schema_name, table_name, filter_func)\n    handler = DataHandler(df)\n    wrapper = sport.get_wrapper()(handler)\n    ds.close()\n\n    return wrapper\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader.load_and_wrap_odds","title":"<code>load_and_wrap_odds(schema_name, table_name, filter_func, sport=None, bookmaker=None)</code>  <code>classmethod</code>","text":"<p>Loads match data along with corresponding betting odds and wraps it for the given sport.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema.</p> required <code>table_name</code> <code>str</code> <p>Name of the match data table.</p> required <code>filter_func</code> <code>Callable</code> <p>A function used to filter the match data.</p> required <code>sport</code> <code>SportType</code> <p>The sport type which determines the data wrapper to use.</p> <code>None</code> <code>bookmaker</code> <code>str</code> <p>The bookmaker name used to filter the odds table.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>DataWrapper</code> <p>A wrapped handler containing the match and betting odds data.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>@classmethod\ndef load_and_wrap_odds(cls, schema_name, table_name, filter_func, sport: SportType = None, bookmaker=None):\n    \"\"\"\n    Loads match data along with corresponding betting odds and wraps it for the given sport.\n\n    Args:\n        schema_name (str): Name of the schema.\n        table_name (str): Name of the match data table.\n        filter_func (Callable): A function used to filter the match data.\n        sport (SportType, optional): The sport type which determines the data wrapper to use.\n        bookmaker (str, optional): The bookmaker name used to filter the odds table.\n\n    Returns:\n        DataWrapper: A wrapped handler containing the match and betting odds data.\n    \"\"\"\n    ds = DataSource(sport)\n    df = ds.query(schema_name, table_name, filter_func)\n\n    bookie_func = lambda c: c.Bookmaker == bookmaker\n    bets = ds.query_no_parse(schema_name, \"Odds_1x2\", bookie_func)\n    bets = bets.rename(columns={\"1\": \"odds_1\", \"X\": \"odds_X\", \"2\": \"odds_2\"})\n\n    cols_to_join = [\"MatchID\", \"odds_1\", \"odds_X\", \"odds_2\"]\n    odds_subset = bets[cols_to_join]\n    df = df.merge(odds_subset, on=\"MatchID\", how=\"inner\")\n    df[[\"odds_1\", \"odds_X\", \"odds_2\"]] = df[[\"odds_1\", \"odds_X\", \"odds_2\"]].apply(pd.to_numeric, errors='coerce')\n\n    handler = DataHandler(df)\n    wrapper = sport.get_wrapper()(handler)\n    ds.close()\n\n    return wrapper\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader.load_distinct","title":"<code>load_distinct(schema_name, table_name, filter_func, distinct_cols=None)</code>  <code>classmethod</code>","text":"<p>Loads a DataFrame from the specified schema and table, optionally using distinct columns.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema in the database.</p> required <code>table_name</code> <code>str</code> <p>Name of the table to query.</p> required <code>filter_func</code> <code>Callable</code> <p>A function used to filter the query.</p> required <code>distinct_cols</code> <code>list</code> <p>Columns to apply distinct selection on.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: The resulting DataFrame from the query.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>@classmethod\ndef load_distinct(cls, schema_name: str, table_name: str, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads a DataFrame from the specified schema and table, optionally using distinct columns.\n\n    Args:\n        schema_name (str): Name of the schema in the database.\n        table_name (str): Name of the table to query.\n        filter_func (Callable): A function used to filter the query.\n        distinct_cols (list, optional): Columns to apply distinct selection on.\n\n    Returns:\n        pd.DataFrame: The resulting DataFrame from the query.\n    \"\"\"\n    ds = DataSource()\n    df = ds.query(schema_name, table_name, filter_func)\n    ds.close()\n    return df\n</code></pre>"},{"location":"reference/dataloader/#dataloader.DataLoader.DataLoader.preview","title":"<code>preview(schema_name, table_name, filter_func, distinct_cols=None)</code>  <code>classmethod</code>","text":"<p>Loads a preview of the data using the preview_query method.</p> <p>Parameters:</p> Name Type Description Default <code>schema_name</code> <code>str</code> <p>Name of the schema in the database.</p> required <code>table_name</code> <code>str</code> <p>Name of the table to preview.</p> required <code>filter_func</code> <code>Callable</code> <p>A function used to filter the query.</p> required <code>distinct_cols</code> <code>list</code> <p>Columns to apply distinct selection on.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A preview of the data.</p> Source code in <code>sports_prediction_framework\\dataloader\\DataLoader.py</code> <pre><code>@classmethod\ndef preview(cls, schema_name: str, table_name: str, filter_func, distinct_cols=None) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads a preview of the data using the preview_query method.\n\n    Args:\n        schema_name (str): Name of the schema in the database.\n        table_name (str): Name of the table to preview.\n        filter_func (Callable): A function used to filter the query.\n        distinct_cols (list, optional): Columns to apply distinct selection on.\n\n    Returns:\n        pd.DataFrame: A preview of the data.\n    \"\"\"\n    ds = DataSource()\n    df = ds.preview_query(schema_name, table_name, filter_func)\n    ds.close()\n    return df\n</code></pre>"},{"location":"reference/datawrapper_advanced/","title":"Advanced wrappers","text":""},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper","title":"<code>MatchWrapper</code>","text":"<p>               Bases: <code>DataWrapper</code></p> <p>Specialized wrapper for match-based data. Inherits from <code>DataWrapper</code> and provides additional functionality specific to sports matches.</p> <p>Attributes:</p> Name Type Description <code>name_columns</code> <code>list[str]</code> <p>Columns indicating team names (e.g., Home, Away).</p> <code>name_id_columns</code> <code>list[str]</code> <p>Columns indicating team IDs (e.g., HID, AID).</p> <code>score_columns</code> <code>list[str]</code> <p>Columns indicating match scores (e.g., HS, AS).</p> <code>result_column</code> <code>list[str]</code> <p>Column containing match results (e.g., WDL).</p> <code>prediction_columns</code> <code>list[int]</code> <p>Prediction column labels corresponding to match outcomes.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>class MatchWrapper(DataWrapper):\n    \"\"\"\n    Specialized wrapper for match-based data. Inherits from `DataWrapper` and provides\n    additional functionality specific to sports matches.\n\n    Attributes:\n        name_columns (list[str]): Columns indicating team names (e.g., Home, Away).\n        name_id_columns (list[str]): Columns indicating team IDs (e.g., HID, AID).\n        score_columns (list[str]): Columns indicating match scores (e.g., HS, AS).\n        result_column (list[str]): Column containing match results (e.g., WDL).\n        prediction_columns (list[int]): Prediction column labels corresponding to match outcomes.\n    \"\"\"\n\n    name_columns = ['Home', 'Away']\n    name_id_columns = ['HID', 'AID']\n    score_columns = ['HS', 'AS']\n    result_column = ['WDL']\n    prediction_columns = [1, 0, 2]\n    odds_columns = ['odds_1',  'odds_X',  'odds_2']\n\n    def __init__(self, data_handler: DataHandler, home_advantage):\n        \"\"\"\n        Initialize a MatchWrapper.\n\n        Args:\n            data_handler (DataHandler): Object that holds and manages the match DataFrame.\n            home_advantage (Any): Information or value to apply a home advantage modifier.\n        \"\"\"\n        super().__init__(data_handler, home_advantage)\n        self.total_set_of_teams = self.get_set_of_teams()\n        self.total_number_of_teams = len(self.total_set_of_teams)\n        self.total_set_of_teams_ids = set()\n\n\n    def __str__(self):\n        # All column groups combined\n        column_groups = (\n            ['Date']+\n            self.name_columns +\n            self.name_id_columns +\n            self.score_columns +\n            self.result_column +\n            self.odds_columns +\n            self.prediction_columns\n\n\n        )\n\n        # Filter only existing columns\n        existing_columns = [col for col in column_groups if col in self.get_dataframe().columns]\n\n        if not existing_columns:\n            return \"No matching columns found.\"\n\n        return str(self.get_dataframe()[existing_columns])\n\n    def set_after_compute_values(self):\n        \"\"\"\n        Recomputes and updates the total set and number of teams\n        after modifications to the DataFrame.\n        \"\"\"\n        self.total_set_of_teams = self.get_set_of_teams()\n        self.total_number_of_teams = len(self.total_set_of_teams)\n\n    def get_set_of_teams(self):\n        \"\"\"\n        Returns a set of all team names present in the DataFrame.\n\n        Returns:\n            set: Unique team names from 'Home' and 'Away' columns.\n        \"\"\"\n        return set(self.data_handler.dataframe['Home']).union(\n            set(self.data_handler.dataframe['Away'])\n        )\n\n    def get_set_of_teams_ids(self):\n        \"\"\"\n        Returns a set of all team IDs present in the DataFrame.\n\n        Returns:\n            set: Unique team IDs from 'HID' and 'AID' columns.\n        \"\"\"\n        return set(self.data_handler.dataframe['HID']).union(\n            set(self.data_handler.dataframe['AID'])\n        )\n\n    def get_labels(self):\n        \"\"\"\n        Retrieves the target labels for training or evaluation.\n\n        Returns:\n            pandas.Series: Series containing match outcomes (WDL).\n        \"\"\"\n        return self.get_dataframe()['WDL']\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper.__init__","title":"<code>__init__(data_handler, home_advantage)</code>","text":"<p>Initialize a MatchWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>data_handler</code> <code>DataHandler</code> <p>Object that holds and manages the match DataFrame.</p> required <code>home_advantage</code> <code>Any</code> <p>Information or value to apply a home advantage modifier.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>def __init__(self, data_handler: DataHandler, home_advantage):\n    \"\"\"\n    Initialize a MatchWrapper.\n\n    Args:\n        data_handler (DataHandler): Object that holds and manages the match DataFrame.\n        home_advantage (Any): Information or value to apply a home advantage modifier.\n    \"\"\"\n    super().__init__(data_handler, home_advantage)\n    self.total_set_of_teams = self.get_set_of_teams()\n    self.total_number_of_teams = len(self.total_set_of_teams)\n    self.total_set_of_teams_ids = set()\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper.get_labels","title":"<code>get_labels()</code>","text":"<p>Retrieves the target labels for training or evaluation.</p> <p>Returns:</p> Type Description <p>pandas.Series: Series containing match outcomes (WDL).</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>def get_labels(self):\n    \"\"\"\n    Retrieves the target labels for training or evaluation.\n\n    Returns:\n        pandas.Series: Series containing match outcomes (WDL).\n    \"\"\"\n    return self.get_dataframe()['WDL']\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper.get_set_of_teams","title":"<code>get_set_of_teams()</code>","text":"<p>Returns a set of all team names present in the DataFrame.</p> <p>Returns:</p> Name Type Description <code>set</code> <p>Unique team names from 'Home' and 'Away' columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>def get_set_of_teams(self):\n    \"\"\"\n    Returns a set of all team names present in the DataFrame.\n\n    Returns:\n        set: Unique team names from 'Home' and 'Away' columns.\n    \"\"\"\n    return set(self.data_handler.dataframe['Home']).union(\n        set(self.data_handler.dataframe['Away'])\n    )\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper.get_set_of_teams_ids","title":"<code>get_set_of_teams_ids()</code>","text":"<p>Returns a set of all team IDs present in the DataFrame.</p> <p>Returns:</p> Name Type Description <code>set</code> <p>Unique team IDs from 'HID' and 'AID' columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>def get_set_of_teams_ids(self):\n    \"\"\"\n    Returns a set of all team IDs present in the DataFrame.\n\n    Returns:\n        set: Unique team IDs from 'HID' and 'AID' columns.\n    \"\"\"\n    return set(self.data_handler.dataframe['HID']).union(\n        set(self.data_handler.dataframe['AID'])\n    )\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.MatchWrapper.MatchWrapper.set_after_compute_values","title":"<code>set_after_compute_values()</code>","text":"<p>Recomputes and updates the total set and number of teams after modifications to the DataFrame.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\MatchWrapper.py</code> <pre><code>def set_after_compute_values(self):\n    \"\"\"\n    Recomputes and updates the total set and number of teams\n    after modifications to the DataFrame.\n    \"\"\"\n    self.total_set_of_teams = self.get_set_of_teams()\n    self.total_number_of_teams = len(self.total_set_of_teams)\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.LeagueWrapper.LeagueWrapper","title":"<code>LeagueWrapper</code>","text":"<p>               Bases: <code>DataWrapper</code></p> <p>Specialized wrapper for handling data grouped by leagues. Inherits from <code>DataWrapper</code> and provides additional league-level aggregation utilities.</p> <p>Attributes:</p> Name Type Description <code>league_column</code> <code>str</code> <p>The name of the column representing the league.</p> <code>number_of_teams_by_leagues</code> <code>dict</code> <p>A mapping from league names to the number of teams.</p> <code>total_number_of_leagues</code> <code>int</code> <p>Total number of unique leagues in the dataset.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\LeagueWrapper.py</code> <pre><code>class LeagueWrapper(DataWrapper):\n    \"\"\"\n    Specialized wrapper for handling data grouped by leagues. Inherits from `DataWrapper`\n    and provides additional league-level aggregation utilities.\n\n    Attributes:\n        league_column (str): The name of the column representing the league.\n        number_of_teams_by_leagues (dict): A mapping from league names to the number of teams.\n        total_number_of_leagues (int): Total number of unique leagues in the dataset.\n    \"\"\"\n\n    league_column = 'League'\n\n    def __init__(self, data_handler: DataHandler, home_advantage):\n        \"\"\"\n        Initialize a LeagueWrapper.\n\n        Args:\n            data_handler (DataHandler): DataHandler object containing league-based match data.\n            home_advantage (Any): Value or flag representing home advantage.\n        \"\"\"\n        super().__init__(data_handler, home_advantage)\n        self.number_of_teams_by_leagues = {}\n        self.total_number_of_leagues = 0\n\n    def set_after_compute_values(self):\n        \"\"\"\n        Recomputes league metadata, including the number of teams per league\n        and the total number of leagues.\n        \"\"\"\n        self.number_of_teams_by_leagues = self.get_number_of_teams_by_league()\n        self.total_number_of_leagues = len(self.get_leagues())\n\n    def get_leagues(self):\n        \"\"\"\n        Retrieves the list of unique leagues in the dataset.\n\n        Returns:\n            numpy.ndarray: An array of unique league names.\n        \"\"\"\n        return pd.unique(self.get_dataframe()[self.league_column])\n\n    def get_number_of_teams_by_league(self):\n        \"\"\"\n        Calculates the number of unique teams in each league.\n\n        Returns:\n            dict: A dictionary mapping league names to the count of unique teams.\n        \"\"\"\n        dict = {}\n        for league, group_values in self.get_dataframe().groupby([self.league_column]):\n            dict[league] = len(set(group_values['Home']).union(set(group_values['Away'])))\n        return dict\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.LeagueWrapper.LeagueWrapper.__init__","title":"<code>__init__(data_handler, home_advantage)</code>","text":"<p>Initialize a LeagueWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>data_handler</code> <code>DataHandler</code> <p>DataHandler object containing league-based match data.</p> required <code>home_advantage</code> <code>Any</code> <p>Value or flag representing home advantage.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\sport\\LeagueWrapper.py</code> <pre><code>def __init__(self, data_handler: DataHandler, home_advantage):\n    \"\"\"\n    Initialize a LeagueWrapper.\n\n    Args:\n        data_handler (DataHandler): DataHandler object containing league-based match data.\n        home_advantage (Any): Value or flag representing home advantage.\n    \"\"\"\n    super().__init__(data_handler, home_advantage)\n    self.number_of_teams_by_leagues = {}\n    self.total_number_of_leagues = 0\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.LeagueWrapper.LeagueWrapper.get_leagues","title":"<code>get_leagues()</code>","text":"<p>Retrieves the list of unique leagues in the dataset.</p> <p>Returns:</p> Type Description <p>numpy.ndarray: An array of unique league names.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\LeagueWrapper.py</code> <pre><code>def get_leagues(self):\n    \"\"\"\n    Retrieves the list of unique leagues in the dataset.\n\n    Returns:\n        numpy.ndarray: An array of unique league names.\n    \"\"\"\n    return pd.unique(self.get_dataframe()[self.league_column])\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.LeagueWrapper.LeagueWrapper.get_number_of_teams_by_league","title":"<code>get_number_of_teams_by_league()</code>","text":"<p>Calculates the number of unique teams in each league.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary mapping league names to the count of unique teams.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\LeagueWrapper.py</code> <pre><code>def get_number_of_teams_by_league(self):\n    \"\"\"\n    Calculates the number of unique teams in each league.\n\n    Returns:\n        dict: A dictionary mapping league names to the count of unique teams.\n    \"\"\"\n    dict = {}\n    for league, group_values in self.get_dataframe().groupby([self.league_column]):\n        dict[league] = len(set(group_values['Home']).union(set(group_values['Away'])))\n    return dict\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.LeagueWrapper.LeagueWrapper.set_after_compute_values","title":"<code>set_after_compute_values()</code>","text":"<p>Recomputes league metadata, including the number of teams per league and the total number of leagues.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\LeagueWrapper.py</code> <pre><code>def set_after_compute_values(self):\n    \"\"\"\n    Recomputes league metadata, including the number of teams per league\n    and the total number of leagues.\n    \"\"\"\n    self.number_of_teams_by_leagues = self.get_number_of_teams_by_league()\n    self.total_number_of_leagues = len(self.get_leagues())\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.RaceWrapper.RaceWrapper","title":"<code>RaceWrapper</code>","text":"<p>               Bases: <code>DataWrapper</code></p> <p>Specialized wrapper for race-based or individual-player events. Inherits from <code>DataWrapper</code> and provides identifiers relevant to player-based competitions.</p> <p>Attributes:</p> Name Type Description <code>name_columns</code> <code>list[str]</code> <p>Column(s) representing player names.</p> <code>name_id_columns</code> <code>list[str]</code> <p>Column(s) representing player IDs.</p> <code>rank_column</code> <code>list[str]</code> <p>Column(s) representing player rankings or positions.</p> Source code in <code>sports_prediction_framework\\datawrapper\\sport\\RaceWrapper.py</code> <pre><code>class RaceWrapper(DataWrapper):\n    \"\"\"\n    Specialized wrapper for race-based or individual-player events. Inherits from `DataWrapper`\n    and provides identifiers relevant to player-based competitions.\n\n    Attributes:\n        name_columns (list[str]): Column(s) representing player names.\n        name_id_columns (list[str]): Column(s) representing player IDs.\n        rank_column (list[str]): Column(s) representing player rankings or positions.\n    \"\"\"\n\n    name_columns = ['Player']\n    name_id_columns = ['PID']\n    rank_column = ['Rank']\n\n    def __init__(self, data_handler: DataHandler, home_advantage):\n        \"\"\"\n        Initialize a RaceWrapper.\n\n        Args:\n            data_handler (DataHandler): Object containing the race or player-based DataFrame.\n            home_advantage (Any): Placeholder for compatibility with `DataWrapper`, may be unused.\n        \"\"\"\n        super().__init__(data_handler, home_advantage)\n</code></pre>"},{"location":"reference/datawrapper_advanced/#datawrapper.sport.RaceWrapper.RaceWrapper.__init__","title":"<code>__init__(data_handler, home_advantage)</code>","text":"<p>Initialize a RaceWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>data_handler</code> <code>DataHandler</code> <p>Object containing the race or player-based DataFrame.</p> required <code>home_advantage</code> <code>Any</code> <p>Placeholder for compatibility with <code>DataWrapper</code>, may be unused.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\sport\\RaceWrapper.py</code> <pre><code>def __init__(self, data_handler: DataHandler, home_advantage):\n    \"\"\"\n    Initialize a RaceWrapper.\n\n    Args:\n        data_handler (DataHandler): Object containing the race or player-based DataFrame.\n        home_advantage (Any): Placeholder for compatibility with `DataWrapper`, may be unused.\n    \"\"\"\n    super().__init__(data_handler, home_advantage)\n</code></pre>"},{"location":"reference/datawrapper_base/","title":"Base wrappers","text":""},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper","title":"<code>DataWrapper</code>","text":"<p>A higher-level interface for interacting with a DataHandler. Can be extended by specialized wrappers for domain-specific logic (e.g., MatchWrapper, RaceWrapper).</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>class DataWrapper:\n    \"\"\"\n    A higher-level interface for interacting with a DataHandler.\n    Can be extended by specialized wrappers for domain-specific logic (e.g., MatchWrapper, RaceWrapper).\n    \"\"\"\n\n    season_column = 'Season'\n\n    # These can be overridden in subclasses\n    name_columns = None\n    name_id_columns = None\n    prediction_columns = None\n    score_columns = None\n    result_column = None\n\n    def __init__(self, data_handler: DataHandler, home_advantage=None):\n        \"\"\"\n        Initializes the DataWrapper with a DataHandler.\n\n        Args:\n            data_handler (DataHandler): Core data manager for handling features, labels, predictions.\n            home_advantage (optional): Optional metadata (used in some subclasses).\n        \"\"\"\n        self.data_handler = data_handler\n\n    def get_dataframe(self):\n        \"\"\"\n        Returns the underlying DataFrame from the DataHandler.\n\n        Returns:\n            pd.DataFrame: The dataset.\n        \"\"\"\n        return self.data_handler.dataframe\n\n    def set_dataframe(self, dataframe):\n        \"\"\"\n        Sets a new DataFrame to the underlying DataHandler.\n\n        Args:\n            dataframe (pd.DataFrame): New data to set.\n        \"\"\"\n        self.data_handler.dataframe = dataframe\n\n    def get_features(self):\n        \"\"\"\n        Returns the feature columns from the DataHandler.\n\n        Returns:\n            pd.DataFrame: DataFrame of feature columns.\n        \"\"\"\n        return self.data_handler.get_features()\n\n    def add_features(self, features, on=None):\n        \"\"\"\n        Adds new features to the dataset.\n\n        Args:\n            features (pd.DataFrame): Feature columns to add.\n            on (str or list, optional): Columns to join on. Defaults to index-based join.\n        \"\"\"\n        self.data_handler.add_features(features, on)\n\n    def add_features_from_csv(self, filename, index=None, on=None):\n        \"\"\"\n        Loads features from a CSV file and joins them into the dataset.\n\n        Args:\n            filename (str): Path to the CSV file.\n            index (str or int, optional): Column to use as the index.\n            on (str or list, optional): Columns to join on.\n        \"\"\"\n        dataframe = pd.read_csv(filename, index_col=index)\n        self.add_features(dataframe, on)\n\n    def get_labels(self):\n        \"\"\"\n        Returns the label columns from the DataHandler.\n\n        Returns:\n            pd.DataFrame: DataFrame of label columns.\n        \"\"\"\n        return self.data_handler.get_labels()\n\n    def add_labels(self, labels):\n        \"\"\"\n        Adds new labels to the dataset.\n\n        Args:\n            labels (pd.DataFrame): Label columns to add.\n        \"\"\"\n        self.data_handler.add_labels(labels)\n\n    def get_predictions(self):\n        \"\"\"\n        Returns the prediction columns from the DataHandler.\n\n        Returns:\n            pd.DataFrame: DataFrame of prediction columns.\n        \"\"\"\n        return self.data_handler.get_predictions()\n\n    def add_predictions(self, predictions):\n        \"\"\"\n        Adds new predictions to the dataset.\n\n        Args:\n            predictions (pd.DataFrame): Prediction columns to add.\n        \"\"\"\n        self.data_handler.add_predictions(predictions)\n\n    def add_columns(self, data):\n        \"\"\"\n        Adds arbitrary columns to the dataset (not tracked as features/labels/predictions).\n\n        Args:\n            data (pd.DataFrame): Columns to add.\n        \"\"\"\n        self.data_handler.add_columns(data)\n\n    def get_columns(self, column_names):\n        \"\"\"\n        Retrieves specified columns from the dataset.\n\n        Args:\n            column_names (list): List of column names to retrieve.\n\n        Returns:\n            pd.DataFrame: DataFrame with specified columns.\n        \"\"\"\n        return self.data_handler.get_columns(column_names)\n\n    def set_after_compute_values(self):\n        \"\"\"\n        Hook method for subclasses to override.\n        Called after features, labels, or predictions are added to recalculate derived values.\n        \"\"\"\n        pass\n\n    def empty(self):\n        \"\"\"\n        Checks whether the underlying dataset is empty.\n\n        Returns:\n            bool: True if empty, False otherwise.\n        \"\"\"\n        return self.get_dataframe().empty\n\n    def deepcopy(self, dataframe: pd.DataFrame = None, feat_cols=None, label_cols=None):\n        new_handler = self.data_handler.copy(dataframe, feat_cols, label_cols)\n        new = self.__class__(new_handler)\n\n        for attribute_key, value in self.__dict__.items():\n            if attribute_key != 'data_handler':\n                new.__dict__[attribute_key] = copy.deepcopy(value)\n\n        return new\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.__init__","title":"<code>__init__(data_handler, home_advantage=None)</code>","text":"<p>Initializes the DataWrapper with a DataHandler.</p> <p>Parameters:</p> Name Type Description Default <code>data_handler</code> <code>DataHandler</code> <p>Core data manager for handling features, labels, predictions.</p> required <code>home_advantage</code> <code>optional</code> <p>Optional metadata (used in some subclasses).</p> <code>None</code> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def __init__(self, data_handler: DataHandler, home_advantage=None):\n    \"\"\"\n    Initializes the DataWrapper with a DataHandler.\n\n    Args:\n        data_handler (DataHandler): Core data manager for handling features, labels, predictions.\n        home_advantage (optional): Optional metadata (used in some subclasses).\n    \"\"\"\n    self.data_handler = data_handler\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.add_columns","title":"<code>add_columns(data)</code>","text":"<p>Adds arbitrary columns to the dataset (not tracked as features/labels/predictions).</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def add_columns(self, data):\n    \"\"\"\n    Adds arbitrary columns to the dataset (not tracked as features/labels/predictions).\n\n    Args:\n        data (pd.DataFrame): Columns to add.\n    \"\"\"\n    self.data_handler.add_columns(data)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.add_features","title":"<code>add_features(features, on=None)</code>","text":"<p>Adds new features to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>DataFrame</code> <p>Feature columns to add.</p> required <code>on</code> <code>str or list</code> <p>Columns to join on. Defaults to index-based join.</p> <code>None</code> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def add_features(self, features, on=None):\n    \"\"\"\n    Adds new features to the dataset.\n\n    Args:\n        features (pd.DataFrame): Feature columns to add.\n        on (str or list, optional): Columns to join on. Defaults to index-based join.\n    \"\"\"\n    self.data_handler.add_features(features, on)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.add_features_from_csv","title":"<code>add_features_from_csv(filename, index=None, on=None)</code>","text":"<p>Loads features from a CSV file and joins them into the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the CSV file.</p> required <code>index</code> <code>str or int</code> <p>Column to use as the index.</p> <code>None</code> <code>on</code> <code>str or list</code> <p>Columns to join on.</p> <code>None</code> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def add_features_from_csv(self, filename, index=None, on=None):\n    \"\"\"\n    Loads features from a CSV file and joins them into the dataset.\n\n    Args:\n        filename (str): Path to the CSV file.\n        index (str or int, optional): Column to use as the index.\n        on (str or list, optional): Columns to join on.\n    \"\"\"\n    dataframe = pd.read_csv(filename, index_col=index)\n    self.add_features(dataframe, on)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.add_labels","title":"<code>add_labels(labels)</code>","text":"<p>Adds new labels to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>DataFrame</code> <p>Label columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def add_labels(self, labels):\n    \"\"\"\n    Adds new labels to the dataset.\n\n    Args:\n        labels (pd.DataFrame): Label columns to add.\n    \"\"\"\n    self.data_handler.add_labels(labels)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.add_predictions","title":"<code>add_predictions(predictions)</code>","text":"<p>Adds new predictions to the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>DataFrame</code> <p>Prediction columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def add_predictions(self, predictions):\n    \"\"\"\n    Adds new predictions to the dataset.\n\n    Args:\n        predictions (pd.DataFrame): Prediction columns to add.\n    \"\"\"\n    self.data_handler.add_predictions(predictions)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.empty","title":"<code>empty()</code>","text":"<p>Checks whether the underlying dataset is empty.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if empty, False otherwise.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def empty(self):\n    \"\"\"\n    Checks whether the underlying dataset is empty.\n\n    Returns:\n        bool: True if empty, False otherwise.\n    \"\"\"\n    return self.get_dataframe().empty\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.get_columns","title":"<code>get_columns(column_names)</code>","text":"<p>Retrieves specified columns from the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>column_names</code> <code>list</code> <p>List of column names to retrieve.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame with specified columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def get_columns(self, column_names):\n    \"\"\"\n    Retrieves specified columns from the dataset.\n\n    Args:\n        column_names (list): List of column names to retrieve.\n\n    Returns:\n        pd.DataFrame: DataFrame with specified columns.\n    \"\"\"\n    return self.data_handler.get_columns(column_names)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.get_dataframe","title":"<code>get_dataframe()</code>","text":"<p>Returns the underlying DataFrame from the DataHandler.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: The dataset.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def get_dataframe(self):\n    \"\"\"\n    Returns the underlying DataFrame from the DataHandler.\n\n    Returns:\n        pd.DataFrame: The dataset.\n    \"\"\"\n    return self.data_handler.dataframe\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.get_features","title":"<code>get_features()</code>","text":"<p>Returns the feature columns from the DataHandler.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame of feature columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def get_features(self):\n    \"\"\"\n    Returns the feature columns from the DataHandler.\n\n    Returns:\n        pd.DataFrame: DataFrame of feature columns.\n    \"\"\"\n    return self.data_handler.get_features()\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.get_labels","title":"<code>get_labels()</code>","text":"<p>Returns the label columns from the DataHandler.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame of label columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def get_labels(self):\n    \"\"\"\n    Returns the label columns from the DataHandler.\n\n    Returns:\n        pd.DataFrame: DataFrame of label columns.\n    \"\"\"\n    return self.data_handler.get_labels()\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.get_predictions","title":"<code>get_predictions()</code>","text":"<p>Returns the prediction columns from the DataHandler.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame of prediction columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def get_predictions(self):\n    \"\"\"\n    Returns the prediction columns from the DataHandler.\n\n    Returns:\n        pd.DataFrame: DataFrame of prediction columns.\n    \"\"\"\n    return self.data_handler.get_predictions()\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.set_after_compute_values","title":"<code>set_after_compute_values()</code>","text":"<p>Hook method for subclasses to override. Called after features, labels, or predictions are added to recalculate derived values.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def set_after_compute_values(self):\n    \"\"\"\n    Hook method for subclasses to override.\n    Called after features, labels, or predictions are added to recalculate derived values.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataWrapper.DataWrapper.set_dataframe","title":"<code>set_dataframe(dataframe)</code>","text":"<p>Sets a new DataFrame to the underlying DataHandler.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>New data to set.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataWrapper.py</code> <pre><code>def set_dataframe(self, dataframe):\n    \"\"\"\n    Sets a new DataFrame to the underlying DataHandler.\n\n    Args:\n        dataframe (pd.DataFrame): New data to set.\n    \"\"\"\n    self.data_handler.dataframe = dataframe\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler","title":"<code>DataHandler</code>","text":"<p>A utility class for managing features, labels, and predictions within a pandas DataFrame. Provides methods for accessing, modifying, and copying the underlying data.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>class DataHandler:\n    \"\"\"\n    A utility class for managing features, labels, and predictions within a pandas DataFrame.\n    Provides methods for accessing, modifying, and copying the underlying data.\n    \"\"\"\n\n    def __init__(self, dataframe: pd.DataFrame = None, feature_cols=None, label_cols=None, prediction_cols=None):\n        \"\"\"\n        Initializes the DataHandler with a DataFrame and optional columns for features, labels, and predictions.\n\n        Args:\n            dataframe (pd.DataFrame, optional): The primary data container.\n            feature_cols (iterable, optional): Column names to mark as features.\n            label_cols (iterable, optional): Column names to mark as labels.\n            prediction_cols (list, optional): Columns used to store predictions.\n        \"\"\"\n        self.dataframe = dataframe\n        self.prediction_cols = prediction_cols  # Columns created by learners for storing predictions\n\n        self.label_cols = set(label_cols) if label_cols is not None else set()\n        self.feature_cols = set(feature_cols) if feature_cols is not None else set()\n\n    def get_dataframe(self):\n        \"\"\"\n        Returns the underlying DataFrame.\n\n        Returns:\n            pd.DataFrame: The managed DataFrame.\n        \"\"\"\n        return self.dataframe\n\n    def set_dataframe(self, dataframe: pd.DataFrame):\n        \"\"\"\n        Sets a new DataFrame as the underlying data container.\n\n        Args:\n            dataframe (pd.DataFrame): The new DataFrame to manage.\n        \"\"\"\n        self.dataframe = dataframe\n\n    def get_features(self):\n        \"\"\"\n        Retrieves the feature columns from the DataFrame.\n\n        Returns:\n            pd.DataFrame: DataFrame containing only feature columns.\n        \"\"\"\n        return self.dataframe[self.feature_cols]\n\n    def add_features(self, features, on=None):\n        \"\"\"\n        Joins new feature columns into the DataFrame and updates the feature column set.\n\n        Args:\n            features (pd.DataFrame): New feature columns to add.\n            on (str or list, optional): Column(s) to join on. Defaults to index-based join.\n        \"\"\"\n        self.dataframe = self.dataframe.join(features, on=on) if on else self.dataframe.join(features)\n        self.feature_cols.update(features.columns.tolist())\n\n    def get_labels(self):\n        \"\"\"\n        Retrieves the label columns from the DataFrame.\n\n        Returns:\n            pd.DataFrame: DataFrame containing only label columns.\n        \"\"\"\n        return self.dataframe[list(self.label_cols)]\n\n    def add_labels(self, labels):\n        \"\"\"\n        Joins new label columns into the DataFrame and updates the label column set.\n\n        Args:\n            labels (pd.DataFrame): New label columns to add.\n        \"\"\"\n        self.dataframe = self.dataframe.join(labels)\n        self.label_cols.update(labels.columns.tolist())\n\n    def get_predictions(self):\n        \"\"\"\n        Retrieves the prediction columns from the DataFrame.\n\n        Returns:\n            pd.DataFrame: DataFrame containing prediction columns.\n        \"\"\"\n        return self.dataframe[self.prediction_cols]\n\n    def add_predictions(self, predictions):\n        \"\"\"\n        Joins new prediction columns into the DataFrame and updates the prediction column list.\n\n        Args:\n            predictions (pd.DataFrame): New prediction columns to add.\n        \"\"\"\n        self.dataframe = self.dataframe.join(predictions)\n        if self.prediction_cols is None:\n            self.prediction_cols = []\n        self.prediction_cols += predictions.columns.tolist()\n\n    def get_columns(self, columns):\n        \"\"\"\n        Retrieves specified columns from the DataFrame.\n\n        Args:\n            columns (list): List of column names to retrieve.\n\n        Returns:\n            pd.DataFrame: DataFrame containing the specified columns.\n        \"\"\"\n        return self.dataframe[columns]\n\n    def add_columns(self, data):\n        \"\"\"\n        Joins additional columns into the DataFrame. Does not update feature/label/prediction sets.\n\n        Args:\n            data (pd.DataFrame): Columns to add.\n        \"\"\"\n        self.dataframe = self.dataframe.join(data)\n\n    def copy(self, dataframe: pd.DataFrame = None, feat_cols=None, label_cols=None):\n        \"\"\"\n        Creates a deep copy of the DataHandler.\n        \"\"\"\n        if dataframe is None:\n            dataframe = self.dataframe.copy(deep=True)  # &lt;-- deep copy of DataFrame\n        if feat_cols is None:\n            feat_cols = copy.deepcopy(self.feature_cols)\n        if label_cols is None:\n            label_cols = copy.deepcopy(self.label_cols)\n\n        return DataHandler(dataframe, feature_cols=feat_cols, label_cols=label_cols)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.__init__","title":"<code>__init__(dataframe=None, feature_cols=None, label_cols=None, prediction_cols=None)</code>","text":"<p>Initializes the DataHandler with a DataFrame and optional columns for features, labels, and predictions.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The primary data container.</p> <code>None</code> <code>feature_cols</code> <code>iterable</code> <p>Column names to mark as features.</p> <code>None</code> <code>label_cols</code> <code>iterable</code> <p>Column names to mark as labels.</p> <code>None</code> <code>prediction_cols</code> <code>list</code> <p>Columns used to store predictions.</p> <code>None</code> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def __init__(self, dataframe: pd.DataFrame = None, feature_cols=None, label_cols=None, prediction_cols=None):\n    \"\"\"\n    Initializes the DataHandler with a DataFrame and optional columns for features, labels, and predictions.\n\n    Args:\n        dataframe (pd.DataFrame, optional): The primary data container.\n        feature_cols (iterable, optional): Column names to mark as features.\n        label_cols (iterable, optional): Column names to mark as labels.\n        prediction_cols (list, optional): Columns used to store predictions.\n    \"\"\"\n    self.dataframe = dataframe\n    self.prediction_cols = prediction_cols  # Columns created by learners for storing predictions\n\n    self.label_cols = set(label_cols) if label_cols is not None else set()\n    self.feature_cols = set(feature_cols) if feature_cols is not None else set()\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.add_columns","title":"<code>add_columns(data)</code>","text":"<p>Joins additional columns into the DataFrame. Does not update feature/label/prediction sets.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>Columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def add_columns(self, data):\n    \"\"\"\n    Joins additional columns into the DataFrame. Does not update feature/label/prediction sets.\n\n    Args:\n        data (pd.DataFrame): Columns to add.\n    \"\"\"\n    self.dataframe = self.dataframe.join(data)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.add_features","title":"<code>add_features(features, on=None)</code>","text":"<p>Joins new feature columns into the DataFrame and updates the feature column set.</p> <p>Parameters:</p> Name Type Description Default <code>features</code> <code>DataFrame</code> <p>New feature columns to add.</p> required <code>on</code> <code>str or list</code> <p>Column(s) to join on. Defaults to index-based join.</p> <code>None</code> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def add_features(self, features, on=None):\n    \"\"\"\n    Joins new feature columns into the DataFrame and updates the feature column set.\n\n    Args:\n        features (pd.DataFrame): New feature columns to add.\n        on (str or list, optional): Column(s) to join on. Defaults to index-based join.\n    \"\"\"\n    self.dataframe = self.dataframe.join(features, on=on) if on else self.dataframe.join(features)\n    self.feature_cols.update(features.columns.tolist())\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.add_labels","title":"<code>add_labels(labels)</code>","text":"<p>Joins new label columns into the DataFrame and updates the label column set.</p> <p>Parameters:</p> Name Type Description Default <code>labels</code> <code>DataFrame</code> <p>New label columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def add_labels(self, labels):\n    \"\"\"\n    Joins new label columns into the DataFrame and updates the label column set.\n\n    Args:\n        labels (pd.DataFrame): New label columns to add.\n    \"\"\"\n    self.dataframe = self.dataframe.join(labels)\n    self.label_cols.update(labels.columns.tolist())\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.add_predictions","title":"<code>add_predictions(predictions)</code>","text":"<p>Joins new prediction columns into the DataFrame and updates the prediction column list.</p> <p>Parameters:</p> Name Type Description Default <code>predictions</code> <code>DataFrame</code> <p>New prediction columns to add.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def add_predictions(self, predictions):\n    \"\"\"\n    Joins new prediction columns into the DataFrame and updates the prediction column list.\n\n    Args:\n        predictions (pd.DataFrame): New prediction columns to add.\n    \"\"\"\n    self.dataframe = self.dataframe.join(predictions)\n    if self.prediction_cols is None:\n        self.prediction_cols = []\n    self.prediction_cols += predictions.columns.tolist()\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.copy","title":"<code>copy(dataframe=None, feat_cols=None, label_cols=None)</code>","text":"<p>Creates a deep copy of the DataHandler.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def copy(self, dataframe: pd.DataFrame = None, feat_cols=None, label_cols=None):\n    \"\"\"\n    Creates a deep copy of the DataHandler.\n    \"\"\"\n    if dataframe is None:\n        dataframe = self.dataframe.copy(deep=True)  # &lt;-- deep copy of DataFrame\n    if feat_cols is None:\n        feat_cols = copy.deepcopy(self.feature_cols)\n    if label_cols is None:\n        label_cols = copy.deepcopy(self.label_cols)\n\n    return DataHandler(dataframe, feature_cols=feat_cols, label_cols=label_cols)\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.get_columns","title":"<code>get_columns(columns)</code>","text":"<p>Retrieves specified columns from the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>list</code> <p>List of column names to retrieve.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame containing the specified columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def get_columns(self, columns):\n    \"\"\"\n    Retrieves specified columns from the DataFrame.\n\n    Args:\n        columns (list): List of column names to retrieve.\n\n    Returns:\n        pd.DataFrame: DataFrame containing the specified columns.\n    \"\"\"\n    return self.dataframe[columns]\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.get_dataframe","title":"<code>get_dataframe()</code>","text":"<p>Returns the underlying DataFrame.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: The managed DataFrame.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def get_dataframe(self):\n    \"\"\"\n    Returns the underlying DataFrame.\n\n    Returns:\n        pd.DataFrame: The managed DataFrame.\n    \"\"\"\n    return self.dataframe\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.get_features","title":"<code>get_features()</code>","text":"<p>Retrieves the feature columns from the DataFrame.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame containing only feature columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def get_features(self):\n    \"\"\"\n    Retrieves the feature columns from the DataFrame.\n\n    Returns:\n        pd.DataFrame: DataFrame containing only feature columns.\n    \"\"\"\n    return self.dataframe[self.feature_cols]\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.get_labels","title":"<code>get_labels()</code>","text":"<p>Retrieves the label columns from the DataFrame.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame containing only label columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def get_labels(self):\n    \"\"\"\n    Retrieves the label columns from the DataFrame.\n\n    Returns:\n        pd.DataFrame: DataFrame containing only label columns.\n    \"\"\"\n    return self.dataframe[list(self.label_cols)]\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.get_predictions","title":"<code>get_predictions()</code>","text":"<p>Retrieves the prediction columns from the DataFrame.</p> <p>Returns:</p> Type Description <p>pd.DataFrame: DataFrame containing prediction columns.</p> Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def get_predictions(self):\n    \"\"\"\n    Retrieves the prediction columns from the DataFrame.\n\n    Returns:\n        pd.DataFrame: DataFrame containing prediction columns.\n    \"\"\"\n    return self.dataframe[self.prediction_cols]\n</code></pre>"},{"location":"reference/datawrapper_base/#datawrapper.DataHandler.DataHandler.set_dataframe","title":"<code>set_dataframe(dataframe)</code>","text":"<p>Sets a new DataFrame as the underlying data container.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The new DataFrame to manage.</p> required Source code in <code>sports_prediction_framework\\datawrapper\\DataHandler.py</code> <pre><code>def set_dataframe(self, dataframe: pd.DataFrame):\n    \"\"\"\n    Sets a new DataFrame as the underlying data container.\n\n    Args:\n        dataframe (pd.DataFrame): The new DataFrame to manage.\n    \"\"\"\n    self.dataframe = dataframe\n</code></pre>"},{"location":"reference/learner/","title":"learner","text":""},{"location":"reference/learner/#learner.Learner.Learner","title":"<code>Learner</code>","text":"<p>Coordinates the training and testing of a model using a Trainer and Tester on data segmented by a DataSelector (scope).</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>class Learner:\n    \"\"\"\n    Coordinates the training and testing of a model using a Trainer and Tester on data segmented by a DataSelector (scope).\n    \"\"\"\n\n    def __init__(self, trainer: Trainer = None, tester: Tester = None, scope: DataSelector = None, **kwargs):\n        \"\"\"\n        Initializes the Learner.\n\n        Args:\n            trainer (Trainer): Component responsible for training the model.\n            tester (Tester): Component responsible for generating predictions.\n            scope (DataSelector): Object that defines training and testing subsets.\n        \"\"\"\n        self.trainer = trainer\n        self.tester = tester\n        self.scope = scope\n        self.last = True\n\n    def compute(self, wrapper: DataWrapper) -&gt; DataWrapper:\n        \"\"\"\n        Executes the train-test workflow and attaches predictions to the wrapper.\n\n        Args:\n            wrapper (DataWrapper): Dataset to train/test on.\n\n        Returns:\n            DataWrapper: Copy of the input wrapper with added predictions.\n        \"\"\"\n        features = self.train_test(wrapper)\n        print(features)\n        if features is None:\n            return wrapper\n        features = features[~features.index.duplicated(keep='first')]\n        pwrapper = wrapper.deepcopy()\n        if self.last:\n            pwrapper.add_predictions(features)\n        else:\n            pwrapper.add_features(features)\n        return pwrapper\n\n    def train_test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n        \"\"\"\n        Performs the train-test split, fits the model, and returns predictions.\n\n        Args:\n            dataset (DataWrapper): Complete dataset.\n\n        Returns:\n            pd.DataFrame: Predictions from the test set.\n        \"\"\"\n        train_wrapper = self.scope.transform_train(dataset)\n        test_wrapper = self.scope.transform_test(dataset)\n        if train_wrapper.empty() or test_wrapper.empty():\n            return pd.DataFrame()\n        self.train(train_wrapper)\n\n        return self.test(test_wrapper)\n\n    def train(self, dataset: DataWrapper):\n        \"\"\"\n        Trains the model using the provided dataset.\n\n        Args:\n            dataset (DataWrapper): Training data.\n\n        Raises:\n            ValueError: If the dataset is empty.\n        \"\"\"\n        if self.trainer is not None:\n            if not dataset.get_dataframe().empty:\n                self.trainer.train(dataset)\n            else:\n                raise ValueError(\"Missing data!\")\n\n    def test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n        \"\"\"\n        Tests the model using the provided dataset and returns predictions.\n\n        Args:\n            dataset (DataWrapper): Testing data.\n\n        Returns:\n            pd.DataFrame: Model predictions.\n\n        Raises:\n            ValueError: If the dataset is empty.\n        \"\"\"\n        if self.tester is not None:\n            if not dataset.get_dataframe().empty:\n                return self.tester.test(dataset)\n            else:\n                raise ValueError(\"Missing data!\")\n        return None\n\n    def set_model_hyper_params(self, params):\n        \"\"\"\n        Sets hyperparameters on the underlying model in both the trainer and tester.\n\n        Args:\n            params (dict): Dictionary of model hyperparameters.\n        \"\"\"\n        self.trainer.model.set_params(params)\n        self.tester.model.set_params(params)\n\n    def reset_state(self):\n        \"\"\"\n        Resets the internal state of the trainer.\n        \"\"\"\n        self.trainer.reset_state()\n\n    def update(self):\n        \"\"\"\n        Updates the state of the DataSelector (e.g., for time-based iteration).\n        \"\"\"\n        self.scope.update()\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.__init__","title":"<code>__init__(trainer=None, tester=None, scope=None, **kwargs)</code>","text":"<p>Initializes the Learner.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>Component responsible for training the model.</p> <code>None</code> <code>tester</code> <code>Tester</code> <p>Component responsible for generating predictions.</p> <code>None</code> <code>scope</code> <code>DataSelector</code> <p>Object that defines training and testing subsets.</p> <code>None</code> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def __init__(self, trainer: Trainer = None, tester: Tester = None, scope: DataSelector = None, **kwargs):\n    \"\"\"\n    Initializes the Learner.\n\n    Args:\n        trainer (Trainer): Component responsible for training the model.\n        tester (Tester): Component responsible for generating predictions.\n        scope (DataSelector): Object that defines training and testing subsets.\n    \"\"\"\n    self.trainer = trainer\n    self.tester = tester\n    self.scope = scope\n    self.last = True\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.compute","title":"<code>compute(wrapper)</code>","text":"<p>Executes the train-test workflow and attaches predictions to the wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>Dataset to train/test on.</p> required <p>Returns:</p> Name Type Description <code>DataWrapper</code> <code>DataWrapper</code> <p>Copy of the input wrapper with added predictions.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def compute(self, wrapper: DataWrapper) -&gt; DataWrapper:\n    \"\"\"\n    Executes the train-test workflow and attaches predictions to the wrapper.\n\n    Args:\n        wrapper (DataWrapper): Dataset to train/test on.\n\n    Returns:\n        DataWrapper: Copy of the input wrapper with added predictions.\n    \"\"\"\n    features = self.train_test(wrapper)\n    print(features)\n    if features is None:\n        return wrapper\n    features = features[~features.index.duplicated(keep='first')]\n    pwrapper = wrapper.deepcopy()\n    if self.last:\n        pwrapper.add_predictions(features)\n    else:\n        pwrapper.add_features(features)\n    return pwrapper\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.reset_state","title":"<code>reset_state()</code>","text":"<p>Resets the internal state of the trainer.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Resets the internal state of the trainer.\n    \"\"\"\n    self.trainer.reset_state()\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.set_model_hyper_params","title":"<code>set_model_hyper_params(params)</code>","text":"<p>Sets hyperparameters on the underlying model in both the trainer and tester.</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>Dictionary of model hyperparameters.</p> required Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def set_model_hyper_params(self, params):\n    \"\"\"\n    Sets hyperparameters on the underlying model in both the trainer and tester.\n\n    Args:\n        params (dict): Dictionary of model hyperparameters.\n    \"\"\"\n    self.trainer.model.set_params(params)\n    self.tester.model.set_params(params)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.test","title":"<code>test(dataset)</code>","text":"<p>Tests the model using the provided dataset and returns predictions.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataWrapper</code> <p>Testing data.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Model predictions.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset is empty.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n    \"\"\"\n    Tests the model using the provided dataset and returns predictions.\n\n    Args:\n        dataset (DataWrapper): Testing data.\n\n    Returns:\n        pd.DataFrame: Model predictions.\n\n    Raises:\n        ValueError: If the dataset is empty.\n    \"\"\"\n    if self.tester is not None:\n        if not dataset.get_dataframe().empty:\n            return self.tester.test(dataset)\n        else:\n            raise ValueError(\"Missing data!\")\n    return None\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.train","title":"<code>train(dataset)</code>","text":"<p>Trains the model using the provided dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataWrapper</code> <p>Training data.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If the dataset is empty.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def train(self, dataset: DataWrapper):\n    \"\"\"\n    Trains the model using the provided dataset.\n\n    Args:\n        dataset (DataWrapper): Training data.\n\n    Raises:\n        ValueError: If the dataset is empty.\n    \"\"\"\n    if self.trainer is not None:\n        if not dataset.get_dataframe().empty:\n            self.trainer.train(dataset)\n        else:\n            raise ValueError(\"Missing data!\")\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.train_test","title":"<code>train_test(dataset)</code>","text":"<p>Performs the train-test split, fits the model, and returns predictions.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataWrapper</code> <p>Complete dataset.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Predictions from the test set.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def train_test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n    \"\"\"\n    Performs the train-test split, fits the model, and returns predictions.\n\n    Args:\n        dataset (DataWrapper): Complete dataset.\n\n    Returns:\n        pd.DataFrame: Predictions from the test set.\n    \"\"\"\n    train_wrapper = self.scope.transform_train(dataset)\n    test_wrapper = self.scope.transform_test(dataset)\n    if train_wrapper.empty() or test_wrapper.empty():\n        return pd.DataFrame()\n    self.train(train_wrapper)\n\n    return self.test(test_wrapper)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.Learner.update","title":"<code>update()</code>","text":"<p>Updates the state of the DataSelector (e.g., for time-based iteration).</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def update(self):\n    \"\"\"\n    Updates the state of the DataSelector (e.g., for time-based iteration).\n    \"\"\"\n    self.scope.update()\n</code></pre>"},{"location":"reference/learner/#learner.Learner.LearnerWithoutScope","title":"<code>LearnerWithoutScope</code>","text":"<p>               Bases: <code>Learner</code></p> <p>Simplified Learner that uses the entire dataset for both training and testing.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>class LearnerWithoutScope(Learner):\n    \"\"\"\n    Simplified Learner that uses the entire dataset for both training and testing.\n    \"\"\"\n\n    def __init__(self, trainer: Trainer = None, tester: Tester = None, **kwargs):\n        \"\"\"\n        Initializes the LearnerWithoutScope. No scope is required.\n\n        Args:\n            trainer (Trainer): Trainer component.\n            tester (Tester): Tester component.\n        \"\"\"\n        super().__init__(trainer, tester, None, **kwargs)\n\n    def train_test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n        \"\"\"\n        Trains and tests the model on the same dataset.\n\n        Args:\n            dataset (DataWrapper): Full dataset.\n\n        Returns:\n            pd.DataFrame: Predictions.\n        \"\"\"\n        self.train(dataset)\n        return self.test(dataset)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.LearnerWithoutScope.__init__","title":"<code>__init__(trainer=None, tester=None, **kwargs)</code>","text":"<p>Initializes the LearnerWithoutScope. No scope is required.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>Trainer component.</p> <code>None</code> <code>tester</code> <code>Tester</code> <p>Tester component.</p> <code>None</code> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def __init__(self, trainer: Trainer = None, tester: Tester = None, **kwargs):\n    \"\"\"\n    Initializes the LearnerWithoutScope. No scope is required.\n\n    Args:\n        trainer (Trainer): Trainer component.\n        tester (Tester): Tester component.\n    \"\"\"\n    super().__init__(trainer, tester, None, **kwargs)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.LearnerWithoutScope.train_test","title":"<code>train_test(dataset)</code>","text":"<p>Trains and tests the model on the same dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataWrapper</code> <p>Full dataset.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Predictions.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def train_test(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n    \"\"\"\n    Trains and tests the model on the same dataset.\n\n    Args:\n        dataset (DataWrapper): Full dataset.\n\n    Returns:\n        pd.DataFrame: Predictions.\n    \"\"\"\n    self.train(dataset)\n    return self.test(dataset)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.UpdatingLearner","title":"<code>UpdatingLearner</code>","text":"<p>               Bases: <code>Learner</code></p> <p>A Learner that iteratively trains and tests the model while a condition in the DataSelector holds. Can coordinate multiple internal learners and merge their predictions.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>class UpdatingLearner(Learner):\n    \"\"\"\n    A Learner that iteratively trains and tests the model while a condition in the DataSelector holds.\n    Can coordinate multiple internal learners and merge their predictions.\n    \"\"\"\n\n    def __init__(\n        self,\n        trainer: Trainer = None,\n        tester: Tester = None,\n        scope: DataSelector = None,\n        learners: list = None\n    ):\n        \"\"\"\n        Initializes the UpdatingLearner.\n\n        Args:\n            trainer (Trainer): Trainer component.\n            tester (Tester): Tester component.\n            scope (DataSelector): DataSelector for iterative training/testing.\n            learners (list): Optional list of nested Learner instances to coordinate.\n        \"\"\"\n        self.learners = learners if isinstance(learners, list) else ([learners] if learners else [])\n        self.merger = Merger() if self.learners else None\n        super().__init__(trainer, tester, scope)\n\n    def train_test(self, wrapper: DataWrapper):\n        \"\"\"\n        Iteratively trains and tests as long as the scope condition holds.\n        If inner learners are provided, they are run in parallel and their predictions merged.\n\n        Args:\n            wrapper (DataWrapper): Full dataset.\n\n        Returns:\n            pd.DataFrame: Concatenated predictions from all iterations.\n        \"\"\"\n        outputs = []\n        copy = wrapper.deepcopy()\n        # iteratively check if still within dataset scope\n        while self.scope.holds():\n            if self.learners:\n                wrappers = []\n                for learner in self.learners:\n                    wrappers.append(learner.compute(copy))\n                    learner.update()\n                wrapper = self.merger.compute(wrappers)\n            outputs.append(super().train_test(wrapper))\n            self.update()\n\n        if self.tester is not None:\n            if len(outputs) == 0:\n                return pd.DataFrame()\n            features = pd.concat([data for data in outputs])\n            return features\n        return None\n\n    def reset_state(self):\n        \"\"\"\n        Resets state of all inner learners, the scope, and the trainer.\n        \"\"\"\n        if self.learners:\n            for learner in self.learners:\n                learner.reset_state()\n        self.scope.reset_state()\n        self.trainer.reset_state()\n</code></pre>"},{"location":"reference/learner/#learner.Learner.UpdatingLearner.__init__","title":"<code>__init__(trainer=None, tester=None, scope=None, learners=None)</code>","text":"<p>Initializes the UpdatingLearner.</p> <p>Parameters:</p> Name Type Description Default <code>trainer</code> <code>Trainer</code> <p>Trainer component.</p> <code>None</code> <code>tester</code> <code>Tester</code> <p>Tester component.</p> <code>None</code> <code>scope</code> <code>DataSelector</code> <p>DataSelector for iterative training/testing.</p> <code>None</code> <code>learners</code> <code>list</code> <p>Optional list of nested Learner instances to coordinate.</p> <code>None</code> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def __init__(\n    self,\n    trainer: Trainer = None,\n    tester: Tester = None,\n    scope: DataSelector = None,\n    learners: list = None\n):\n    \"\"\"\n    Initializes the UpdatingLearner.\n\n    Args:\n        trainer (Trainer): Trainer component.\n        tester (Tester): Tester component.\n        scope (DataSelector): DataSelector for iterative training/testing.\n        learners (list): Optional list of nested Learner instances to coordinate.\n    \"\"\"\n    self.learners = learners if isinstance(learners, list) else ([learners] if learners else [])\n    self.merger = Merger() if self.learners else None\n    super().__init__(trainer, tester, scope)\n</code></pre>"},{"location":"reference/learner/#learner.Learner.UpdatingLearner.reset_state","title":"<code>reset_state()</code>","text":"<p>Resets state of all inner learners, the scope, and the trainer.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Resets state of all inner learners, the scope, and the trainer.\n    \"\"\"\n    if self.learners:\n        for learner in self.learners:\n            learner.reset_state()\n    self.scope.reset_state()\n    self.trainer.reset_state()\n</code></pre>"},{"location":"reference/learner/#learner.Learner.UpdatingLearner.train_test","title":"<code>train_test(wrapper)</code>","text":"<p>Iteratively trains and tests as long as the scope condition holds. If inner learners are provided, they are run in parallel and their predictions merged.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>Full dataset.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: Concatenated predictions from all iterations.</p> Source code in <code>sports_prediction_framework\\learner\\Learner.py</code> <pre><code>def train_test(self, wrapper: DataWrapper):\n    \"\"\"\n    Iteratively trains and tests as long as the scope condition holds.\n    If inner learners are provided, they are run in parallel and their predictions merged.\n\n    Args:\n        wrapper (DataWrapper): Full dataset.\n\n    Returns:\n        pd.DataFrame: Concatenated predictions from all iterations.\n    \"\"\"\n    outputs = []\n    copy = wrapper.deepcopy()\n    # iteratively check if still within dataset scope\n    while self.scope.holds():\n        if self.learners:\n            wrappers = []\n            for learner in self.learners:\n                wrappers.append(learner.compute(copy))\n                learner.update()\n            wrapper = self.merger.compute(wrappers)\n        outputs.append(super().train_test(wrapper))\n        self.update()\n\n    if self.tester is not None:\n        if len(outputs) == 0:\n            return pd.DataFrame()\n        features = pd.concat([data for data in outputs])\n        return features\n    return None\n</code></pre>"},{"location":"reference/learner/#learner.Tester.Tester","title":"<code>Tester</code>","text":"<p>Handles prediction for a given model on a dataset wrapped by DataWrapper.</p> Source code in <code>sports_prediction_framework\\learner\\Tester.py</code> <pre><code>class Tester:\n    \"\"\"\n    Handles prediction for a given model on a dataset wrapped by DataWrapper.\n    \"\"\"\n\n    def __init__(self, model: Model = None):\n        \"\"\"\n        Initializes the Tester with a model.\n\n        Args:\n            model (Model): The predictive model to be tested.\n        \"\"\"\n        self.model = model\n\n    def compute(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n        \"\"\"\n        Alias for the test method, runs prediction on the dataset.\n\n        Args:\n            dataset (DataWrapper): Dataset wrapper containing features.\n\n        Returns:\n            pd.DataFrame: Predictions with index aligned to dataset.\n        \"\"\"\n        return self.test(dataset)\n\n    def test(self, wrapper: DataWrapper) -&gt; pd.DataFrame:\n        \"\"\"\n        Generates predictions from the model using the provided DataWrapper.\n\n        Args:\n            wrapper (DataWrapper): Dataset wrapper.\n\n        Returns:\n            pd.DataFrame: Predictions indexed by the original dataset index.\n                          Columns depend on the model's output shape and type.\n        \"\"\"\n        # Select features based on model's expected input columns\n        if not self.model.in_cols:\n            features = wrapper.get_features()\n        else:\n            features = wrapper.get_dataframe()[self.model.in_cols]\n\n        # Scikit-learn model specific handling\n        if isinstance(self.model, ScikitModel):\n            if features.isnull().values.any():\n                print('Features contain nulls or NaNs in scikit predicting')\n                return pd.DataFrame()  # Return empty if invalid data\n\n            preds = self.model.predict(features)\n\n            # If multiclass/multilabel prediction, use class names as columns\n            if preds.shape[1] &gt; 1:\n                cols = self.model.scikit_model.classes_\n            else:\n                # Use label columns from the wrapper if single-output\n                cols = wrapper.data_handler.label_cols\n\n            return pd.DataFrame(index=wrapper.get_dataframe().index, data=preds, columns=cols)\n        else:\n            # For other model types, just convert predictions to DataFrame\n            preds = self.model.predict(features)\n            return pd.DataFrame(index=wrapper.get_dataframe().index, data=preds)\n</code></pre>"},{"location":"reference/learner/#learner.Tester.Tester.__init__","title":"<code>__init__(model=None)</code>","text":"<p>Initializes the Tester with a model.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>The predictive model to be tested.</p> <code>None</code> Source code in <code>sports_prediction_framework\\learner\\Tester.py</code> <pre><code>def __init__(self, model: Model = None):\n    \"\"\"\n    Initializes the Tester with a model.\n\n    Args:\n        model (Model): The predictive model to be tested.\n    \"\"\"\n    self.model = model\n</code></pre>"},{"location":"reference/learner/#learner.Tester.Tester.compute","title":"<code>compute(dataset)</code>","text":"<p>Alias for the test method, runs prediction on the dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset</code> <code>DataWrapper</code> <p>Dataset wrapper containing features.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Predictions with index aligned to dataset.</p> Source code in <code>sports_prediction_framework\\learner\\Tester.py</code> <pre><code>def compute(self, dataset: DataWrapper) -&gt; pd.DataFrame:\n    \"\"\"\n    Alias for the test method, runs prediction on the dataset.\n\n    Args:\n        dataset (DataWrapper): Dataset wrapper containing features.\n\n    Returns:\n        pd.DataFrame: Predictions with index aligned to dataset.\n    \"\"\"\n    return self.test(dataset)\n</code></pre>"},{"location":"reference/learner/#learner.Tester.Tester.test","title":"<code>test(wrapper)</code>","text":"<p>Generates predictions from the model using the provided DataWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>Dataset wrapper.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: Predictions indexed by the original dataset index.           Columns depend on the model's output shape and type.</p> Source code in <code>sports_prediction_framework\\learner\\Tester.py</code> <pre><code>def test(self, wrapper: DataWrapper) -&gt; pd.DataFrame:\n    \"\"\"\n    Generates predictions from the model using the provided DataWrapper.\n\n    Args:\n        wrapper (DataWrapper): Dataset wrapper.\n\n    Returns:\n        pd.DataFrame: Predictions indexed by the original dataset index.\n                      Columns depend on the model's output shape and type.\n    \"\"\"\n    # Select features based on model's expected input columns\n    if not self.model.in_cols:\n        features = wrapper.get_features()\n    else:\n        features = wrapper.get_dataframe()[self.model.in_cols]\n\n    # Scikit-learn model specific handling\n    if isinstance(self.model, ScikitModel):\n        if features.isnull().values.any():\n            print('Features contain nulls or NaNs in scikit predicting')\n            return pd.DataFrame()  # Return empty if invalid data\n\n        preds = self.model.predict(features)\n\n        # If multiclass/multilabel prediction, use class names as columns\n        if preds.shape[1] &gt; 1:\n            cols = self.model.scikit_model.classes_\n        else:\n            # Use label columns from the wrapper if single-output\n            cols = wrapper.data_handler.label_cols\n\n        return pd.DataFrame(index=wrapper.get_dataframe().index, data=preds, columns=cols)\n    else:\n        # For other model types, just convert predictions to DataFrame\n        preds = self.model.predict(features)\n        return pd.DataFrame(index=wrapper.get_dataframe().index, data=preds)\n</code></pre>"},{"location":"reference/learner/#learner.Trainer.Trainer","title":"<code>Trainer</code>","text":"Source code in <code>sports_prediction_framework\\learner\\Trainer.py</code> <pre><code>class Trainer:\n\n    def __init__(self, model: Model = None):\n        \"\"\"\n        Initialize the Trainer with a model instance.\n\n        Args:\n            model (Model, optional): The model to be trained.\n        \"\"\"\n        self.model = model\n\n    def compute(self, dataset: DataWrapper):\n        \"\"\"\n        Trigger the training process on the provided dataset.\n        \"\"\"\n        self.train(dataset)\n\n    def train(self, wrapper: DataWrapper):\n        \"\"\"\n        Train the model using features and labels extracted from the wrapper.\n\n        Args:\n            wrapper (DataWrapper): The dataset wrapper containing features and labels.\n        \"\"\"\n        if not self.model.in_cols:\n            features = wrapper.get_features()\n        else:\n            features = wrapper.get_dataframe()[self.model.in_cols]\n\n        # Let the model extract additional parameters from the data wrapper if needed\n        self.model.set_parameters_from_wrapper(wrapper)\n\n        # Fit the model on the selected features and labels\n        self.model.fit(features, wrapper.get_labels())\n\n    def reset_state(self):\n        \"\"\"\n        Reset the internal state of the model (if any).\n        \"\"\"\n        self.model.reset_state()\n</code></pre>"},{"location":"reference/learner/#learner.Trainer.Trainer.__init__","title":"<code>__init__(model=None)</code>","text":"<p>Initialize the Trainer with a model instance.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>Model</code> <p>The model to be trained.</p> <code>None</code> Source code in <code>sports_prediction_framework\\learner\\Trainer.py</code> <pre><code>def __init__(self, model: Model = None):\n    \"\"\"\n    Initialize the Trainer with a model instance.\n\n    Args:\n        model (Model, optional): The model to be trained.\n    \"\"\"\n    self.model = model\n</code></pre>"},{"location":"reference/learner/#learner.Trainer.Trainer.compute","title":"<code>compute(dataset)</code>","text":"<p>Trigger the training process on the provided dataset.</p> Source code in <code>sports_prediction_framework\\learner\\Trainer.py</code> <pre><code>def compute(self, dataset: DataWrapper):\n    \"\"\"\n    Trigger the training process on the provided dataset.\n    \"\"\"\n    self.train(dataset)\n</code></pre>"},{"location":"reference/learner/#learner.Trainer.Trainer.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset the internal state of the model (if any).</p> Source code in <code>sports_prediction_framework\\learner\\Trainer.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Reset the internal state of the model (if any).\n    \"\"\"\n    self.model.reset_state()\n</code></pre>"},{"location":"reference/learner/#learner.Trainer.Trainer.train","title":"<code>train(wrapper)</code>","text":"<p>Train the model using features and labels extracted from the wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>The dataset wrapper containing features and labels.</p> required Source code in <code>sports_prediction_framework\\learner\\Trainer.py</code> <pre><code>def train(self, wrapper: DataWrapper):\n    \"\"\"\n    Train the model using features and labels extracted from the wrapper.\n\n    Args:\n        wrapper (DataWrapper): The dataset wrapper containing features and labels.\n    \"\"\"\n    if not self.model.in_cols:\n        features = wrapper.get_features()\n    else:\n        features = wrapper.get_dataframe()[self.model.in_cols]\n\n    # Let the model extract additional parameters from the data wrapper if needed\n    self.model.set_parameters_from_wrapper(wrapper)\n\n    # Fit the model on the selected features and labels\n    self.model.fit(features, wrapper.get_labels())\n</code></pre>"},{"location":"reference/neural_model/","title":"Neural model","text":""},{"location":"reference/neural_model/#model.FlatModel.FlatModel","title":"<code>FlatModel</code>","text":"<p>               Bases: <code>NeuralModel</code></p> Source code in <code>sports_prediction_framework\\model\\FlatModel.py</code> <pre><code>class FlatModel(NeuralModel):\n\n    def __init__(self,params: dict, pretrained_weights: Optional[torch.Tensor] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Initialize the FlatModel. Creates an instance of the TorchFlat model and sets it up.\n\n        Args:\n            pretrained_weights (Optional[torch.Tensor]): Weights to initialize the model with,\n                                                          if provided. Defaults to None.\n            **kwargs: Additional keyword arguments passed to the parent class initializer.\n        \"\"\"\n        # Initialize the TorchFlat model with optional pretrained weights\n        super().__init__(**kwargs)\n        self.params = params\n        self.pretrained_weights = pretrained_weights\n\n        self.model = TorchFlat(pretrained_weights)\n        self.set_params(params)\n\n        # Call the complex initialization of the model to set up the layers\n        self.model.complex_init()\n\n    def set_parameters_from_wrapper(self, wrapper: MatchWrapper) -&gt; None:\n        \"\"\"\n        Adjust the model parameters based on the provided MatchWrapper.\n\n        Args:\n            wrapper (MatchWrapper): The wrapper that contains match-related data used to\n                                     configure the model (e.g., number of teams).\n        \"\"\"\n        # Set model parameters using data from the wrapper (e.g., number of teams)\n        self.model.set_parameters_from_wrapper(wrapper)\n\n    def reset_state(self):\n        self.model = TorchFlat(self.pretrained_weights)\n        self.set_params(self.params)\n\n        # Call the complex initialization of the model to set up the layers\n        self.model.complex_init()\n</code></pre>"},{"location":"reference/neural_model/#model.FlatModel.FlatModel.__init__","title":"<code>__init__(params, pretrained_weights=None, **kwargs)</code>","text":"<p>Initialize the FlatModel. Creates an instance of the TorchFlat model and sets it up.</p> <p>Parameters:</p> Name Type Description Default <code>pretrained_weights</code> <code>Optional[Tensor]</code> <p>Weights to initialize the model with,                                           if provided. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <p>Additional keyword arguments passed to the parent class initializer.</p> <code>{}</code> Source code in <code>sports_prediction_framework\\model\\FlatModel.py</code> <pre><code>def __init__(self,params: dict, pretrained_weights: Optional[torch.Tensor] = None, **kwargs) -&gt; None:\n    \"\"\"\n    Initialize the FlatModel. Creates an instance of the TorchFlat model and sets it up.\n\n    Args:\n        pretrained_weights (Optional[torch.Tensor]): Weights to initialize the model with,\n                                                      if provided. Defaults to None.\n        **kwargs: Additional keyword arguments passed to the parent class initializer.\n    \"\"\"\n    # Initialize the TorchFlat model with optional pretrained weights\n    super().__init__(**kwargs)\n    self.params = params\n    self.pretrained_weights = pretrained_weights\n\n    self.model = TorchFlat(pretrained_weights)\n    self.set_params(params)\n\n    # Call the complex initialization of the model to set up the layers\n    self.model.complex_init()\n</code></pre>"},{"location":"reference/neural_model/#model.FlatModel.FlatModel.set_parameters_from_wrapper","title":"<code>set_parameters_from_wrapper(wrapper)</code>","text":"<p>Adjust the model parameters based on the provided MatchWrapper.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>MatchWrapper</code> <p>The wrapper that contains match-related data used to                      configure the model (e.g., number of teams).</p> required Source code in <code>sports_prediction_framework\\model\\FlatModel.py</code> <pre><code>def set_parameters_from_wrapper(self, wrapper: MatchWrapper) -&gt; None:\n    \"\"\"\n    Adjust the model parameters based on the provided MatchWrapper.\n\n    Args:\n        wrapper (MatchWrapper): The wrapper that contains match-related data used to\n                                 configure the model (e.g., number of teams).\n    \"\"\"\n    # Set model parameters using data from the wrapper (e.g., number of teams)\n    self.model.set_parameters_from_wrapper(wrapper)\n</code></pre>"},{"location":"reference/optimizer/","title":"optimizer","text":""},{"location":"reference/optimizer/#optimizer.Optimizer.Optimizer","title":"<code>Optimizer</code>","text":"<p>A class for optimizing hyperparameters using Optuna.</p> <p>Attributes:</p> Name Type Description <code>wrapper</code> <code>DataWrapper</code> <p>Data handling object for training and evaluation.</p> <code>learner</code> <code>Learner</code> <p>Model wrapper that can be trained and evaluated.</p> <code>metric</code> <code>Metric</code> <p>Metric enum used for evaluation (e.g., Accuracy, F1 Score).</p> <code>search_space</code> <code>dict</code> <p>Dictionary defining the hyperparameter search space.</p> <code>n_trials</code> <code>int</code> <p>Number of trials to run during optimization.</p> <code>direction</code> <code>str</code> <p>Optimization direction ('maximize' or 'minimize').</p> <code>sampler</code> <code>BaseSampler</code> <p>Sampler for Optuna study.</p> Source code in <code>sports_prediction_framework\\optimizer\\Optimizer.py</code> <pre><code>class Optimizer:\n    \"\"\"\n    A class for optimizing hyperparameters using Optuna.\n\n    Attributes:\n        wrapper (DataWrapper): Data handling object for training and evaluation.\n        learner (Learner): Model wrapper that can be trained and evaluated.\n        metric (Metric): Metric enum used for evaluation (e.g., Accuracy, F1 Score).\n        search_space (dict): Dictionary defining the hyperparameter search space.\n        n_trials (int): Number of trials to run during optimization.\n        direction (str): Optimization direction ('maximize' or 'minimize').\n        sampler (optuna.samplers.BaseSampler, optional): Sampler for Optuna study.\n    \"\"\"\n\n    def __init__(\n        self,\n        wrapper: DataWrapper,\n        learner: Learner,\n        metric: Metric,\n        search_space: Dict[str, Tuple],\n        n_trials: int = 50,\n        direction: str = \"maximize\",\n        sampler: Optional[optuna.samplers.BaseSampler] = None,\n    ):\n        self.wrapper = wrapper\n        self.learner = learner\n        self.metric = metric\n        self.search_space = search_space\n        self.n_trials = n_trials\n        self.direction = direction\n        self.sampler = sampler\n        self.study = None\n\n    def run(self):\n        \"\"\"\n        Runs the optimization process using Optuna.\n        \"\"\"\n        self.study = optuna.create_study(direction=self.direction, sampler=self.sampler)\n        self.study.optimize(self._objective, n_trials=self.n_trials)\n\n    def _suggest_params(self, trial):\n        \"\"\"\n        Suggests hyperparameter values for the current trial.\n\n        Args:\n            trial (optuna.trial.Trial): The current Optuna trial.\n\n        Returns:\n            dict: A dictionary of suggested hyperparameter values.\n        \"\"\"\n        params = {}\n        for name, (ptype, *args) in self.search_space.items():\n            kwargs = {}\n            if args and isinstance(args[-1], dict):\n                kwargs = args[-1]\n                args = args[:-1]\n            suggest_fn = getattr(trial, f\"suggest_{ptype}\")\n            params[name] = suggest_fn(name, *args, **kwargs)\n        return params\n\n    def _objective(self, trial):\n        \"\"\"\n        Objective function for the Optuna optimization.\n\n        Args:\n            trial (optuna.trial.Trial): The trial object.\n\n        Returns:\n            float: The evaluation score based on the selected metric.\n        \"\"\"\n        try:\n            params = self._suggest_params(trial)\n            self.learner.reset_state()\n            self.learner.set_model_hyper_params(params)\n            preds = self.learner.compute(self.wrapper)\n            #print(preds.get_dataframe())\n            metrics, _ = evaluate_metrics(preds.get_dataframe(), 'macro')\n            print(metrics)\n\n            if self.metric.value not in metrics:\n                raise ValueError(f\"Metric '{self.metric.value}' not found in evaluation results.\")\n\n            score = metrics[self.metric.value]\n            if isinstance(score, pd.Series):\n                score = score.item()\n            print(f\"Trial {trial.number}: {params}, {self.metric.value} = {score:.4f}\")\n            return score\n\n        except Exception as e:\n            print(f\"Trial {trial.number} pruned due to error: {e}\")\n            raise optuna.TrialPruned()\n\n    def best_params(self) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the best hyperparameters found by the optimization.\n\n        Returns:\n            dict: Best hyperparameters if available, else an empty dictionary.\n        \"\"\"\n        return self.study.best_params if self.study else {}\n\n    def best_value(self) -&gt; float:\n        \"\"\"\n        Returns the best metric value achieved during the optimization.\n\n        Returns:\n            float: Best value if available, else NaN.\n        \"\"\"\n        return self.study.best_value if self.study else float(\"nan\")\n</code></pre>"},{"location":"reference/optimizer/#optimizer.Optimizer.Optimizer.best_params","title":"<code>best_params()</code>","text":"<p>Returns the best hyperparameters found by the optimization.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>Dict[str, Any]</code> <p>Best hyperparameters if available, else an empty dictionary.</p> Source code in <code>sports_prediction_framework\\optimizer\\Optimizer.py</code> <pre><code>def best_params(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the best hyperparameters found by the optimization.\n\n    Returns:\n        dict: Best hyperparameters if available, else an empty dictionary.\n    \"\"\"\n    return self.study.best_params if self.study else {}\n</code></pre>"},{"location":"reference/optimizer/#optimizer.Optimizer.Optimizer.best_value","title":"<code>best_value()</code>","text":"<p>Returns the best metric value achieved during the optimization.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Best value if available, else NaN.</p> Source code in <code>sports_prediction_framework\\optimizer\\Optimizer.py</code> <pre><code>def best_value(self) -&gt; float:\n    \"\"\"\n    Returns the best metric value achieved during the optimization.\n\n    Returns:\n        float: Best value if available, else NaN.\n    \"\"\"\n    return self.study.best_value if self.study else float(\"nan\")\n</code></pre>"},{"location":"reference/optimizer/#optimizer.Optimizer.Optimizer.run","title":"<code>run()</code>","text":"<p>Runs the optimization process using Optuna.</p> Source code in <code>sports_prediction_framework\\optimizer\\Optimizer.py</code> <pre><code>def run(self):\n    \"\"\"\n    Runs the optimization process using Optuna.\n    \"\"\"\n    self.study = optuna.create_study(direction=self.direction, sampler=self.sampler)\n    self.study.optimize(self._objective, n_trials=self.n_trials)\n</code></pre>"},{"location":"reference/scope/","title":"scope","text":""},{"location":"reference/scope/#transformer.Scope.EnumScope","title":"<code>EnumScope</code>","text":"<p>               Bases: <code>Scope</code></p> <p>Scope that iterates over an enumerated list of values for a given column.</p>"},{"location":"reference/scope/#transformer.Scope.EnumScope--parameters","title":"Parameters","text":"<p>wrapper : DataWrapper, optional     Data wrapper providing access to data. parameters : dict, optional     Configuration including:       - col (str): column name to filter on (default 'League')       - enum (list): list of enum values to iterate (default ['Bundesliga'])</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class EnumScope(Scope):\n    \"\"\"\n    Scope that iterates over an enumerated list of values for a given column.\n\n    Parameters\n    ----------\n    wrapper : DataWrapper, optional\n        Data wrapper providing access to data.\n    parameters : dict, optional\n        Configuration including:\n          - col (str): column name to filter on (default 'League')\n          - enum (list): list of enum values to iterate (default ['Bundesliga'])\n    \"\"\"\n\n    default_parameters = {'col': 'League', 'enum': ['Bundesliga']}\n    cur_index = 0\n\n    def __init__(self, wrapper=None, parameters=default_parameters):\n        super().__init__(wrapper, parameters)\n\n    def set_parameters_from_wrapper(self, wrapper: DataWrapper):\n        \"\"\"\n        Initialize enum list from unique values of the column if not provided.\n\n        Parameters\n        ----------\n        wrapper : DataWrapper\n            Data wrapper to extract unique column values.\n        \"\"\"\n        if 'enum' not in self.parameters:\n            self.enum = pd.unique(self.wrapper.get_columns(self.col)).tolist()\n\n    def shift(self):\n        \"\"\"\n        Advance to the next enum value.\n        \"\"\"\n        self.cur_index += 1\n\n    def inside(self):\n        \"\"\"\n        Check if the current enum index is within the list bounds.\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return self.cur_index &lt; len(self.enum)\n\n    def reset_state(self):\n        \"\"\"\n        Reset the current enum index to zero.\n        \"\"\"\n        self.cur_index = 0\n\n    def current_state(self):\n        \"\"\"\n        Return the current enum value as a list for filtering.\n\n        Returns\n        -------\n        tuple\n            (column_name, [current_enum_value])\n        \"\"\"\n        return (self.col, [self.enum[self.cur_index]])\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.EnumScope.current_state","title":"<code>current_state()</code>","text":"<p>Return the current enum value as a list for filtering.</p>"},{"location":"reference/scope/#transformer.Scope.EnumScope.current_state--returns","title":"Returns","text":"<p>tuple     (column_name, [current_enum_value])</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def current_state(self):\n    \"\"\"\n    Return the current enum value as a list for filtering.\n\n    Returns\n    -------\n    tuple\n        (column_name, [current_enum_value])\n    \"\"\"\n    return (self.col, [self.enum[self.cur_index]])\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.EnumScope.inside","title":"<code>inside()</code>","text":"<p>Check if the current enum index is within the list bounds.</p>"},{"location":"reference/scope/#transformer.Scope.EnumScope.inside--returns","title":"Returns","text":"<p>bool</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def inside(self):\n    \"\"\"\n    Check if the current enum index is within the list bounds.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self.cur_index &lt; len(self.enum)\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.EnumScope.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset the current enum index to zero.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Reset the current enum index to zero.\n    \"\"\"\n    self.cur_index = 0\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.EnumScope.set_parameters_from_wrapper","title":"<code>set_parameters_from_wrapper(wrapper)</code>","text":"<p>Initialize enum list from unique values of the column if not provided.</p>"},{"location":"reference/scope/#transformer.Scope.EnumScope.set_parameters_from_wrapper--parameters","title":"Parameters","text":"<p>wrapper : DataWrapper     Data wrapper to extract unique column values.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def set_parameters_from_wrapper(self, wrapper: DataWrapper):\n    \"\"\"\n    Initialize enum list from unique values of the column if not provided.\n\n    Parameters\n    ----------\n    wrapper : DataWrapper\n        Data wrapper to extract unique column values.\n    \"\"\"\n    if 'enum' not in self.parameters:\n        self.enum = pd.unique(self.wrapper.get_columns(self.col)).tolist()\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.EnumScope.shift","title":"<code>shift()</code>","text":"<p>Advance to the next enum value.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def shift(self):\n    \"\"\"\n    Advance to the next enum value.\n    \"\"\"\n    self.cur_index += 1\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.Scope","title":"<code>Scope</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for data segmentation scopes.</p> <p>Defines the interface and common initialization logic for various types of scopes used to segment or window datasets (e.g., by season, league, or time).</p>"},{"location":"reference/scope/#transformer.Scope.Scope--parameters","title":"Parameters","text":"<p>wrapper : DataWrapper, optional     Wrapper object providing access to the underlying data. parameters : dict, optional     Dictionary of parameters used to configure the scope.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class Scope(ABC):\n    \"\"\"\n    Abstract base class for data segmentation scopes.\n\n    Defines the interface and common initialization logic for various types of\n    scopes used to segment or window datasets (e.g., by season, league, or time).\n\n    Parameters\n    ----------\n    wrapper : DataWrapper, optional\n        Wrapper object providing access to the underlying data.\n    parameters : dict, optional\n        Dictionary of parameters used to configure the scope.\n    \"\"\"\n\n    def __init__(self, wrapper: DataWrapper = None, parameters=None):\n        self.wrapper = wrapper\n        self.parameters = parameters\n        AttributeSetter.set_attributes(self, parameters)\n\n    def shift(self):\n        \"\"\"\n        Move or adjust the scope window/segment forward.\n\n        Intended to be implemented by subclasses.\n        \"\"\"\n        pass\n\n    def inside(self):\n        \"\"\"\n        Check if the current scope window/segment is still within valid bounds.\n\n        Returns\n        -------\n        bool\n            True if still within bounds, False otherwise.\n\n        Intended to be implemented by subclasses.\n        \"\"\"\n        pass\n\n    def reset_state(self):\n        \"\"\"\n        Reset the scope to its initial state.\n\n        Intended to be implemented by subclasses.\n        \"\"\"\n        pass\n\n    def current_state(self):\n        \"\"\"\n        Return the current scope state, typically the segment or window limits.\n\n        Returns\n        -------\n        tuple\n            Typically (column_name, (start_value, end_value)) or similar.\n\n        Intended to be implemented by subclasses.\n        \"\"\"\n        pass\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.Scope.current_state","title":"<code>current_state()</code>","text":"<p>Return the current scope state, typically the segment or window limits.</p>"},{"location":"reference/scope/#transformer.Scope.Scope.current_state--returns","title":"Returns","text":"<p>tuple     Typically (column_name, (start_value, end_value)) or similar.</p> <p>Intended to be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def current_state(self):\n    \"\"\"\n    Return the current scope state, typically the segment or window limits.\n\n    Returns\n    -------\n    tuple\n        Typically (column_name, (start_value, end_value)) or similar.\n\n    Intended to be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.Scope.inside","title":"<code>inside()</code>","text":"<p>Check if the current scope window/segment is still within valid bounds.</p>"},{"location":"reference/scope/#transformer.Scope.Scope.inside--returns","title":"Returns","text":"<p>bool     True if still within bounds, False otherwise.</p> <p>Intended to be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def inside(self):\n    \"\"\"\n    Check if the current scope window/segment is still within valid bounds.\n\n    Returns\n    -------\n    bool\n        True if still within bounds, False otherwise.\n\n    Intended to be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.Scope.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset the scope to its initial state.</p> <p>Intended to be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Reset the scope to its initial state.\n\n    Intended to be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.Scope.shift","title":"<code>shift()</code>","text":"<p>Move or adjust the scope window/segment forward.</p> <p>Intended to be implemented by subclasses.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def shift(self):\n    \"\"\"\n    Move or adjust the scope window/segment forward.\n\n    Intended to be implemented by subclasses.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeExpander","title":"<code>ScopeExpander</code>","text":"<p>               Bases: <code>WindowScope</code></p> <p>Scope variant that expands the window size by a stride on each shift.</p>"},{"location":"reference/scope/#transformer.Scope.ScopeExpander--methods","title":"Methods","text":"<p>shift():     Increase the window size by the stride value. inside():     Returns whether the expanded window end is within the maximum allowed.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class ScopeExpander(WindowScope):\n    \"\"\"\n    Scope variant that expands the window size by a stride on each shift.\n\n    Methods\n    -------\n    shift():\n        Increase the window size by the stride value.\n    inside():\n        Returns whether the expanded window end is within the maximum allowed.\n    \"\"\"\n\n    def shift(self):\n        \"\"\"\n        Increase the window size by stride.\n        \"\"\"\n        self.size += self.stride\n\n    def inside(self):\n        \"\"\"\n        Check if the window end is still within max.\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return self.start + self.size &lt;= self.max\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeExpander.inside","title":"<code>inside()</code>","text":"<p>Check if the window end is still within max.</p>"},{"location":"reference/scope/#transformer.Scope.ScopeExpander.inside--returns","title":"Returns","text":"<p>bool</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def inside(self):\n    \"\"\"\n    Check if the window end is still within max.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self.start + self.size &lt;= self.max\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeExpander.shift","title":"<code>shift()</code>","text":"<p>Increase the window size by stride.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def shift(self):\n    \"\"\"\n    Increase the window size by stride.\n    \"\"\"\n    self.size += self.stride\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeRoller","title":"<code>ScopeRoller</code>","text":"<p>               Bases: <code>WindowScope</code></p> <p>Scope variant that rolls the window start forward by the stride on each shift.</p>"},{"location":"reference/scope/#transformer.Scope.ScopeRoller--methods","title":"Methods","text":"<p>shift():     Move the window start by stride. inside():     Returns whether the window start is still within the maximum allowed.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class ScopeRoller(WindowScope):\n    \"\"\"\n    Scope variant that rolls the window start forward by the stride on each shift.\n\n    Methods\n    -------\n    shift():\n        Move the window start by stride.\n    inside():\n        Returns whether the window start is still within the maximum allowed.\n    \"\"\"\n\n    def shift(self):\n        \"\"\"\n        Move the window start forward by stride.\n        \"\"\"\n        self.start += self.stride\n\n    def inside(self):\n        \"\"\"\n        Check if the window start is still within max.\n\n        Returns\n        -------\n        bool\n        \"\"\"\n        return self.start &lt;= self.max\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeRoller.inside","title":"<code>inside()</code>","text":"<p>Check if the window start is still within max.</p>"},{"location":"reference/scope/#transformer.Scope.ScopeRoller.inside--returns","title":"Returns","text":"<p>bool</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def inside(self):\n    \"\"\"\n    Check if the window start is still within max.\n\n    Returns\n    -------\n    bool\n    \"\"\"\n    return self.start &lt;= self.max\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.ScopeRoller.shift","title":"<code>shift()</code>","text":"<p>Move the window start forward by stride.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def shift(self):\n    \"\"\"\n    Move the window start forward by stride.\n    \"\"\"\n    self.start += self.stride\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.TestingWindowScope","title":"<code>TestingWindowScope</code>","text":"<p>               Bases: <code>WindowScope</code></p> <p>Scope for testing windows that depend on a related training window scope.</p>"},{"location":"reference/scope/#transformer.Scope.TestingWindowScope--parameters","title":"Parameters","text":"<p>training_window_scope : WindowScope     The training window scope to base the testing window on. parameters : dict, optional     Parameters for the testing window scope (default sets 'col' to 'Season', 'size' to 1).</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class TestingWindowScope(WindowScope):\n    \"\"\"\n    Scope for testing windows that depend on a related training window scope.\n\n    Parameters\n    ----------\n    training_window_scope : WindowScope\n        The training window scope to base the testing window on.\n    parameters : dict, optional\n        Parameters for the testing window scope (default sets 'col' to 'Season', 'size' to 1).\n    \"\"\"\n\n    name = 'testing_window_scope'\n    init_parameters = {name: {'col': 'Season', 'size': 1}}\n\n    def __init__(self, training_window_scope: WindowScope, parameters=init_parameters, **kwargs):\n        self.training_window_scope = training_window_scope\n        super().__init__(parameters=parameters, **kwargs)\n\n    def set_parameters(self, parameters):\n        \"\"\"\n        Override to set testing window parameters relative to the training window.\n\n        Parameters\n        ----------\n        parameters : dict\n            Parameters dict (not currently used for custom values).\n\n        Notes\n        -----\n        This method sets:\n          - start: training start + training size + 1\n          - max: training max\n          - stride: training stride\n          - orig_start: initialized to start\n          - orig_size: initialized to current size\n        \"\"\"\n        if parameters is not None:\n            self.start = self.training_window_scope.start + self.training_window_scope.size + 1\n            self.max = self.training_window_scope.max\n            self.stride = self.training_window_scope.stride\n            self.orig_start = self.start\n            self.orig_size = self.size\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.TestingWindowScope.set_parameters","title":"<code>set_parameters(parameters)</code>","text":"<p>Override to set testing window parameters relative to the training window.</p>"},{"location":"reference/scope/#transformer.Scope.TestingWindowScope.set_parameters--parameters","title":"Parameters","text":"<p>parameters : dict     Parameters dict (not currently used for custom values).</p>"},{"location":"reference/scope/#transformer.Scope.TestingWindowScope.set_parameters--notes","title":"Notes","text":"<p>This method sets:   - start: training start + training size + 1   - max: training max   - stride: training stride   - orig_start: initialized to start   - orig_size: initialized to current size</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def set_parameters(self, parameters):\n    \"\"\"\n    Override to set testing window parameters relative to the training window.\n\n    Parameters\n    ----------\n    parameters : dict\n        Parameters dict (not currently used for custom values).\n\n    Notes\n    -----\n    This method sets:\n      - start: training start + training size + 1\n      - max: training max\n      - stride: training stride\n      - orig_start: initialized to start\n      - orig_size: initialized to current size\n    \"\"\"\n    if parameters is not None:\n        self.start = self.training_window_scope.start + self.training_window_scope.size + 1\n        self.max = self.training_window_scope.max\n        self.stride = self.training_window_scope.stride\n        self.orig_start = self.start\n        self.orig_size = self.size\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.WindowScope","title":"<code>WindowScope</code>","text":"<p>               Bases: <code>Scope</code></p> <p>Scope implementation that defines a window on a continuous or ordinal column (e.g., season, year), with a fixed size and stride for iteration.</p>"},{"location":"reference/scope/#transformer.Scope.WindowScope--parameters","title":"Parameters","text":"<p>wrapper : DataWrapper, optional     Data wrapper providing the dataset. parameters : dict, optional     Configuration parameters including:       - col (str): column name to window on (default 'Season')       - start (int): starting value of the window (default 2000)       - max (int): maximum value for the window (default 2005)       - size (int): size of the window (default 1)       - stride (int): step size to move the window (default 2)</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>class WindowScope(Scope):\n    \"\"\"\n    Scope implementation that defines a window on a continuous or ordinal column\n    (e.g., season, year), with a fixed size and stride for iteration.\n\n    Parameters\n    ----------\n    wrapper : DataWrapper, optional\n        Data wrapper providing the dataset.\n    parameters : dict, optional\n        Configuration parameters including:\n          - col (str): column name to window on (default 'Season')\n          - start (int): starting value of the window (default 2000)\n          - max (int): maximum value for the window (default 2005)\n          - size (int): size of the window (default 1)\n          - stride (int): step size to move the window (default 2)\n    \"\"\"\n\n    default_parameters = {'col': 'Season', 'start': 2000, 'max': 2005, 'size': 1, 'stride': 2}\n\n    def __init__(self, wrapper: DataWrapper = None, parameters=default_parameters):\n        super().__init__(wrapper, parameters)\n        if self.parameters is not None:\n            if 'start' in self.parameters:\n                self.start = self.parameters['start']\n            elif self.wrapper is not None and self.parameters['col'] is not None:\n                self.start = self.wrapper.get_dataframe()[self.parameters['col']].min()\n            if 'max' in self.parameters:\n                self.max = self.parameters['max']\n            elif self.wrapper is not None:\n                self.max = self.wrapper.get_dataframe()[self.parameters['col']].max()\n            self.orig_start = self.start\n            self.orig_size = self.size\n\n    def reset_state(self):\n        \"\"\"\n        Reset the window to its original start and size.\n        \"\"\"\n        self.start = self.orig_start\n        self.size = self.orig_size\n\n    def current_state(self):\n        \"\"\"\n        Return the current window range as a tuple with the column and start/end.\n\n        Returns\n        -------\n        tuple\n            (column_name, (start_value, end_value))\n        \"\"\"\n        if isinstance(self.start, int) or isinstance(self.size, int):\n            return self.col, (self.start, self.start + self.size + timedelta(days=1).days)\n        return self.col, (self.start, self.start + self.size + timedelta(days=1))\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.WindowScope.current_state","title":"<code>current_state()</code>","text":"<p>Return the current window range as a tuple with the column and start/end.</p>"},{"location":"reference/scope/#transformer.Scope.WindowScope.current_state--returns","title":"Returns","text":"<p>tuple     (column_name, (start_value, end_value))</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def current_state(self):\n    \"\"\"\n    Return the current window range as a tuple with the column and start/end.\n\n    Returns\n    -------\n    tuple\n        (column_name, (start_value, end_value))\n    \"\"\"\n    if isinstance(self.start, int) or isinstance(self.size, int):\n        return self.col, (self.start, self.start + self.size + timedelta(days=1).days)\n    return self.col, (self.start, self.start + self.size + timedelta(days=1))\n</code></pre>"},{"location":"reference/scope/#transformer.Scope.WindowScope.reset_state","title":"<code>reset_state()</code>","text":"<p>Reset the window to its original start and size.</p> Source code in <code>sports_prediction_framework\\transformer\\Scope.py</code> <pre><code>def reset_state(self):\n    \"\"\"\n    Reset the window to its original start and size.\n    \"\"\"\n    self.start = self.orig_start\n    self.size = self.orig_size\n</code></pre>"},{"location":"reference/simulation/","title":"Base class","text":""},{"location":"reference/simulation/#simulation.Simulation.Simulation","title":"<code>Simulation</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for betting strategy simulations.</p> <p>Provides a standardized interface and shared functionality for evaluating betting strategies using model predictions, actual match outcomes, and betting odds.</p> <p>Parameters:</p> Name Type Description Default <code>datawrapper</code> <code>DataWrapper</code> <p>Object providing access to the underlying match dataframe.</p> required <p>Attributes:</p> Name Type Description <code>df</code> <code>DataFrame</code> <p>Copy of the dataframe containing match data, including probabilities and results.</p> <code>results</code> <code>list of float</code> <p>List of profit/loss values for each match in the simulation.</p> Source code in <code>sports_prediction_framework\\simulation\\Simulation.py</code> <pre><code>class Simulation(ABC):\n    \"\"\"\n    Abstract base class for betting strategy simulations.\n\n    Provides a standardized interface and shared functionality for evaluating\n    betting strategies using model predictions, actual match outcomes, and betting odds.\n\n    Args:\n        datawrapper (DataWrapper): Object providing access to the underlying match dataframe.\n\n    Attributes:\n        df (pandas.DataFrame): Copy of the dataframe containing match data, including probabilities and results.\n        results (list of float): List of profit/loss values for each match in the simulation.\n    \"\"\"\n\n    def __init__(self, datawrapper: DataWrapper):\n        \"\"\"\n        Initialize the Simulation base class.\n\n        Args:\n            datawrapper (DataWrapper): A wrapper object that provides access to the match dataframe.\n\n        Notes:\n            Drops rows with NaN in any of the probability columns (0, 1, 2).\n            Also creates a 'prediction' column based on the highest predicted probability\n            among columns 0, 1, and 2, corresponding to draw, home win, and away win.\n        \"\"\"\n        self.datawrapper = datawrapper\n        self.df = datawrapper.get_dataframe().copy()\n\n        # Ensure columns 0,1,2 are numeric\n        for col in [0, 1, 2]:\n            self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n\n        # Drop rows with NaN in any of the probability columns\n        self.df = self.df.dropna(subset=[0, 1, 2])\n\n        # Predict the most likely outcome (0: draw, 1: home win, 2: away win)\n        self.df[\"prediction\"] = self.df[[0, 1, 2]].idxmax(axis=1).astype(int)\n\n        self.results = []\n\n    @abstractmethod\n    def run(self):\n        \"\"\"\n        Run the betting simulation strategy.\n\n        This method must be implemented by subclasses to define how profits/losses\n        are calculated and recorded in `self.results`.\n        \"\"\"\n        pass\n\n    def evaluate(self):\n        \"\"\"\n        Evaluate the simulation's performance.\n\n        Returns:\n            dict: A dictionary containing the following keys:\n                - total_return (float): Total sum of profits/losses.\n                - mean_return (float): Average profit/loss per bet.\n                - std_return (float): Standard deviation of profits/losses.\n                - sharpe_ratio (float): Ratio of mean return to standard deviation.\n        \"\"\"\n        returns = pd.Series(self.results)\n        total_return = returns.sum()\n        mean_return = returns.mean()\n        std_return = returns.std()\n        sharpe_ratio = mean_return / std_return if std_return != 0 else float(\"nan\")\n        return {\n            \"total_return\": total_return,\n            \"mean_return\": mean_return,\n            \"std_return\": std_return,\n            \"sharpe_ratio\": sharpe_ratio\n        }\n\n    def summary(self):\n        \"\"\"\n        Print a summary of evaluation metrics to the console.\n        \"\"\"\n        evals = self.evaluate()\n        print(f\"Total Return:  {evals['total_return']:.2f}\")\n        print(f\"Mean Return:   {evals['mean_return']:.4f}\")\n        print(f\"Std Dev:       {evals['std_return']:.4f}\")\n        print(f\"Sharpe Ratio:  {evals['sharpe_ratio']:.4f}\")\n</code></pre>"},{"location":"reference/simulation/#simulation.Simulation.Simulation.__init__","title":"<code>__init__(datawrapper)</code>","text":"<p>Initialize the Simulation base class.</p> <p>Parameters:</p> Name Type Description Default <code>datawrapper</code> <code>DataWrapper</code> <p>A wrapper object that provides access to the match dataframe.</p> required Notes <p>Drops rows with NaN in any of the probability columns (0, 1, 2). Also creates a 'prediction' column based on the highest predicted probability among columns 0, 1, and 2, corresponding to draw, home win, and away win.</p> Source code in <code>sports_prediction_framework\\simulation\\Simulation.py</code> <pre><code>def __init__(self, datawrapper: DataWrapper):\n    \"\"\"\n    Initialize the Simulation base class.\n\n    Args:\n        datawrapper (DataWrapper): A wrapper object that provides access to the match dataframe.\n\n    Notes:\n        Drops rows with NaN in any of the probability columns (0, 1, 2).\n        Also creates a 'prediction' column based on the highest predicted probability\n        among columns 0, 1, and 2, corresponding to draw, home win, and away win.\n    \"\"\"\n    self.datawrapper = datawrapper\n    self.df = datawrapper.get_dataframe().copy()\n\n    # Ensure columns 0,1,2 are numeric\n    for col in [0, 1, 2]:\n        self.df[col] = pd.to_numeric(self.df[col], errors='coerce')\n\n    # Drop rows with NaN in any of the probability columns\n    self.df = self.df.dropna(subset=[0, 1, 2])\n\n    # Predict the most likely outcome (0: draw, 1: home win, 2: away win)\n    self.df[\"prediction\"] = self.df[[0, 1, 2]].idxmax(axis=1).astype(int)\n\n    self.results = []\n</code></pre>"},{"location":"reference/simulation/#simulation.Simulation.Simulation.evaluate","title":"<code>evaluate()</code>","text":"<p>Evaluate the simulation's performance.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary containing the following keys: - total_return (float): Total sum of profits/losses. - mean_return (float): Average profit/loss per bet. - std_return (float): Standard deviation of profits/losses. - sharpe_ratio (float): Ratio of mean return to standard deviation.</p> Source code in <code>sports_prediction_framework\\simulation\\Simulation.py</code> <pre><code>def evaluate(self):\n    \"\"\"\n    Evaluate the simulation's performance.\n\n    Returns:\n        dict: A dictionary containing the following keys:\n            - total_return (float): Total sum of profits/losses.\n            - mean_return (float): Average profit/loss per bet.\n            - std_return (float): Standard deviation of profits/losses.\n            - sharpe_ratio (float): Ratio of mean return to standard deviation.\n    \"\"\"\n    returns = pd.Series(self.results)\n    total_return = returns.sum()\n    mean_return = returns.mean()\n    std_return = returns.std()\n    sharpe_ratio = mean_return / std_return if std_return != 0 else float(\"nan\")\n    return {\n        \"total_return\": total_return,\n        \"mean_return\": mean_return,\n        \"std_return\": std_return,\n        \"sharpe_ratio\": sharpe_ratio\n    }\n</code></pre>"},{"location":"reference/simulation/#simulation.Simulation.Simulation.run","title":"<code>run()</code>  <code>abstractmethod</code>","text":"<p>Run the betting simulation strategy.</p> <p>This method must be implemented by subclasses to define how profits/losses are calculated and recorded in <code>self.results</code>.</p> Source code in <code>sports_prediction_framework\\simulation\\Simulation.py</code> <pre><code>@abstractmethod\ndef run(self):\n    \"\"\"\n    Run the betting simulation strategy.\n\n    This method must be implemented by subclasses to define how profits/losses\n    are calculated and recorded in `self.results`.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/simulation/#simulation.Simulation.Simulation.summary","title":"<code>summary()</code>","text":"<p>Print a summary of evaluation metrics to the console.</p> Source code in <code>sports_prediction_framework\\simulation\\Simulation.py</code> <pre><code>def summary(self):\n    \"\"\"\n    Print a summary of evaluation metrics to the console.\n    \"\"\"\n    evals = self.evaluate()\n    print(f\"Total Return:  {evals['total_return']:.2f}\")\n    print(f\"Mean Return:   {evals['mean_return']:.4f}\")\n    print(f\"Std Dev:       {evals['std_return']:.4f}\")\n    print(f\"Sharpe Ratio:  {evals['sharpe_ratio']:.4f}\")\n</code></pre>"},{"location":"reference/simulation_advanced/","title":"Simulation implementations","text":""},{"location":"reference/simulation_advanced/#simulation.FlatBettingSimulation.FlatBettingSimulation","title":"<code>FlatBettingSimulation</code>","text":"<p>               Bases: <code>Simulation</code></p> <p>Implements a flat betting strategy simulation.</p> <p>In this simulation, a fixed stake is placed on each match based on the model's predicted outcome. If the prediction is correct, the return is calculated as (odds - 1) * stake. If incorrect, the entire stake is lost.</p>"},{"location":"reference/simulation_advanced/#simulation.FlatBettingSimulation.FlatBettingSimulation--attributes","title":"Attributes:","text":"<p>stake : float     The fixed amount to bet on each match.</p> Source code in <code>sports_prediction_framework\\simulation\\FlatBettingSimulation.py</code> <pre><code>class FlatBettingSimulation(Simulation):\n    \"\"\"\n    Implements a flat betting strategy simulation.\n\n    In this simulation, a fixed stake is placed on each match based on the\n    model's predicted outcome. If the prediction is correct, the return is\n    calculated as (odds - 1) * stake. If incorrect, the entire stake is lost.\n\n    Attributes:\n    -----------\n    stake : float\n        The fixed amount to bet on each match.\n    \"\"\"\n\n    def __init__(self, datawrapper: DataWrapper, stake=1.0):\n        \"\"\"\n        Initialize the FlatBettingSimulation.\n\n        Parameters:\n        -----------\n        datawrapper : DataWrapper\n            A wrapper object that provides access to the match dataframe.\n        stake : float, optional (default=1.0)\n            The fixed amount to wager on each prediction.\n        \"\"\"\n        super().__init__(datawrapper)\n        self.stake = stake\n\n    def run(self):\n        \"\"\"\n        Execute the flat betting simulation.\n\n        For each row in the dataframe, places a bet on the predicted outcome.\n        If the prediction matches the actual result, calculates profit based\n        on the odds. Otherwise, records a loss equal to the stake.\n        \"\"\"\n        for _, row in self.df.iterrows():\n            pred = row[\"prediction\"]\n            actual = row[\"WDL\"]\n\n            # Select corresponding odds\n            if pred == 1:\n                odds = row[\"odds_1\"]\n            elif pred == 0:\n                odds = row[\"odds_X\"]\n            elif pred == 2:\n                odds = row[\"odds_2\"]\n            else:\n                self.results.append(0)\n                continue\n\n            # Skip if odds are invalid\n            if pd.isna(odds) or odds &lt;= 1.0:\n                self.results.append(0)\n                continue\n\n            # Calculate return\n            if pred == actual:\n                profit = (odds - 1) * self.stake\n            else:\n                profit = -self.stake\n\n            self.results.append(profit)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.FlatBettingSimulation.FlatBettingSimulation.__init__","title":"<code>__init__(datawrapper, stake=1.0)</code>","text":"<p>Initialize the FlatBettingSimulation.</p>"},{"location":"reference/simulation_advanced/#simulation.FlatBettingSimulation.FlatBettingSimulation.__init__--parameters","title":"Parameters:","text":"<p>datawrapper : DataWrapper     A wrapper object that provides access to the match dataframe. stake : float, optional (default=1.0)     The fixed amount to wager on each prediction.</p> Source code in <code>sports_prediction_framework\\simulation\\FlatBettingSimulation.py</code> <pre><code>def __init__(self, datawrapper: DataWrapper, stake=1.0):\n    \"\"\"\n    Initialize the FlatBettingSimulation.\n\n    Parameters:\n    -----------\n    datawrapper : DataWrapper\n        A wrapper object that provides access to the match dataframe.\n    stake : float, optional (default=1.0)\n        The fixed amount to wager on each prediction.\n    \"\"\"\n    super().__init__(datawrapper)\n    self.stake = stake\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.FlatBettingSimulation.FlatBettingSimulation.run","title":"<code>run()</code>","text":"<p>Execute the flat betting simulation.</p> <p>For each row in the dataframe, places a bet on the predicted outcome. If the prediction matches the actual result, calculates profit based on the odds. Otherwise, records a loss equal to the stake.</p> Source code in <code>sports_prediction_framework\\simulation\\FlatBettingSimulation.py</code> <pre><code>def run(self):\n    \"\"\"\n    Execute the flat betting simulation.\n\n    For each row in the dataframe, places a bet on the predicted outcome.\n    If the prediction matches the actual result, calculates profit based\n    on the odds. Otherwise, records a loss equal to the stake.\n    \"\"\"\n    for _, row in self.df.iterrows():\n        pred = row[\"prediction\"]\n        actual = row[\"WDL\"]\n\n        # Select corresponding odds\n        if pred == 1:\n            odds = row[\"odds_1\"]\n        elif pred == 0:\n            odds = row[\"odds_X\"]\n        elif pred == 2:\n            odds = row[\"odds_2\"]\n        else:\n            self.results.append(0)\n            continue\n\n        # Skip if odds are invalid\n        if pd.isna(odds) or odds &lt;= 1.0:\n            self.results.append(0)\n            continue\n\n        # Calculate return\n        if pred == actual:\n            profit = (odds - 1) * self.stake\n        else:\n            profit = -self.stake\n\n        self.results.append(profit)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.KellySimulation.KellySimulation","title":"<code>KellySimulation</code>","text":"<p>               Bases: <code>Simulation</code></p> <p>Kelly betting simulation.</p> <p>Bets a fraction of the bankroll based on the Kelly criterion, maximizing the expected logarithmic growth of wealth.</p>"},{"location":"reference/simulation_advanced/#simulation.KellySimulation.KellySimulation--attributes","title":"Attributes","text":"<p>data_wrapper : DataWrapper     DataWrapper instance containing the data to simulate on. initial_bankroll : float     The starting bankroll, default is 1.0.</p> Source code in <code>sports_prediction_framework\\simulation\\KellySimulation.py</code> <pre><code>class KellySimulation(Simulation):\n    \"\"\"\n    Kelly betting simulation.\n\n    Bets a fraction of the bankroll based on the Kelly criterion, maximizing the\n    expected logarithmic growth of wealth.\n\n    Attributes\n    ----------\n    data_wrapper : DataWrapper\n        DataWrapper instance containing the data to simulate on.\n    initial_bankroll : float\n        The starting bankroll, default is 1.0.\n\n    \"\"\"\n\n    def __init__(self, data_wrapper, initial_bankroll=1.0):\n        \"\"\"\n        Initialize KellySimulation.\n\n        Parameters\n        ----------\n        data_wrapper : DataWrapper\n            DataWrapper instance holding the data.\n        initial_bankroll : float, optional\n            Starting bankroll (default is 1.0).\n        \"\"\"\n        super().__init__(data_wrapper)\n        self.initial_bankroll = initial_bankroll\n\n    def run(self):\n        df = self.df.copy()\n        bankroll = self.initial_bankroll\n        self.bankroll_history = [bankroll]\n\n        odds_map = {0: 'odds_1', 1: 'odds_X', 2: 'odd_2'}\n\n        for _, row in df.iterrows():\n            pred = row['prediction']\n            prob = row[pred]\n            odds = row[odds_map[pred]]\n\n            edge = prob * (odds - 1) - (1 - prob)\n            fraction = max(edge / (odds - 1), 0) if odds &gt; 1 else 0\n\n            bet_amount = bankroll * fraction\n\n            win = 1 if row['WDL'] == pred else 0\n            ret = bet_amount * (odds if win else 0) - bet_amount\n\n            bankroll += ret\n            self.bankroll_history.append(bankroll)\n            self.results.append(ret)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.KellySimulation.KellySimulation.__init__","title":"<code>__init__(data_wrapper, initial_bankroll=1.0)</code>","text":"<p>Initialize KellySimulation.</p>"},{"location":"reference/simulation_advanced/#simulation.KellySimulation.KellySimulation.__init__--parameters","title":"Parameters","text":"<p>data_wrapper : DataWrapper     DataWrapper instance holding the data. initial_bankroll : float, optional     Starting bankroll (default is 1.0).</p> Source code in <code>sports_prediction_framework\\simulation\\KellySimulation.py</code> <pre><code>def __init__(self, data_wrapper, initial_bankroll=1.0):\n    \"\"\"\n    Initialize KellySimulation.\n\n    Parameters\n    ----------\n    data_wrapper : DataWrapper\n        DataWrapper instance holding the data.\n    initial_bankroll : float, optional\n        Starting bankroll (default is 1.0).\n    \"\"\"\n    super().__init__(data_wrapper)\n    self.initial_bankroll = initial_bankroll\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.UnderdogSimulation.ThresholdUnderdogSimulation","title":"<code>ThresholdUnderdogSimulation</code>","text":"<p>               Bases: <code>Simulation</code></p> <p>A betting simulation that places bets on the underdog only if the odds exceed a threshold.</p>"},{"location":"reference/simulation_advanced/#simulation.UnderdogSimulation.ThresholdUnderdogSimulation--attributes","title":"Attributes:","text":"<p>stake : float     The fixed amount to bet on each match. threshold : float     The minimum odds required to place a bet.</p> Source code in <code>sports_prediction_framework\\simulation\\UnderdogSimulation.py</code> <pre><code>class ThresholdUnderdogSimulation(Simulation):\n    \"\"\"\n    A betting simulation that places bets on the underdog only if the odds exceed a threshold.\n\n    Attributes:\n    -----------\n    stake : float\n        The fixed amount to bet on each match.\n    threshold : float\n        The minimum odds required to place a bet.\n    \"\"\"\n\n    def __init__(self, datawrapper: DataWrapper, stake: float = 1.0, threshold: float = 3.0):\n        \"\"\"\n        Initialize the ThresholdUnderdogSimulation.\n\n        Parameters:\n        -----------\n        datawrapper : DataWrapper\n            A wrapper object that provides access to the match dataframe.\n        stake : float\n            The fixed bet amount per match (default is 1.0).\n        threshold : float\n            Minimum odds value required to place a bet (default is 3.0).\n        \"\"\"\n        super().__init__(datawrapper)\n        self.stake = stake\n        self.threshold = threshold\n\n    def run(self):\n        \"\"\"\n        Run the underdog betting simulation with a minimum odds threshold.\n\n        For each match, bet on the outcome with the highest odds if those odds exceed the threshold.\n        \"\"\"\n        df = self.df.copy()\n        odds_cols = {0: 'odds_1', 1: 'odds_X', 2: 'odd_2'}\n\n        for _, row in df.iterrows():\n            # Get all outcome odds\n            odds_values = {k: row[v] for k, v in odds_cols.items()}\n            underdog_outcome = max(odds_values, key=odds_values.get)\n            odds = odds_values[underdog_outcome]\n\n            # Only bet if odds exceed threshold\n            if odds &lt; self.threshold or odds &lt;= 1:\n                self.results.append(0)\n                continue\n\n            win = row['WDL'] == underdog_outcome\n            ret = self.stake * (odds if win else 0) - self.stake\n            self.results.append(ret)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.UnderdogSimulation.ThresholdUnderdogSimulation.__init__","title":"<code>__init__(datawrapper, stake=1.0, threshold=3.0)</code>","text":"<p>Initialize the ThresholdUnderdogSimulation.</p>"},{"location":"reference/simulation_advanced/#simulation.UnderdogSimulation.ThresholdUnderdogSimulation.__init__--parameters","title":"Parameters:","text":"<p>datawrapper : DataWrapper     A wrapper object that provides access to the match dataframe. stake : float     The fixed bet amount per match (default is 1.0). threshold : float     Minimum odds value required to place a bet (default is 3.0).</p> Source code in <code>sports_prediction_framework\\simulation\\UnderdogSimulation.py</code> <pre><code>def __init__(self, datawrapper: DataWrapper, stake: float = 1.0, threshold: float = 3.0):\n    \"\"\"\n    Initialize the ThresholdUnderdogSimulation.\n\n    Parameters:\n    -----------\n    datawrapper : DataWrapper\n        A wrapper object that provides access to the match dataframe.\n    stake : float\n        The fixed bet amount per match (default is 1.0).\n    threshold : float\n        Minimum odds value required to place a bet (default is 3.0).\n    \"\"\"\n    super().__init__(datawrapper)\n    self.stake = stake\n    self.threshold = threshold\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.UnderdogSimulation.ThresholdUnderdogSimulation.run","title":"<code>run()</code>","text":"<p>Run the underdog betting simulation with a minimum odds threshold.</p> <p>For each match, bet on the outcome with the highest odds if those odds exceed the threshold.</p> Source code in <code>sports_prediction_framework\\simulation\\UnderdogSimulation.py</code> <pre><code>def run(self):\n    \"\"\"\n    Run the underdog betting simulation with a minimum odds threshold.\n\n    For each match, bet on the outcome with the highest odds if those odds exceed the threshold.\n    \"\"\"\n    df = self.df.copy()\n    odds_cols = {0: 'odds_1', 1: 'odds_X', 2: 'odd_2'}\n\n    for _, row in df.iterrows():\n        # Get all outcome odds\n        odds_values = {k: row[v] for k, v in odds_cols.items()}\n        underdog_outcome = max(odds_values, key=odds_values.get)\n        odds = odds_values[underdog_outcome]\n\n        # Only bet if odds exceed threshold\n        if odds &lt; self.threshold or odds &lt;= 1:\n            self.results.append(0)\n            continue\n\n        win = row['WDL'] == underdog_outcome\n        ret = self.stake * (odds if win else 0) - self.stake\n        self.results.append(ret)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.EVSimulation.EVSimulation","title":"<code>EVSimulation</code>","text":"<p>               Bases: <code>Simulation</code></p> <p>A betting simulation strategy based on Expected Value (EV).</p> <p>Bets are placed only on matches where the EV is positive, calculated as:     EV = (prob * (odds - 1)) - (1 - prob)</p>"},{"location":"reference/simulation_advanced/#simulation.EVSimulation.EVSimulation--attributes","title":"Attributes:","text":"<p>stake : float     The fixed amount to bet on each qualified match.</p> Source code in <code>sports_prediction_framework\\simulation\\EVSimulation.py</code> <pre><code>class EVSimulation(Simulation):\n    \"\"\"\n    A betting simulation strategy based on Expected Value (EV).\n\n    Bets are placed only on matches where the EV is positive, calculated as:\n        EV = (prob * (odds - 1)) - (1 - prob)\n\n    Attributes:\n    -----------\n    stake : float\n        The fixed amount to bet on each qualified match.\n    \"\"\"\n\n    def __init__(self, datawrapper: DataWrapper, stake: float = 1.0):\n        \"\"\"\n        Initialize the EVSimulation.\n\n        Parameters:\n        -----------\n        datawrapper : DataWrapper\n            A wrapper object that provides access to the match dataframe.\n        stake : float\n            The fixed bet amount per qualified match (default is 1.0).\n        \"\"\"\n        super().__init__(datawrapper)\n        self.stake = stake\n\n    def run(self):\n        \"\"\"\n        Run the expected value betting simulation.\n\n        A fixed stake is placed only if the EV for the predicted outcome is positive.\n        \"\"\"\n        df = self.df.copy()\n        odds_map = {0: 'odds_1', 1: 'odds_X', 2: 'odd_2'}\n\n        for _, row in df.iterrows():\n            pred = row['prediction']\n            prob = row[pred]\n            odds_col = odds_map[pred]\n            odds = row[odds_col]\n\n            if odds &lt;= 1:\n                self.results.append(0)\n                continue\n\n            # Calculate expected value\n            ev = (prob * (odds - 1)) - (1 - prob)\n\n            if ev &gt; 0:\n                win = row['WDL'] == pred\n                ret = self.stake * (odds if win else 0) - self.stake\n                self.results.append(ret)\n            else:\n                self.results.append(0)\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.EVSimulation.EVSimulation.__init__","title":"<code>__init__(datawrapper, stake=1.0)</code>","text":"<p>Initialize the EVSimulation.</p>"},{"location":"reference/simulation_advanced/#simulation.EVSimulation.EVSimulation.__init__--parameters","title":"Parameters:","text":"<p>datawrapper : DataWrapper     A wrapper object that provides access to the match dataframe. stake : float     The fixed bet amount per qualified match (default is 1.0).</p> Source code in <code>sports_prediction_framework\\simulation\\EVSimulation.py</code> <pre><code>def __init__(self, datawrapper: DataWrapper, stake: float = 1.0):\n    \"\"\"\n    Initialize the EVSimulation.\n\n    Parameters:\n    -----------\n    datawrapper : DataWrapper\n        A wrapper object that provides access to the match dataframe.\n    stake : float\n        The fixed bet amount per qualified match (default is 1.0).\n    \"\"\"\n    super().__init__(datawrapper)\n    self.stake = stake\n</code></pre>"},{"location":"reference/simulation_advanced/#simulation.EVSimulation.EVSimulation.run","title":"<code>run()</code>","text":"<p>Run the expected value betting simulation.</p> <p>A fixed stake is placed only if the EV for the predicted outcome is positive.</p> Source code in <code>sports_prediction_framework\\simulation\\EVSimulation.py</code> <pre><code>def run(self):\n    \"\"\"\n    Run the expected value betting simulation.\n\n    A fixed stake is placed only if the EV for the predicted outcome is positive.\n    \"\"\"\n    df = self.df.copy()\n    odds_map = {0: 'odds_1', 1: 'odds_X', 2: 'odd_2'}\n\n    for _, row in df.iterrows():\n        pred = row['prediction']\n        prob = row[pred]\n        odds_col = odds_map[pred]\n        odds = row[odds_col]\n\n        if odds &lt;= 1:\n            self.results.append(0)\n            continue\n\n        # Calculate expected value\n        ev = (prob * (odds - 1)) - (1 - prob)\n\n        if ev &gt; 0:\n            win = row['WDL'] == pred\n            ret = self.stake * (odds if win else 0) - self.stake\n            self.results.append(ret)\n        else:\n            self.results.append(0)\n</code></pre>"},{"location":"reference/torch_model/","title":"Torch model","text":""},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule","title":"<code>TorchModule</code>","text":"<p>               Bases: <code>Module</code>, <code>ABC</code></p> <p>Base class for PyTorch models that handles training and prediction logic. Intended to be subclassed with specific implementations of: - forward() - get_features_batch() - get_labels_batch() - model_specific_computation()</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>class TorchModule(torch.nn.Module, ABC):\n    \"\"\"\n    Base class for PyTorch models that handles training and prediction logic.\n    Intended to be subclassed with specific implementations of:\n    - forward()\n    - get_features_batch()\n    - get_labels_batch()\n    - model_specific_computation()\n    \"\"\"\n\n    def __init__(self, **kwargs) -&gt; None:\n        \"\"\"\n         Initializes default training parameters.\n         Subclasses can override these or pass them via kwargs.\n         \"\"\"\n        super(TorchModule, self).__init__()\n        self.print_info = False             # Whether to print info during training\n        self.batch_size = 9                 # Mini-batch size\n        self.epochs = 100                   # Number of training epochs\n        self.train_loss = []                # Store average training loss per epoch\n        self.train_accuracy = []            # Store average training accuracy per epoch\n        self.lr = 0.0001                    # Learning rate\n\n    @abstractmethod\n    def forward(self, *args, **kwargs) -&gt; torch.Tensor:\n        \"\"\"\n        Must be implemented by subclass to define model forward pass.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_features_batch(self, features: pd.DataFrame, start_index: int) -&gt; Tuple:\n        \"\"\"\n        Extract a batch of features from the full dataset.\n\n        :param features: Full features DataFrame\n        :param start_index: Start index of batch\n        :return: Batch tuple (to be passed to forward)\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def get_labels_batch(self, labels: pd.DataFrame, start_index: int) -&gt; torch.Tensor:\n        \"\"\"\n        Extract corresponding labels for a feature batch.\n\n        :param labels: Full labels DataFrame\n        :param start_index: Start index of batch\n        :return: Tensor of labels\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def model_specific_computation(self, features: pd.DataFrame, labels: pd.DataFrame, start_index: int) -&gt; None:\n        \"\"\"\n        Optional hook for any custom per-batch logic during training.\n\n        :param features: Features DataFrame\n        :param labels: Labels DataFrame\n        :param start_index: Start index of the current batch\n        \"\"\"\n        pass\n\n    def fit(self, features: pd.DataFrame, labels: pd.DataFrame = None):\n        \"\"\"\n        Trains the model on the given features and labels.\n\n        :param features: DataFrame containing input features\n        :param labels: DataFrame containing ground truth labels\n        \"\"\"\n        criterion = torch.nn.NLLLoss()\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n        running_loss = []\n        running_accuracy = []\n\n        for epoch in range(self.epochs):\n            acc = 0\n            loss_value = 0.0\n            optimizer.zero_grad()\n\n            # Iterate over mini-batches\n            for j in range(0, features.shape[0], self.batch_size):\n                # Get input features and labels for the batch\n                outputs = self(*self.get_features_batch(features, j))\n                result = self.get_labels_batch(labels, j)\n\n                # Compute loss and update weights\n                loss = criterion(outputs, result)\n                loss.backward()\n                optimizer.step()\n                loss_value += loss.item()\n\n                # Compute number of correct predictions in batch\n                _, predicted = torch.max(outputs.data, 1)\n                correct = int((predicted == result).sum().item())\n                running_accuracy.append(correct)\n                acc += correct\n\n                # Optional subclass hook for additional computation/logging\n                self.model_specific_computation(features, labels, j)\n\n            # Print training info per epoch\n            if self.print_info:\n                print(f\"Epoch:{epoch}, train_loss:{loss_value:.5f}, train_acc:{acc / features.shape[0]:.5f}\")\n\n            running_loss.append(loss_value)\n\n        # Compute overall training metrics across all epochs\n        self.train_loss.append(sum(running_loss) / ((features.shape[0] / self.batch_size) * self.epochs))\n        self.train_accuracy.append(sum(running_accuracy) / (features.shape[0] * self.epochs))\n\n    def predict(self, data: pd.DataFrame, mode=\"test\") -&gt; np.ndarray:\n        \"\"\"\n        Predicts output probabilities for the input data using the trained model.\n\n        :param data: DataFrame containing input features\n        :param mode: Optional flag for test/validation usage\n        :return: Numpy array of predicted probabilities\n        \"\"\"\n        predicted, outputs = self.get_predictions(data)\n        return torch.exp(outputs).numpy()  # Convert log-probabilities to probabilities\n\n    def get_predictions(self, matches) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Computes predicted classes and raw model outputs.\n\n        :param matches: DataFrame containing input features\n        :return: Tuple of predicted class indices and raw log-probabilities\n        \"\"\"\n        outputs = self.get_probabilities(matches)\n        _, predicted = torch.max(torch.exp(outputs.data), 1)  # Get class with highest probability\n        return predicted, outputs\n\n    def get_probabilities(self, matches):\n        \"\"\"\n        Computes raw model outputs (log-probabilities) using forward pass.\n\n        :param matches: DataFrame with match data, must include columns 'HID' and 'AID'\n        :return: Tensor of log-probabilities for each match\n        \"\"\"\n        self.eval()  # Set model to eval mode (disables dropout, etc.)\n\n        home = torch.from_numpy(matches['HID'].values.astype('int64'))\n        away = torch.from_numpy(matches['AID'].values.astype('int64'))\n\n        with torch.no_grad():  # Disable gradient tracking\n            outputs = self(matches, home, away)\n\n        self.train()  # Switch back to training mode\n        return outputs\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Initializes default training parameters. Subclasses can override these or pass them via kwargs.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>def __init__(self, **kwargs) -&gt; None:\n    \"\"\"\n     Initializes default training parameters.\n     Subclasses can override these or pass them via kwargs.\n     \"\"\"\n    super(TorchModule, self).__init__()\n    self.print_info = False             # Whether to print info during training\n    self.batch_size = 9                 # Mini-batch size\n    self.epochs = 100                   # Number of training epochs\n    self.train_loss = []                # Store average training loss per epoch\n    self.train_accuracy = []            # Store average training accuracy per epoch\n    self.lr = 0.0001                    # Learning rate\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.fit","title":"<code>fit(features, labels=None)</code>","text":"<p>Trains the model on the given features and labels.</p> <p>:param features: DataFrame containing input features :param labels: DataFrame containing ground truth labels</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>def fit(self, features: pd.DataFrame, labels: pd.DataFrame = None):\n    \"\"\"\n    Trains the model on the given features and labels.\n\n    :param features: DataFrame containing input features\n    :param labels: DataFrame containing ground truth labels\n    \"\"\"\n    criterion = torch.nn.NLLLoss()\n    optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n    running_loss = []\n    running_accuracy = []\n\n    for epoch in range(self.epochs):\n        acc = 0\n        loss_value = 0.0\n        optimizer.zero_grad()\n\n        # Iterate over mini-batches\n        for j in range(0, features.shape[0], self.batch_size):\n            # Get input features and labels for the batch\n            outputs = self(*self.get_features_batch(features, j))\n            result = self.get_labels_batch(labels, j)\n\n            # Compute loss and update weights\n            loss = criterion(outputs, result)\n            loss.backward()\n            optimizer.step()\n            loss_value += loss.item()\n\n            # Compute number of correct predictions in batch\n            _, predicted = torch.max(outputs.data, 1)\n            correct = int((predicted == result).sum().item())\n            running_accuracy.append(correct)\n            acc += correct\n\n            # Optional subclass hook for additional computation/logging\n            self.model_specific_computation(features, labels, j)\n\n        # Print training info per epoch\n        if self.print_info:\n            print(f\"Epoch:{epoch}, train_loss:{loss_value:.5f}, train_acc:{acc / features.shape[0]:.5f}\")\n\n        running_loss.append(loss_value)\n\n    # Compute overall training metrics across all epochs\n    self.train_loss.append(sum(running_loss) / ((features.shape[0] / self.batch_size) * self.epochs))\n    self.train_accuracy.append(sum(running_accuracy) / (features.shape[0] * self.epochs))\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.forward","title":"<code>forward(*args, **kwargs)</code>  <code>abstractmethod</code>","text":"<p>Must be implemented by subclass to define model forward pass.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>@abstractmethod\ndef forward(self, *args, **kwargs) -&gt; torch.Tensor:\n    \"\"\"\n    Must be implemented by subclass to define model forward pass.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.get_features_batch","title":"<code>get_features_batch(features, start_index)</code>  <code>abstractmethod</code>","text":"<p>Extract a batch of features from the full dataset.</p> <p>:param features: Full features DataFrame :param start_index: Start index of batch :return: Batch tuple (to be passed to forward)</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>@abstractmethod\ndef get_features_batch(self, features: pd.DataFrame, start_index: int) -&gt; Tuple:\n    \"\"\"\n    Extract a batch of features from the full dataset.\n\n    :param features: Full features DataFrame\n    :param start_index: Start index of batch\n    :return: Batch tuple (to be passed to forward)\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.get_labels_batch","title":"<code>get_labels_batch(labels, start_index)</code>  <code>abstractmethod</code>","text":"<p>Extract corresponding labels for a feature batch.</p> <p>:param labels: Full labels DataFrame :param start_index: Start index of batch :return: Tensor of labels</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>@abstractmethod\ndef get_labels_batch(self, labels: pd.DataFrame, start_index: int) -&gt; torch.Tensor:\n    \"\"\"\n    Extract corresponding labels for a feature batch.\n\n    :param labels: Full labels DataFrame\n    :param start_index: Start index of batch\n    :return: Tensor of labels\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.get_predictions","title":"<code>get_predictions(matches)</code>","text":"<p>Computes predicted classes and raw model outputs.</p> <p>:param matches: DataFrame containing input features :return: Tuple of predicted class indices and raw log-probabilities</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>def get_predictions(self, matches) -&gt; Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Computes predicted classes and raw model outputs.\n\n    :param matches: DataFrame containing input features\n    :return: Tuple of predicted class indices and raw log-probabilities\n    \"\"\"\n    outputs = self.get_probabilities(matches)\n    _, predicted = torch.max(torch.exp(outputs.data), 1)  # Get class with highest probability\n    return predicted, outputs\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.get_probabilities","title":"<code>get_probabilities(matches)</code>","text":"<p>Computes raw model outputs (log-probabilities) using forward pass.</p> <p>:param matches: DataFrame with match data, must include columns 'HID' and 'AID' :return: Tensor of log-probabilities for each match</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>def get_probabilities(self, matches):\n    \"\"\"\n    Computes raw model outputs (log-probabilities) using forward pass.\n\n    :param matches: DataFrame with match data, must include columns 'HID' and 'AID'\n    :return: Tensor of log-probabilities for each match\n    \"\"\"\n    self.eval()  # Set model to eval mode (disables dropout, etc.)\n\n    home = torch.from_numpy(matches['HID'].values.astype('int64'))\n    away = torch.from_numpy(matches['AID'].values.astype('int64'))\n\n    with torch.no_grad():  # Disable gradient tracking\n        outputs = self(matches, home, away)\n\n    self.train()  # Switch back to training mode\n    return outputs\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.model_specific_computation","title":"<code>model_specific_computation(features, labels, start_index)</code>  <code>abstractmethod</code>","text":"<p>Optional hook for any custom per-batch logic during training.</p> <p>:param features: Features DataFrame :param labels: Labels DataFrame :param start_index: Start index of the current batch</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>@abstractmethod\ndef model_specific_computation(self, features: pd.DataFrame, labels: pd.DataFrame, start_index: int) -&gt; None:\n    \"\"\"\n    Optional hook for any custom per-batch logic during training.\n\n    :param features: Features DataFrame\n    :param labels: Labels DataFrame\n    :param start_index: Start index of the current batch\n    \"\"\"\n    pass\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchModule.TorchModule.predict","title":"<code>predict(data, mode='test')</code>","text":"<p>Predicts output probabilities for the input data using the trained model.</p> <p>:param data: DataFrame containing input features :param mode: Optional flag for test/validation usage :return: Numpy array of predicted probabilities</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchModule.py</code> <pre><code>def predict(self, data: pd.DataFrame, mode=\"test\") -&gt; np.ndarray:\n    \"\"\"\n    Predicts output probabilities for the input data using the trained model.\n\n    :param data: DataFrame containing input features\n    :param mode: Optional flag for test/validation usage\n    :return: Numpy array of predicted probabilities\n    \"\"\"\n    predicted, outputs = self.get_predictions(data)\n    return torch.exp(outputs).numpy()  # Convert log-probabilities to probabilities\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat","title":"<code>TorchFlat</code>","text":"<p>               Bases: <code>TorchModule</code></p> <p>A simple feedforward network that takes team embeddings (home and away), concatenates them, and passes through multiple dense layers to predict match outcomes.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>class TorchFlat(TorchModule):\n    \"\"\"\n    A simple feedforward network that takes team embeddings (home and away),\n    concatenates them, and passes through multiple dense layers to predict match outcomes.\n    \"\"\"\n\n    def __init__(self, pretrained_weights: Optional[Tensor] = None) -&gt; None:\n        \"\"\"\n        Initializes the model, optionally using pretrained embeddings.\n\n        :param pretrained_weights: Optional pretrained weights for team embeddings\n        \"\"\"\n        super(TorchFlat, self).__init__()\n        self.activation = torch.nn.ReLU()\n        if pretrained_weights is not None:\n            self.embedding: Embedding = Embedding.from_pretrained(pretrained_weights)\n        else:\n            self.embedding: Optional[Embedding] = None\n\n    def complex_init(self) -&gt; None:\n        \"\"\"\n        Initializes the dense architecture of the model according to the specified type.\n        \"\"\"\n        assert self.n_dense &gt;= 2, \"n_dense must be at least 2\"\n\n        if self.architecture_type == 'rectangle':\n            # n_dense-1 transitions before the output layer\n            self.dense_dims = [self.dense_dim] * (self.n_dense - 1)\n        elif self.architecture_type == 'pyramid':\n            self.dense_dims = []\n            step = max(1, (self.dense_dim - self.out_dim) // (self.n_dense - 1))\n            dim = self.dense_dim\n            for _ in range(self.n_dense - 1):\n                self.dense_dims.append(dim)\n                dim = max(dim - step, self.out_dim)\n\n        lin_layers = []\n        lin_layers.append(torch.nn.Linear(self.embed_dim * 2, self.dense_dims[0]))\n        for i in range(len(self.dense_dims) - 1):\n            lin_layers.append(torch.nn.Linear(self.dense_dims[i], self.dense_dims[i + 1]))\n        lin_layers.append(torch.nn.Linear(self.dense_dims[-1], self.out_dim))\n\n        self.lin_layers = ModuleList(lin_layers)\n        self.out = LogSoftmax(dim=1)\n        self.drop = Dropout(p=0.1)\n\n    def forward(self, data: pd.DataFrame, team_home: Tensor, team_away: Tensor) -&gt; Tensor:\n        \"\"\"\n        Defines the forward pass of the model.\n\n        :param data: Input data (not used directly here)\n        :param team_home: Tensor of home team IDs\n        :param team_away: Tensor of away team IDs\n        :return: Log-probabilities tensor with shape [batch_size, out_dim]\n        \"\"\"\n        home_emb = self.embedding(team_home)\n        away_emb = self.embedding(team_away)\n        x = torch.cat((home_emb, away_emb), 1)\n\n        for layer in self.lin_layers:\n            x = self.activation(layer(x))\n            x = self.drop(x)\n\n        x = self.out(x)\n        return x.reshape(-1, self.out_dim)\n\n    def set_parameters_from_wrapper(self, wrapper: MatchWrapper) -&gt; None:\n        \"\"\"\n        Initializes the embedding layer based on the dataset's metadata.\n\n        :param wrapper: A MatchWrapper instance containing team count info\n        \"\"\"\n        if self.embedding is None:\n            self.embedding = Embedding(wrapper.total_number_of_teams, self.embed_dim)\n\n    def get_features_batch(self, features: pd.DataFrame, batch_index: int) -&gt; Tuple[pd.DataFrame, Tensor, Tensor]:\n        \"\"\"\n        Retrieves a batch of home and away team IDs from the dataset.\n\n        :param features: The full features DataFrame\n        :param batch_index: Starting index of the batch\n        :return: A tuple (features_df, home_team_tensor, away_team_tensor)\n        \"\"\"\n        home = torch.from_numpy(\n            features.iloc[batch_index:batch_index + self.batch_size]['HID'].values.astype('int64'))\n        away = torch.from_numpy(\n            features.iloc[batch_index:batch_index + self.batch_size]['AID'].values.astype('int64'))\n        return features, home, away\n\n    def get_labels_batch(self, labels: pd.DataFrame, batch_index: int) -&gt; Tensor:\n        \"\"\"\n        Retrieves a batch of match results as a tensor.\n\n        :param labels: The full labels DataFrame\n        :param batch_index: Starting index of the batch\n        :return: A tensor of labels for the batch\n        \"\"\"\n\n        batch_end = min(batch_index + self.batch_size, len(labels))\n\n        result_slice = labels.iloc[batch_index:batch_end]\n\n        # Convert the slice to a tensor\n        result = torch.from_numpy(result_slice.values.astype('int64').reshape(-1, ))\n\n        # Check the shape of the result\n\n        return result\n\n    def model_specific_computation(self, features, labels, j):\n        pass\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.__init__","title":"<code>__init__(pretrained_weights=None)</code>","text":"<p>Initializes the model, optionally using pretrained embeddings.</p> <p>:param pretrained_weights: Optional pretrained weights for team embeddings</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def __init__(self, pretrained_weights: Optional[Tensor] = None) -&gt; None:\n    \"\"\"\n    Initializes the model, optionally using pretrained embeddings.\n\n    :param pretrained_weights: Optional pretrained weights for team embeddings\n    \"\"\"\n    super(TorchFlat, self).__init__()\n    self.activation = torch.nn.ReLU()\n    if pretrained_weights is not None:\n        self.embedding: Embedding = Embedding.from_pretrained(pretrained_weights)\n    else:\n        self.embedding: Optional[Embedding] = None\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.complex_init","title":"<code>complex_init()</code>","text":"<p>Initializes the dense architecture of the model according to the specified type.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def complex_init(self) -&gt; None:\n    \"\"\"\n    Initializes the dense architecture of the model according to the specified type.\n    \"\"\"\n    assert self.n_dense &gt;= 2, \"n_dense must be at least 2\"\n\n    if self.architecture_type == 'rectangle':\n        # n_dense-1 transitions before the output layer\n        self.dense_dims = [self.dense_dim] * (self.n_dense - 1)\n    elif self.architecture_type == 'pyramid':\n        self.dense_dims = []\n        step = max(1, (self.dense_dim - self.out_dim) // (self.n_dense - 1))\n        dim = self.dense_dim\n        for _ in range(self.n_dense - 1):\n            self.dense_dims.append(dim)\n            dim = max(dim - step, self.out_dim)\n\n    lin_layers = []\n    lin_layers.append(torch.nn.Linear(self.embed_dim * 2, self.dense_dims[0]))\n    for i in range(len(self.dense_dims) - 1):\n        lin_layers.append(torch.nn.Linear(self.dense_dims[i], self.dense_dims[i + 1]))\n    lin_layers.append(torch.nn.Linear(self.dense_dims[-1], self.out_dim))\n\n    self.lin_layers = ModuleList(lin_layers)\n    self.out = LogSoftmax(dim=1)\n    self.drop = Dropout(p=0.1)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.forward","title":"<code>forward(data, team_home, team_away)</code>","text":"<p>Defines the forward pass of the model.</p> <p>:param data: Input data (not used directly here) :param team_home: Tensor of home team IDs :param team_away: Tensor of away team IDs :return: Log-probabilities tensor with shape [batch_size, out_dim]</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def forward(self, data: pd.DataFrame, team_home: Tensor, team_away: Tensor) -&gt; Tensor:\n    \"\"\"\n    Defines the forward pass of the model.\n\n    :param data: Input data (not used directly here)\n    :param team_home: Tensor of home team IDs\n    :param team_away: Tensor of away team IDs\n    :return: Log-probabilities tensor with shape [batch_size, out_dim]\n    \"\"\"\n    home_emb = self.embedding(team_home)\n    away_emb = self.embedding(team_away)\n    x = torch.cat((home_emb, away_emb), 1)\n\n    for layer in self.lin_layers:\n        x = self.activation(layer(x))\n        x = self.drop(x)\n\n    x = self.out(x)\n    return x.reshape(-1, self.out_dim)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.get_features_batch","title":"<code>get_features_batch(features, batch_index)</code>","text":"<p>Retrieves a batch of home and away team IDs from the dataset.</p> <p>:param features: The full features DataFrame :param batch_index: Starting index of the batch :return: A tuple (features_df, home_team_tensor, away_team_tensor)</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def get_features_batch(self, features: pd.DataFrame, batch_index: int) -&gt; Tuple[pd.DataFrame, Tensor, Tensor]:\n    \"\"\"\n    Retrieves a batch of home and away team IDs from the dataset.\n\n    :param features: The full features DataFrame\n    :param batch_index: Starting index of the batch\n    :return: A tuple (features_df, home_team_tensor, away_team_tensor)\n    \"\"\"\n    home = torch.from_numpy(\n        features.iloc[batch_index:batch_index + self.batch_size]['HID'].values.astype('int64'))\n    away = torch.from_numpy(\n        features.iloc[batch_index:batch_index + self.batch_size]['AID'].values.astype('int64'))\n    return features, home, away\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.get_labels_batch","title":"<code>get_labels_batch(labels, batch_index)</code>","text":"<p>Retrieves a batch of match results as a tensor.</p> <p>:param labels: The full labels DataFrame :param batch_index: Starting index of the batch :return: A tensor of labels for the batch</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def get_labels_batch(self, labels: pd.DataFrame, batch_index: int) -&gt; Tensor:\n    \"\"\"\n    Retrieves a batch of match results as a tensor.\n\n    :param labels: The full labels DataFrame\n    :param batch_index: Starting index of the batch\n    :return: A tensor of labels for the batch\n    \"\"\"\n\n    batch_end = min(batch_index + self.batch_size, len(labels))\n\n    result_slice = labels.iloc[batch_index:batch_end]\n\n    # Convert the slice to a tensor\n    result = torch.from_numpy(result_slice.values.astype('int64').reshape(-1, ))\n\n    # Check the shape of the result\n\n    return result\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchFlat.TorchFlat.set_parameters_from_wrapper","title":"<code>set_parameters_from_wrapper(wrapper)</code>","text":"<p>Initializes the embedding layer based on the dataset's metadata.</p> <p>:param wrapper: A MatchWrapper instance containing team count info</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchFlat.py</code> <pre><code>def set_parameters_from_wrapper(self, wrapper: MatchWrapper) -&gt; None:\n    \"\"\"\n    Initializes the embedding layer based on the dataset's metadata.\n\n    :param wrapper: A MatchWrapper instance containing team count info\n    \"\"\"\n    if self.embedding is None:\n        self.embedding = Embedding(wrapper.total_number_of_teams, self.embed_dim)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN","title":"<code>TorchGNN</code>","text":"<p>               Bases: <code>TorchModule</code></p> <p>A Graph Neural Network model that uses team embeddings and match-based graph structure to predict match outcomes using PyTorch Geometric.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>class TorchGNN(TorchModule):\n    \"\"\"\n    A Graph Neural Network model that uses team embeddings and match-based graph structure\n    to predict match outcomes using PyTorch Geometric.\n    \"\"\"\n\n    def __init__(self, graph):\n        \"\"\"\n        Initializes the model with a given dynamic graph object.\n        \"\"\"\n        super(TorchGNN, self).__init__()\n        self.graph = graph\n        self.num_teams = None\n        self.embedding = None\n\n    def complex_init(self):\n        \"\"\"\n        Initializes the convolutional and dense layers based on architecture settings.\n        \"\"\"\n        if self.architecture_type == 'rectangle':\n            self.conv_dims = [self.conv_dim] * (self.n_conv + 1)\n            self.dense_dims = [self.dense_dim] * self.n_dense\n\n        self.activation = nn.ReLU()\n\n        self.conv_layers = ModuleList(\n            [GraphConv(self.embed_dim, self.conv_dims[0])] +\n            [GraphConv(self.conv_dims[i], self.conv_dims[i + 1]) for i in range(self.n_conv - 1)]\n        )\n\n        self.lin_layers = ModuleList(\n            [Linear(self.conv_dims[self.n_conv - 1] * 2, self.dense_dims[0])] +\n            [Linear(self.dense_dims[i], self.dense_dims[i + 1]) for i in range(self.n_dense - 2)] +\n            [Linear(self.dense_dims[self.n_dense - 2], self.out_dim)]\n        )\n\n        self.out = LogSoftmax(dim=1)\n        self.drop = Dropout(p=0.1)\n\n    def set_parameters_from_wrapper(self, wrapper: MatchWrapper):\n        \"\"\"\n        Initializes team embeddings based on the number of teams in the dataset.\n        \"\"\"\n        if self.num_teams is None:\n            self.num_teams = wrapper.total_number_of_teams\n            self.embedding = Embedding(num_embeddings=self.num_teams, embedding_dim=self.embed_dim)\n\n    def forward(self, features, home, away):\n        \"\"\"\n        Performs a forward pass using the current match features and graph structure.\n        \"\"\"\n        key = features.iloc[0][self.graph.column].iloc[1]  # gets scalar value\n\n        graph = self.graph.graphs[key]\n        edge_index, edge_weight = graph.edge_index, graph.edge_weight\n\n        x = torch.arange(self.num_teams, device=home.device)\n        x = self.embedding(x)\n\n        x = self.conv_layers[0](x, edge_index, edge_weight) if len(edge_weight) &gt; 0 else self.conv_layers[0](x, edge_index)\n        x = self.activation(x)\n        x = self.drop(x)\n\n        for i in range(self.n_conv - 1):\n            conv = self.conv_layers[i + 1]\n            x = conv(x, edge_index, edge_weight) if len(edge_weight) &gt; 0 else conv(x, edge_index)\n            x = self.activation(x)\n            x = self.drop(x)\n\n        x = torch.cat([x[home], x[away]], dim=1)\n\n        for layer in self.lin_layers:\n            x = self.activation(layer(x))\n            x = self.drop(x)\n\n        return self.out(x).reshape(-1, self.out_dim)\n\n    def model_specific_computation(self, features, labels, batch_index):\n        \"\"\"\n        Updates the graph edges based on the current batch's match outcomes.\n        \"\"\"\n        _, home, away = self.get_features_batch(features, batch_index)\n        result = self.get_labels_batch(labels, batch_index)\n        self.graph.graphs[features[self.graph.column].iloc[0][1]].compute(home, away, result)\n\n    def get_features_batch(self, features, batch_index):\n        \"\"\"\n        Extracts home and away team indices from features for the current batch.\n        \"\"\"\n        batch = features.iloc[batch_index:batch_index + self.batch_size]\n        home = torch.from_numpy(batch['HID'].values.astype('int64'))\n        away = torch.from_numpy(batch['AID'].values.astype('int64'))\n        return features, home, away\n\n    def get_labels_batch(self, labels, batch_index):\n        \"\"\"\n        Extracts match result labels for the current batch.\n        \"\"\"\n        return torch.from_numpy(labels.iloc[batch_index:batch_index + self.batch_size].values.astype('int64'))\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.__init__","title":"<code>__init__(graph)</code>","text":"<p>Initializes the model with a given dynamic graph object.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def __init__(self, graph):\n    \"\"\"\n    Initializes the model with a given dynamic graph object.\n    \"\"\"\n    super(TorchGNN, self).__init__()\n    self.graph = graph\n    self.num_teams = None\n    self.embedding = None\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.complex_init","title":"<code>complex_init()</code>","text":"<p>Initializes the convolutional and dense layers based on architecture settings.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def complex_init(self):\n    \"\"\"\n    Initializes the convolutional and dense layers based on architecture settings.\n    \"\"\"\n    if self.architecture_type == 'rectangle':\n        self.conv_dims = [self.conv_dim] * (self.n_conv + 1)\n        self.dense_dims = [self.dense_dim] * self.n_dense\n\n    self.activation = nn.ReLU()\n\n    self.conv_layers = ModuleList(\n        [GraphConv(self.embed_dim, self.conv_dims[0])] +\n        [GraphConv(self.conv_dims[i], self.conv_dims[i + 1]) for i in range(self.n_conv - 1)]\n    )\n\n    self.lin_layers = ModuleList(\n        [Linear(self.conv_dims[self.n_conv - 1] * 2, self.dense_dims[0])] +\n        [Linear(self.dense_dims[i], self.dense_dims[i + 1]) for i in range(self.n_dense - 2)] +\n        [Linear(self.dense_dims[self.n_dense - 2], self.out_dim)]\n    )\n\n    self.out = LogSoftmax(dim=1)\n    self.drop = Dropout(p=0.1)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.forward","title":"<code>forward(features, home, away)</code>","text":"<p>Performs a forward pass using the current match features and graph structure.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def forward(self, features, home, away):\n    \"\"\"\n    Performs a forward pass using the current match features and graph structure.\n    \"\"\"\n    key = features.iloc[0][self.graph.column].iloc[1]  # gets scalar value\n\n    graph = self.graph.graphs[key]\n    edge_index, edge_weight = graph.edge_index, graph.edge_weight\n\n    x = torch.arange(self.num_teams, device=home.device)\n    x = self.embedding(x)\n\n    x = self.conv_layers[0](x, edge_index, edge_weight) if len(edge_weight) &gt; 0 else self.conv_layers[0](x, edge_index)\n    x = self.activation(x)\n    x = self.drop(x)\n\n    for i in range(self.n_conv - 1):\n        conv = self.conv_layers[i + 1]\n        x = conv(x, edge_index, edge_weight) if len(edge_weight) &gt; 0 else conv(x, edge_index)\n        x = self.activation(x)\n        x = self.drop(x)\n\n    x = torch.cat([x[home], x[away]], dim=1)\n\n    for layer in self.lin_layers:\n        x = self.activation(layer(x))\n        x = self.drop(x)\n\n    return self.out(x).reshape(-1, self.out_dim)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.get_features_batch","title":"<code>get_features_batch(features, batch_index)</code>","text":"<p>Extracts home and away team indices from features for the current batch.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def get_features_batch(self, features, batch_index):\n    \"\"\"\n    Extracts home and away team indices from features for the current batch.\n    \"\"\"\n    batch = features.iloc[batch_index:batch_index + self.batch_size]\n    home = torch.from_numpy(batch['HID'].values.astype('int64'))\n    away = torch.from_numpy(batch['AID'].values.astype('int64'))\n    return features, home, away\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.get_labels_batch","title":"<code>get_labels_batch(labels, batch_index)</code>","text":"<p>Extracts match result labels for the current batch.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def get_labels_batch(self, labels, batch_index):\n    \"\"\"\n    Extracts match result labels for the current batch.\n    \"\"\"\n    return torch.from_numpy(labels.iloc[batch_index:batch_index + self.batch_size].values.astype('int64'))\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.model_specific_computation","title":"<code>model_specific_computation(features, labels, batch_index)</code>","text":"<p>Updates the graph edges based on the current batch's match outcomes.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def model_specific_computation(self, features, labels, batch_index):\n    \"\"\"\n    Updates the graph edges based on the current batch's match outcomes.\n    \"\"\"\n    _, home, away = self.get_features_batch(features, batch_index)\n    result = self.get_labels_batch(labels, batch_index)\n    self.graph.graphs[features[self.graph.column].iloc[0][1]].compute(home, away, result)\n</code></pre>"},{"location":"reference/torch_model/#model.torch_model.TorchGNN.TorchGNN.set_parameters_from_wrapper","title":"<code>set_parameters_from_wrapper(wrapper)</code>","text":"<p>Initializes team embeddings based on the number of teams in the dataset.</p> Source code in <code>sports_prediction_framework\\model\\torch_model\\TorchGNN.py</code> <pre><code>def set_parameters_from_wrapper(self, wrapper: MatchWrapper):\n    \"\"\"\n    Initializes team embeddings based on the number of teams in the dataset.\n    \"\"\"\n    if self.num_teams is None:\n        self.num_teams = wrapper.total_number_of_teams\n        self.embedding = Embedding(num_embeddings=self.num_teams, embedding_dim=self.embed_dim)\n</code></pre>"},{"location":"reference/transformations/","title":"transformations","text":""},{"location":"reference/transformations/#transformer.Transformer.Transformer","title":"<code>Transformer</code>","text":"Source code in <code>sports_prediction_framework\\transformer\\Transformer.py</code> <pre><code>class Transformer:\n    transformations = {'names_to_ids':True, 'names_to_ids_scope':False, 'remove_small_seasons':False,\n              'result_column':False, 'score_diff':False, 'round_column':False, 'date_from_time':False,\n              'only_latest_odds': False, 'only_first_odds': False, 'first_and_latest_odds': False}\n\n    base_transformer = BaseTransformer()\n\n\n\n    def load_from_dict(self,transform_dict: dict):\n        \"\"\"\n        Updates the `transformations` dictionary with key-value pairs from `transform_dict`.\n\n        Args:\n            transform_dict (dict): A dictionary containing transformation keys and their corresponding values.\n        \"\"\"\n\n        for key, value in transform_dict.items():\n            if key in self.transformations.keys():\n                self.transformations[key] = value\n            else:\n                print(f\"Invalid transformation {key}\")\n\n\n    def load_from_list(self, transform_list: list):\n        \"\"\"\n        Sets the corresponding entries in the transformations dictionary to True for each element in transform_list.\n\n        Args:\n            transform_list (list): A list of transformation keys to be updated in the transformations dictionary.\n        \"\"\"\n        for elem in transform_list:\n            if elem in self.transformations.keys():\n                self.transformations[elem] = True\n\n\n    def transform(self, wrapper: DataWrapper):\n        \"\"\"\n        Applies transformations to the wrapper based on the active flags in the `transformations` dictionary.\n\n        Args:\n            wrapper (DataWrapper): The data wrapper to be transformed.\n\n        Returns:\n            DataWrapper: The transformed data wrapper after applying the selected transformations.\n        \"\"\"\n        t = self.transformations\n        if t['names_to_ids']:\n            wrapper = self.base_transformer.names_to_ids(wrapper)\n        if t['date_from_time']:\n            wrapper = self.base_transformer.get_date_from_time(wrapper)\n        if t['only_first_odds']:\n            wrapper = self.base_transformer.get_first_odds(wrapper)\n        if t['only_latest_odds']:\n            wrapper = self.base_transformer.get_latest_odds(wrapper)\n        if t['first_and_latest_odds']:\n            wrapper = self.base_transformer.get_first_and_latest_odds(wrapper)\n\n        return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.Transformer.Transformer.load_from_dict","title":"<code>load_from_dict(transform_dict)</code>","text":"<p>Updates the <code>transformations</code> dictionary with key-value pairs from <code>transform_dict</code>.</p> <p>Parameters:</p> Name Type Description Default <code>transform_dict</code> <code>dict</code> <p>A dictionary containing transformation keys and their corresponding values.</p> required Source code in <code>sports_prediction_framework\\transformer\\Transformer.py</code> <pre><code>def load_from_dict(self,transform_dict: dict):\n    \"\"\"\n    Updates the `transformations` dictionary with key-value pairs from `transform_dict`.\n\n    Args:\n        transform_dict (dict): A dictionary containing transformation keys and their corresponding values.\n    \"\"\"\n\n    for key, value in transform_dict.items():\n        if key in self.transformations.keys():\n            self.transformations[key] = value\n        else:\n            print(f\"Invalid transformation {key}\")\n</code></pre>"},{"location":"reference/transformations/#transformer.Transformer.Transformer.load_from_list","title":"<code>load_from_list(transform_list)</code>","text":"<p>Sets the corresponding entries in the transformations dictionary to True for each element in transform_list.</p> <p>Parameters:</p> Name Type Description Default <code>transform_list</code> <code>list</code> <p>A list of transformation keys to be updated in the transformations dictionary.</p> required Source code in <code>sports_prediction_framework\\transformer\\Transformer.py</code> <pre><code>def load_from_list(self, transform_list: list):\n    \"\"\"\n    Sets the corresponding entries in the transformations dictionary to True for each element in transform_list.\n\n    Args:\n        transform_list (list): A list of transformation keys to be updated in the transformations dictionary.\n    \"\"\"\n    for elem in transform_list:\n        if elem in self.transformations.keys():\n            self.transformations[elem] = True\n</code></pre>"},{"location":"reference/transformations/#transformer.Transformer.Transformer.transform","title":"<code>transform(wrapper)</code>","text":"<p>Applies transformations to the wrapper based on the active flags in the <code>transformations</code> dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>The data wrapper to be transformed.</p> required <p>Returns:</p> Name Type Description <code>DataWrapper</code> <p>The transformed data wrapper after applying the selected transformations.</p> Source code in <code>sports_prediction_framework\\transformer\\Transformer.py</code> <pre><code>def transform(self, wrapper: DataWrapper):\n    \"\"\"\n    Applies transformations to the wrapper based on the active flags in the `transformations` dictionary.\n\n    Args:\n        wrapper (DataWrapper): The data wrapper to be transformed.\n\n    Returns:\n        DataWrapper: The transformed data wrapper after applying the selected transformations.\n    \"\"\"\n    t = self.transformations\n    if t['names_to_ids']:\n        wrapper = self.base_transformer.names_to_ids(wrapper)\n    if t['date_from_time']:\n        wrapper = self.base_transformer.get_date_from_time(wrapper)\n    if t['only_first_odds']:\n        wrapper = self.base_transformer.get_first_odds(wrapper)\n    if t['only_latest_odds']:\n        wrapper = self.base_transformer.get_latest_odds(wrapper)\n    if t['first_and_latest_odds']:\n        wrapper = self.base_transformer.get_first_and_latest_odds(wrapper)\n\n    return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer","title":"<code>BaseTransformer</code>","text":"Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>class BaseTransformer:\n\n    def __init__(self):\n        self.id_map = {}\n\n    def add_features(self, wrapper: DataWrapper, features) -&gt; DataWrapper:\n        dataset_c = wrapper.deepcopy()\n        dataset_c.add_features(features)\n        return dataset_c\n\n    def names_to_ids(self, wrapper: DataWrapper):\n\n        data = wrapper.data_handler\n        names = set.union(*[set(data.dataframe[col]) for col in wrapper.name_columns])\n        self.id_map.update({name: id for id, name in enumerate(sorted(names))})\n\n        series = []\n        data = wrapper.data_handler\n        for namec, idc in zip(wrapper.name_columns, wrapper.name_id_columns):\n            series.append(data.dataframe[namec].map(self.id_map.get).rename(idc))\n\n        return self.add_features(wrapper, pd.concat(series, axis=1))\n\n    def remove_small_seasons(self, wrapper: DataWrapper, min_teams: int):\n        \"\"\"\n        Removes seasons from the DataFrame in DataWrapper where the number of unique teams is less than min_teams.\n\n        Args:\n            wrapper (DataWrapper): An instance of DataWrapper containing the DataFrame.\n            min_teams (int): The minimum number of unique teams required to keep a season.\n\n        Returns:\n            DataWrapper: The modified DataWrapper with small seasons removed.\n        \"\"\"\n        league_column = 'League'\n        season_column = 'Season'\n        to_be_removed = []\n        for group_values,season in wrapper.get_dataframe().groupby([league_column,season_column]):\n            if len(set(season['HID']).union(set(season['AID']))) &lt; min_teams:\n                to_be_removed.append(group_values)\n        for rem in to_be_removed:\n            wrapper.get_dataframe().drop(wrapper.get_dataframe()[(wrapper.get_dataframe()[league_column] == rem[0]) &amp;\n                                         (wrapper.get_dataframe()[season_column] == rem[1])].index,\n                                         inplace=True)\n        return wrapper\n\n\n    def get_date_from_time(self, wrapper:DataWrapper) -&gt; DataWrapper:\n        \"\"\"\n        Extracts and converts dates from the 'Time' column in the DataFrame, accounting for season transitions.\n\n        Args:\n            wrapper (DataWrapper): An instance of DataWrapper containing the DataFrame.\n\n        Returns:\n            DataWrapper: The modified DataWrapper with the 'Date' column updated.\n        \"\"\"\n\n        seasons = []\n        for _,season in wrapper.get_dataframe().groupby(['League','Season']):\n            season['day'] = season['Time'].str.split('.').str[0]\n            season['month'] = pd.to_numeric(season['Time'].str.split('.').str[1])\n            season = season.sort_values(['month', 'day'])\n            season['diff'] = season['month'].diff()\n            try:\n                min_index = season[season['diff']&gt;1]['diff'].idxmin()\n            except:\n                min_index = season['month'].idxmin()\n            season['Date'] = pd.to_datetime(season.loc[:min_index]['Time'] + (season.loc[:min_index]['Season']+1).apply(str), format=\"%d.%m.%Y\", errors='coerce')\n            season.loc[min_index:,'Date'] = pd.to_datetime(season.loc[min_index:]['Time'] + (season.loc[min_index:]['Season']).apply(str), format=\"%d.%m.%Y\", errors='coerce')\n            season = season[season['Date'].notnull()]\n            seasons.append(season)\n\n        wrapper.set_dataframe(pd.DataFrame(index=wrapper.get_dataframe().index, data=pd.concat(seasons)['Date']))\n        return wrapper\n\n    def get_first_odds(self, wrapper: DataWrapper) -&gt; DataWrapper:\n        \"\"\"\n        Modifies the DataFrame inside the DataWrapper to keep only the first betting odds for each event.\n\n        Args:\n            wrapper (DataWrapper): An instance of DataWrapper.\n\n        Returns:\n            wrapper\n        \"\"\"\n        wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='last', inplace=True)\n        return wrapper\n\n    def get_latest_odds(self, wrapper: DataWrapper) -&gt; DataWrapper:\n        \"\"\"\n        Modifies the DataFrame inside the DataWrapper to keep only the last betting odds for each event.\n\n        Args:\n            wrapper (DataWrapper): An instance of DataWrapper.\n\n        Returns:\n            wrapper\n        \"\"\"\n        wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='first', inplace=True)\n        return wrapper\n\n    def get_first_and_latest_odds(self, wrapper: DataWrapper)-&gt; DataWrapper:\n        \"\"\"\n        Modifies the DataFrame inside the DataWrapper to keep only the first and the last betting odds together.\n\n        Args:\n            wrapper (DataWrapper): An instance of DataWrapper.\n\n        Returns:\n            wrapper\n        \"\"\"\n        dataframe_first = wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='first')\n        dataframe_last = wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='last')\n\n        dataframe_final = dataframe_first.append(dataframe_last)\n\n        wrapper.set_dataframe(dataframe_final)\n        return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer.get_date_from_time","title":"<code>get_date_from_time(wrapper)</code>","text":"<p>Extracts and converts dates from the 'Time' column in the DataFrame, accounting for season transitions.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>An instance of DataWrapper containing the DataFrame.</p> required <p>Returns:</p> Name Type Description <code>DataWrapper</code> <code>DataWrapper</code> <p>The modified DataWrapper with the 'Date' column updated.</p> Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>def get_date_from_time(self, wrapper:DataWrapper) -&gt; DataWrapper:\n    \"\"\"\n    Extracts and converts dates from the 'Time' column in the DataFrame, accounting for season transitions.\n\n    Args:\n        wrapper (DataWrapper): An instance of DataWrapper containing the DataFrame.\n\n    Returns:\n        DataWrapper: The modified DataWrapper with the 'Date' column updated.\n    \"\"\"\n\n    seasons = []\n    for _,season in wrapper.get_dataframe().groupby(['League','Season']):\n        season['day'] = season['Time'].str.split('.').str[0]\n        season['month'] = pd.to_numeric(season['Time'].str.split('.').str[1])\n        season = season.sort_values(['month', 'day'])\n        season['diff'] = season['month'].diff()\n        try:\n            min_index = season[season['diff']&gt;1]['diff'].idxmin()\n        except:\n            min_index = season['month'].idxmin()\n        season['Date'] = pd.to_datetime(season.loc[:min_index]['Time'] + (season.loc[:min_index]['Season']+1).apply(str), format=\"%d.%m.%Y\", errors='coerce')\n        season.loc[min_index:,'Date'] = pd.to_datetime(season.loc[min_index:]['Time'] + (season.loc[min_index:]['Season']).apply(str), format=\"%d.%m.%Y\", errors='coerce')\n        season = season[season['Date'].notnull()]\n        seasons.append(season)\n\n    wrapper.set_dataframe(pd.DataFrame(index=wrapper.get_dataframe().index, data=pd.concat(seasons)['Date']))\n    return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer.get_first_and_latest_odds","title":"<code>get_first_and_latest_odds(wrapper)</code>","text":"<p>Modifies the DataFrame inside the DataWrapper to keep only the first and the last betting odds together.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>An instance of DataWrapper.</p> required <p>Returns:</p> Type Description <code>DataWrapper</code> <p>wrapper</p> Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>def get_first_and_latest_odds(self, wrapper: DataWrapper)-&gt; DataWrapper:\n    \"\"\"\n    Modifies the DataFrame inside the DataWrapper to keep only the first and the last betting odds together.\n\n    Args:\n        wrapper (DataWrapper): An instance of DataWrapper.\n\n    Returns:\n        wrapper\n    \"\"\"\n    dataframe_first = wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='first')\n    dataframe_last = wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='last')\n\n    dataframe_final = dataframe_first.append(dataframe_last)\n\n    wrapper.set_dataframe(dataframe_final)\n    return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer.get_first_odds","title":"<code>get_first_odds(wrapper)</code>","text":"<p>Modifies the DataFrame inside the DataWrapper to keep only the first betting odds for each event.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>An instance of DataWrapper.</p> required <p>Returns:</p> Type Description <code>DataWrapper</code> <p>wrapper</p> Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>def get_first_odds(self, wrapper: DataWrapper) -&gt; DataWrapper:\n    \"\"\"\n    Modifies the DataFrame inside the DataWrapper to keep only the first betting odds for each event.\n\n    Args:\n        wrapper (DataWrapper): An instance of DataWrapper.\n\n    Returns:\n        wrapper\n    \"\"\"\n    wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='last', inplace=True)\n    return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer.get_latest_odds","title":"<code>get_latest_odds(wrapper)</code>","text":"<p>Modifies the DataFrame inside the DataWrapper to keep only the last betting odds for each event.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>An instance of DataWrapper.</p> required <p>Returns:</p> Type Description <code>DataWrapper</code> <p>wrapper</p> Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>def get_latest_odds(self, wrapper: DataWrapper) -&gt; DataWrapper:\n    \"\"\"\n    Modifies the DataFrame inside the DataWrapper to keep only the last betting odds for each event.\n\n    Args:\n        wrapper (DataWrapper): An instance of DataWrapper.\n\n    Returns:\n        wrapper\n    \"\"\"\n    wrapper.get_dataframe().drop_duplicates(subset=[\"MatchID\"], keep='first', inplace=True)\n    return wrapper\n</code></pre>"},{"location":"reference/transformations/#transformer.BaseTransformer.BaseTransformer.remove_small_seasons","title":"<code>remove_small_seasons(wrapper, min_teams)</code>","text":"<p>Removes seasons from the DataFrame in DataWrapper where the number of unique teams is less than min_teams.</p> <p>Parameters:</p> Name Type Description Default <code>wrapper</code> <code>DataWrapper</code> <p>An instance of DataWrapper containing the DataFrame.</p> required <code>min_teams</code> <code>int</code> <p>The minimum number of unique teams required to keep a season.</p> required <p>Returns:</p> Name Type Description <code>DataWrapper</code> <p>The modified DataWrapper with small seasons removed.</p> Source code in <code>sports_prediction_framework\\transformer\\BaseTransformer.py</code> <pre><code>def remove_small_seasons(self, wrapper: DataWrapper, min_teams: int):\n    \"\"\"\n    Removes seasons from the DataFrame in DataWrapper where the number of unique teams is less than min_teams.\n\n    Args:\n        wrapper (DataWrapper): An instance of DataWrapper containing the DataFrame.\n        min_teams (int): The minimum number of unique teams required to keep a season.\n\n    Returns:\n        DataWrapper: The modified DataWrapper with small seasons removed.\n    \"\"\"\n    league_column = 'League'\n    season_column = 'Season'\n    to_be_removed = []\n    for group_values,season in wrapper.get_dataframe().groupby([league_column,season_column]):\n        if len(set(season['HID']).union(set(season['AID']))) &lt; min_teams:\n            to_be_removed.append(group_values)\n    for rem in to_be_removed:\n        wrapper.get_dataframe().drop(wrapper.get_dataframe()[(wrapper.get_dataframe()[league_column] == rem[0]) &amp;\n                                     (wrapper.get_dataframe()[season_column] == rem[1])].index,\n                                     inplace=True)\n    return wrapper\n</code></pre>"}]}